{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "MIRCV.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7cf20dfc36584b989acb0b73c8b788c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ImageModel",
          "state": {
            "_view_name": "ImageView",
            "_dom_classes": [],
            "_model_name": "ImageModel",
            "format": "png",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "width": "300",
            "_view_module_version": "1.5.0",
            "layout": "IPY_MODEL_51c9455d96e44c19bcc0107e366482dc",
            "height": "400",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "51c9455d96e44c19bcc0107e366482dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "73781e25a871407780b982b8554422aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ImageModel",
          "state": {
            "_view_name": "ImageView",
            "_dom_classes": [],
            "_model_name": "ImageModel",
            "format": "jpeg",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "width": "300",
            "_view_module_version": "1.5.0",
            "layout": "IPY_MODEL_48d8e0cbccc64d0985cd16ffc8396353",
            "height": "400",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "48d8e0cbccc64d0985cd16ffc8396353": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MarshaGomez/DNN-Sketches-image-analysis/blob/main/Code/MIRCV.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZNzp-m2gZrg"
      },
      "source": [
        "### Setting up the project\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rK6clnXKgorx"
      },
      "source": [
        "import numpy as np\n",
        "from numpy.linalg import norm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFDxt-ReEght",
        "outputId": "1b663c4f-8bd7-4450-cf12-e74f438f00d5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8gB6xCUDuzT"
      },
      "source": [
        "zip_path = '/content/gdrive/Shareddrives/COMPUTER_VISION/MIM_zipped.zip'\n",
        "!cp \"{zip_path}\" .\n",
        "!unzip -q MIM_zipped.zip\n",
        "!rm MIM_zipped.zip\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVssdlksgFVj"
      },
      "source": [
        "### LSH Class\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBH4ovNrgW9e"
      },
      "source": [
        "# def singleton(class_):\n",
        "#     instances = {}\n",
        "#     def getinstance(*args, **kwargs):\n",
        "#         if class_ not in instances:\n",
        "#             instances[class_] = class_(*args, **kwargs)\n",
        "#         return instances[class_]\n",
        "#     return getinstance\n",
        "\n",
        "# @singleton\n",
        "# per adesso è più scomodo che utile averlo come singleton\n",
        "import time\n",
        "\n",
        "class LSH:\n",
        "  def __init__(self, feature_dim, g = 10, h = 20, w = 4, differentiate_g = False, bitwise_hash = False):\n",
        "    \"\"\"\n",
        "    We have to find a way to load the stored index if exists or initialize the \n",
        "    initial structure\n",
        "    \"\"\"\n",
        "    self._index = {}\n",
        "    if bitwise_hash:\n",
        "      # self.x = np.random.randn(g, h, feature_dim) # non sembra richieda una distribuzione normale\n",
        "      self.x = np.random.normal(size=(g, h, feature_dim))\n",
        "    else:\n",
        "      self.x = np.random.normal(size=(g, h, feature_dim))\n",
        "    self.w = np.ones((g, h, 1)) * w\n",
        "    self.b = np.random.rand(g, h, 1) * w\n",
        "    self.differentiate_g = differentiate_g # se 2 g inseriscono nello stesso bucket, possiamo decidere se differenziarle o meno\n",
        "    self.bitwise_hash = bitwise_hash # another way to create h (h will be only 0 o 1)\n",
        "\n",
        "  def _hash(self, features):\n",
        "    \"\"\"\n",
        "    crea l'hash di più cose contemporaeamente si aspetta un array composto dalle features una sotta l'altra (linguaggio super matematico)\n",
        "    \"\"\"\n",
        "    # g = np.trunc((np.dot(p, self.x) + self.b) / self.w)\n",
        "    #g = np.trunc((np.dot(self.x, p) + self.b) / self.w) questo funziona con 1\n",
        "    # g = np.transpose(np.trunc(((np.dot(self.x, p.T) + self.b) / self.w)), (0,2,1)) miglior modo di vederlo\n",
        "    if self.bitwise_hash:\n",
        "      return (np.transpose(np.dot(self.x, features.T), (0,2,1)) > 0).astype(int).astype(str)\n",
        "    return np.transpose(np.trunc(((np.dot(self.x, features.T) + self.b) / self.w)), (0,2,1)).astype(int).astype(str)\n",
        "\n",
        "  def insert(self, features, ids, labels):\n",
        "    \"\"\"\n",
        "    Insert new data, ci aspettiamo un array d\n",
        "    \"\"\"\n",
        "    g = self._hash(features)\n",
        "    assert features.shape[0] == len(ids), \"mismatch between ids length and features\"\n",
        "    assert len(labels) == len(ids), \"mismatch between ids length and labels\"\n",
        "    \n",
        "    number_elements = len(ids)\n",
        "    i = 0\n",
        "    print(\"hash calculated\")\n",
        "    print(g.shape)\n",
        "    g_index = -1\n",
        "    for g_function in g:\n",
        "      start_inner_for = time.time()\n",
        "      g_index += 1\n",
        "      for row in g_function:\n",
        "        if i % 10000 == 0:\n",
        "          start = time.time()\n",
        "        \n",
        "        if self.differentiate_g: # assicura che ogni g inserisca in un bucket differente\n",
        "          bucket_id = str(g_index) + '-' + ','.join(row)\n",
        "        else: \n",
        "          bucket_id = ','.join(row)\n",
        "        \n",
        "        if i % 10000 == 0:\n",
        "            end = time.time()\n",
        "            print(f'join {end - start}')\n",
        "        if not bucket_id in self._index:\n",
        "          # self._index[bucket_id] = { 'features': np.array([features[i % number_elements]]), 'ids': np.array([ids[i % number_elements]]), 'labels': np.array([labels[i % number_elements]])}\n",
        "          self._index[bucket_id] = { 'features': [features[i % number_elements]], 'ids': [ids[i % number_elements]], 'labels': [labels[i % number_elements]]}\n",
        "          if i % 10000 == 0:\n",
        "            end = time.time()\n",
        "            print(f'not in bucket {end - start}')\n",
        "        else:\n",
        "          if ids[i % number_elements] in self._index[bucket_id]['ids']:\n",
        "            # print(\"duplicate\")\n",
        "            continue\n",
        "          if i % 10000 == 0:\n",
        "            end = time.time()\n",
        "            print(f'checking duplicates {end - start}')\n",
        "          # print(\"collision inserted\")\n",
        "          # self._index[bucket_id]['features'] = np.vstack((self._index[bucket_id]['features'], features[i % number_elements]))\n",
        "          self._index[bucket_id]['features'].append(features[i % number_elements])\n",
        "          # self._index[bucket_id]['ids'] = np.vstack((self._index[bucket_id]['ids'], ids[i % number_elements]))\n",
        "          self._index[bucket_id]['ids'].append(ids[i % number_elements])\n",
        "          # self._index[bucket_id]['labels'] = np.vstack((self._index[bucket_id]['labels'], labels[i % number_elements]))\n",
        "          self._index[bucket_id]['labels'].append(labels[i % number_elements])\n",
        "          if i % 10000 == 0:\n",
        "            end = time.time()\n",
        "            print(f'stacking {end - start}')\n",
        "        i += 1\n",
        "        assert i > 0, 'out of bound'\n",
        "      end_inner_for = time.time()\n",
        "      print(f'inner for time: {end_inner_for - start_inner_for}')\n",
        "    \n",
        "    for bucket_id in self._index:\n",
        "      self._index[bucket_id]['features'] = np.array(self._index[bucket_id]['features'])\n",
        "      print(self._index[bucket_id]['features'].shape)\n",
        "      self._index[bucket_id]['ids'] = np.array(self._index[bucket_id]['ids'], )\n",
        "      self._index[bucket_id]['labels'] = np.array(self._index[bucket_id]['labels'])\n",
        "      \n",
        "\n",
        "  def query(self, features, top_k, mode = 'euclidean', return_cost = False):\n",
        "    \"\"\"\n",
        "    Query the data\n",
        "    \"\"\"\n",
        "    g = self._hash(np.array([features]))\n",
        "    i = 0\n",
        "    k = None\n",
        "    top_k += 1 # per far ritornare k e non k - 1\n",
        "    cost = 0\n",
        "    g_index = -1\n",
        "    assert mode in ['similarity', 'euclidean'], \"mode must be similarity or euclidean\"\n",
        "    for g_function in g:\n",
        "      g_index += 1\n",
        "      for row in g_function:\n",
        "        if self.differentiate_g: # assicura che ogni g inserisca in un bucket differente\n",
        "          bucket_id = str(g_index) + '-' + ','.join(row)\n",
        "        else: \n",
        "          bucket_id = ','.join(row)\n",
        "        print(bucket_id)\n",
        "        if bucket_id in self._index:\n",
        "          # posso avere duplicati perchè se i punti vengono inseriti in più bucket, posso avere duplicati\n",
        "          # quindi devo eliminarli\n",
        "          # l'ho messo qua fuori che il controllo duplicati è uguale per tutte e due le distanze\n",
        "          # print(f'bucket {bucket_id}')\n",
        "          if k is not None:\n",
        "            # print(\"duplicate\")\n",
        "            duplicate_index = np.isin(self._index[bucket_id]['ids'], k['ids'])\n",
        "            if duplicate_index.all():\n",
        "              continue; # se sono tutti duplicati non ha senso contare nulla\n",
        "            bucket = {}\n",
        "            bucket['ids'] = self._index[bucket_id]['ids'][~duplicate_index] # prendo quelli che non sono duplicati\n",
        "            # print(duplicate_index)\n",
        "            # print(self._index[bucket_id]['features'])\n",
        "            bucket['features'] = self._index[bucket_id]['features'][~duplicate_index.flatten()] # each duplicate index must delete a row of features\n",
        "            bucket['labels'] = self._index[bucket_id]['labels'][~duplicate_index]\n",
        "          else:\n",
        "            bucket = self._index[bucket_id]\n",
        "        \n",
        "          if mode == 'euclidean':\n",
        "            # print(bucket['features'].shape)\n",
        "            dist = norm(bucket['features'] - np.array(features), axis=1)\n",
        "            print(f'dist shape {dist.shape} and dist size {dist.size}')\n",
        "            cost += dist.size\n",
        "            if k is None:\n",
        "              idx_partitioned = np.argpartition(dist, top_k - 1 if dist.shape[0] - 1 > top_k - 1 else dist.shape[0] - 1)\n",
        "              if dist.shape[0] - 1 > top_k - 1:  \n",
        "                  idx_partitioned = idx_partitioned[:top_k - 1]\n",
        "              k = {}\n",
        "              # qua è più comodo avere array 1- dimensionali\n",
        "              k['ids'] = bucket['ids'][idx_partitioned].flatten()\n",
        "              k['labels'] = bucket['labels'][idx_partitioned].flatten()\n",
        "              k['distances'] = dist[idx_partitioned]\n",
        "              continue\n",
        "            # https://stackoverflow.com/questions/10337533/a-fast-way-to-find-the-largest-n-elements-in-an-numpy-array\n",
        "            # argpartition sembra essere incredibilmente veloce\n",
        "            # ma non ordina completamente, ordina solo rispetto un punto, nel senso\n",
        "            # io gli sto dicendo butta quelli più piccoli di k da una parte e quelli più grandi all'altra, ma non sto ordinando\n",
        "            if k['distances'].shape[0] < top_k:\n",
        "                # print((k['distances'].shape, dist.shape))\n",
        "                distances = np.concatenate((k['distances'], dist))\n",
        "                # print((k['ids'].shape, bucket['ids'].shape))\n",
        "                # print(k['ids'])\n",
        "                # print(bucket['ids'])\n",
        "                ids = np.concatenate((k['ids'], bucket['ids']))\n",
        "                # print((k['labels'].shape, bucket['labels'].shape))\n",
        "                labels = np.concatenate((k['labels'], bucket['labels']))\n",
        "                idx_sorted = np.argpartition(distances, top_k - 1 if distances.shape[0] - 1 > top_k else distances.shape[0] - 1)\n",
        "                if distances.shape[0] - 1 > top_k - 1:  \n",
        "                  idx_sorted = idx_sorted[:top_k - 1]\n",
        "                k['ids'] = ids[idx_sorted]\n",
        "                k['labels'] = labels[idx_sorted]\n",
        "                k['distances'] = distances[idx_sorted]\n",
        "                # print(f'k = {k}')\n",
        "                continue\n",
        "\n",
        "            idx = dist < np.max(k['distances'])\n",
        "            # print(f\"idx = {idx}\")\n",
        "            if np.any(idx):\n",
        "              distances = np.concatenate((k['distances'], dist[idx]))\n",
        "              ids = np.concatenate((k['ids'], bucket['ids'][idx]))\n",
        "              labels = np.concatenate((k['labels'], bucket['labels'][idx]))\n",
        "              idx_sorted = np.argpartition(distances, top_k - 1 if distances.shape[0] - 1 > top_k else distances.shape[0] - 1)\n",
        "              if distances.shape[0] - 1 > top_k - 1:  \n",
        "                  idx_sorted = idx_sorted[:top_k - 1]\n",
        "              k['ids'] = ids[idx_sorted]\n",
        "              k['labels'] = labels[idx_sorted]\n",
        "              k['distances'] = distances[idx_sorted]\n",
        "\n",
        "          else:\n",
        "            # print(bucket['features'].shape)\n",
        "            sim = np.sum(bucket['features'] * np.array(features), axis=1) / (norm(bucket['features'], axis=1) * norm(np.array([features]), axis=1))\n",
        "            print(f'sim shape {sim.shape} and sim size {sim.size}')\n",
        "            cost += sim.size\n",
        "            if k is None:\n",
        "              idx_partitioned = np.argpartition(sim, -(top_k - 1) if sim.shape[0] - 1 > top_k - 1 else sim.shape[0] - 1)\n",
        "              if sim.shape[0] - 1 > top_k - 1:  \n",
        "                idx_partitioned = idx_partitioned[-(top_k - 1):]\n",
        "              k = {}\n",
        "              # qua è più comodo avere array 1- dimensionali\n",
        "              k['ids'] = bucket['ids'][idx_partitioned].flatten()\n",
        "              k['labels'] = bucket['labels'][idx_partitioned].flatten()\n",
        "              k['similarities'] = sim[idx_partitioned]\n",
        "              continue\n",
        "            # https://stackoverflow.com/questions/10337533/a-fast-way-to-find-the-largest-n-elements-in-an-numpy-array\n",
        "            # argpartition sembra essere incredibilmente veloce\n",
        "            # ma non ordina completamente, ordina solo rispetto un punto, nel senso\n",
        "            # io gli sto dicendo butta quelli più piccoli di k da una parte e quelli più grandi all'altra, ma non sto ordinando\n",
        "            if k['similarities'].shape[0] < top_k:\n",
        "                # print((k['similarities'].shape, sim.shape))\n",
        "                similarities = np.concatenate((k['similarities'], sim))\n",
        "                # print((k['ids'].shape, bucket['ids'].shape))\n",
        "                # print(k['ids'])\n",
        "                # print(bucket['ids'])\n",
        "                ids = np.concatenate((k['ids'], bucket['ids']))\n",
        "                # print((k['labels'].shape, bucket['labels'].shape))\n",
        "                labels = np.concatenate((k['labels'], bucket['labels']))\n",
        "                idx_sorted = np.argpartition(similarities, -(top_k - 1) if similarities.shape[0] - 1 > top_k - 1 else similarities.shape[0] - 1)\n",
        "                if similarities.shape[0] - 1 > top_k - 1:  \n",
        "                  idx_sorted = idx_sorted[-(top_k - 1):]\n",
        "                k['ids'] = ids[idx_sorted]\n",
        "                k['labels'] = labels[idx_sorted]\n",
        "                k['similarities'] = similarities[idx_sorted]\n",
        "                # print(f'k = {k}')\n",
        "                continue\n",
        "\n",
        "            idx = sim > np.min(k['similarities'])\n",
        "            # print(f\"idx = {idx}\")\n",
        "            if np.any(idx):\n",
        "              similarities = np.concatenate((k['similarities'], sim[idx]))\n",
        "              ids = np.concatenate((k['ids'], bucket['ids'][idx]))\n",
        "              labels = np.concatenate((k['labels'], bucket['labels'][idx]))\n",
        "              idx_sorted = np.argpartition(similarities, -(top_k - 1) if similarities.shape[0] - 1 > top_k - 1 else similarities.shape[0] - 1)\n",
        "              if similarities.shape[0] - 1 > top_k - 1:  \n",
        "                idx_sorted = idx_sorted[-(top_k - 1):]\n",
        "              k['ids'] = ids[idx_sorted]\n",
        "              k['labels'] = labels[idx_sorted]\n",
        "              k['similarities'] = similarities[idx_sorted]\n",
        "        i += 1\n",
        "    # ora ordino totalmente i risultati\n",
        "    if k is None:\n",
        "      return {} #zero result\n",
        "    if mode == 'euclidean':\n",
        "      idx_sorted = np.argsort(k['distances'])\n",
        "      idx_sorted = idx_sorted[:top_k - 1 if k['distances'].shape[0] - 1 > top_k else k['distances'].shape[0]]\n",
        "      k['distances'] = k['distances'][idx_sorted]\n",
        "      k['ids'] = k['ids'][idx_sorted]\n",
        "      k['labels'] = k['labels'][idx_sorted]\n",
        "      if return_cost:\n",
        "        return (k, cost)\n",
        "      return k\n",
        "    idx_sorted = np.argsort(k['similarities'])[::-1]\n",
        "    idx_sorted = idx_sorted[:top_k - 1 if k['similarities'].shape[0] - 1 > top_k else k['similarities'].shape[0]]\n",
        "    k['similarities'] = k['similarities'][idx_sorted]\n",
        "    k['ids'] = k['ids'][idx_sorted]\n",
        "    k['labels'] = k['labels'][idx_sorted]\n",
        "    if return_cost:\n",
        "      return (k, cost)\n",
        "    return k\n",
        "\n",
        "  def store(self):\n",
        "    pass\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OclqmXVqxEn",
        "outputId": "df4a5aab-9906-4b0a-ba9c-ff004dc98ed7"
      },
      "source": [
        "a = np.array([4, 3, 2, 1, 0])\r\n",
        "a[np.argpartition(a,0)]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 3, 2, 1, 4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGc8niClvT0b"
      },
      "source": [
        "class NO_INDEX:\r\n",
        "  def __init__(self):\r\n",
        "    self.features = None\r\n",
        "    self.ids = None\r\n",
        "    self.labels = None\r\n",
        "\r\n",
        "  def insert(self, features, ids, labels):\r\n",
        "    assert features.shape[0] == len(ids), \"mismatch between ids length and features\"\r\n",
        "    assert len(labels) == len(ids), \"mismatch between ids length and labels\"\r\n",
        "    self.features = features\r\n",
        "    self.ids = ids\r\n",
        "    self.labels = labels\r\n",
        "  \r\n",
        "  def query(self, features, top_k, mode = 'euclidean', return_cost = False):\r\n",
        "    assert mode in ['similarity', 'euclidean'], \"mode must be similarity or euclidean\"\r\n",
        "    top_k += 1\r\n",
        "    if mode == 'euclidean':\r\n",
        "      dist = norm(self.features - np.array(features), axis=1)\r\n",
        "      idx_partitioned = np.argpartition(dist, top_k - 1 if dist.shape[0] - 1 > top_k - 1 else dist.shape[0] - 1)\r\n",
        "      k = {}\r\n",
        "      # qua è più comodo avere array 1- dimensionali\r\n",
        "      k['ids'] = self.ids[idx_partitioned].flatten()[:top_k - 1 if dist.shape[0] - 1 > top_k - 1 else dist.shape[0]]\r\n",
        "      k['labels'] = self.labels[idx_partitioned].flatten()[:top_k - 1 if dist.shape[0] - 1 > top_k - 1 else dist.shape[0]]\r\n",
        "      k['distances'] = dist[idx_partitioned][:top_k - 1 if dist.shape[0] - 1 > top_k - 1 else dist.shape[0]]\r\n",
        "      \r\n",
        "      idx_sorted = np.argsort(k['distances'])\r\n",
        "      idx_sorted = idx_sorted\r\n",
        "      k['distances'] = k['distances'][idx_sorted]\r\n",
        "      k['ids'] = k['ids'][idx_sorted]\r\n",
        "      k['labels'] = k['labels'][idx_sorted]\r\n",
        "      if return_cost:\r\n",
        "        return (k, dist.size)\r\n",
        "      return k\r\n",
        "    sim = np.sum(self.features * np.array(features), axis=1) / (norm(self.features, axis=1) * norm(np.array([features]), axis=1))\r\n",
        "    idx_partitioned = np.argpartition(sim, -(top_k - 1) if sim.shape[0] - 1 > top_k - 1 else sim.shape[0] - 1)\r\n",
        "    print(sim.shape[0])\r\n",
        "    k = {}\r\n",
        "    # qua è più comodo avere array 1- dimensionali\r\n",
        "    if sim.shape[0] - 1 > top_k - 1:  \r\n",
        "      idx_partitioned = idx_partitioned[-(top_k - 1):]\r\n",
        "\r\n",
        "    k['ids'] = self.ids[idx_partitioned].flatten()\r\n",
        "    k['labels'] = self.labels[idx_partitioned].flatten()\r\n",
        "    k['similarities'] = sim[idx_partitioned]\r\n",
        "    idx_sorted = np.argsort(k['similarities'])[::-1]\r\n",
        "    idx_sorted = idx_sorted\r\n",
        "    k['similarities'] = k['similarities'][idx_sorted]\r\n",
        "    k['ids'] = k['ids'][idx_sorted]\r\n",
        "    k['labels'] = k['labels'][idx_sorted]\r\n",
        "    if return_cost:\r\n",
        "      return (k, sim.size)\r\n",
        "    return k\r\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOSZDImuQBW9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "494ab459-5f9a-47cf-fc2c-58f8fe742d45"
      },
      "source": [
        "#### TESTING PURPOSE\n",
        "print('\"Base LSH\"')\n",
        "index = LSH(feature_dim= 2, g= 2, h=2)\n",
        "print('x=')\n",
        "print(index.x)\n",
        "print('w=')\n",
        "print(index.w)\n",
        "print('b=')\n",
        "print(index.b)\n",
        "print('ps =')\n",
        "print(np.array([[1,1], [1.1, 1.2], [1.4, 1.44], [3, 4]]))\n",
        "print('insert')\n",
        "index.insert(\n",
        "     np.array([[1,1], [1.1, 1.2], [1.4, 1.44], [3, 4]]), \n",
        "     np.array(['uno', 'due', 'tre','quattro']),\n",
        "     np.array([0,0,1,1])\n",
        "     )\n",
        "print(index._index)\n",
        "print('query euclidean')\n",
        "print(index.query([1,1], 4, return_cost=True))\n",
        "print('query similarity')\n",
        "print(index.query([1,1], 4, mode='similarity', return_cost=True))\n",
        "print(index)\n",
        "\n",
        "\n",
        "print('\"Differentiate g LSH\"')\n",
        "index = LSH(feature_dim= 2, g= 2, h=2, differentiate_g=True)\n",
        "print('x=')\n",
        "print(index.x)\n",
        "print('w=')\n",
        "print(index.w)\n",
        "print('b=')\n",
        "print(index.b)\n",
        "print('ps =')\n",
        "print(np.array([[1,1], [1.1, 1.2], [1.4, 1.44], [3, 4]]))\n",
        "print('insert')\n",
        "index.insert(\n",
        "     np.array([[1,1], [1.1, 1.2], [1.4, 1.44], [3, 4]]), \n",
        "     np.array(['uno', 'due', 'tre','quattro']),\n",
        "     np.array([0,0,1,1])\n",
        "     )\n",
        "print(index._index)\n",
        "print('query')\n",
        "print(index.query([1,1], 4))\n",
        "print(index)\n",
        "\n",
        "\n",
        "print('\"bitwise hash LSH\"')\n",
        "index = LSH(feature_dim= 2, g=2, h=2, bitwise_hash=True)\n",
        "print('x=')\n",
        "print(index.x)\n",
        "print('w=')\n",
        "print(index.w)\n",
        "print('b=')\n",
        "print(index.b)\n",
        "print('ps =')\n",
        "print(np.array([[1,1], [1.1, 1.2], [1.4, 1.44], [3, 4]]))\n",
        "print('insert')\n",
        "index.insert(\n",
        "     np.array([[1,1], [1.1, 1.2], [1.4, 1.44], [3, 4]]), \n",
        "     np.array(['uno', 'due', 'tre','quattro']),\n",
        "     np.array([0,0,1,1])\n",
        "     )\n",
        "print(index._index)\n",
        "print('query')\n",
        "print(index.query([1,1], 4))\n",
        "print(index)\n",
        "\n",
        "print('NO INDEX')\n",
        "index = NO_INDEX()\n",
        "print(np.array([[1,1], [1.1, 1.2], [1.4, 1.44], [3, 4]]))\n",
        "print('insert')\n",
        "index.insert(\n",
        "     np.array([[1,1], [1.1, 1.2], [1.4, 1.44], [3, 4]]), \n",
        "     np.array(['uno', 'due', 'tre','quattro']),\n",
        "     np.array([0,0,1,1])\n",
        "     )\n",
        "print('query euclidean')\n",
        "print(index.query([1,1], 4, return_cost=True))\n",
        "print('query similarity')\n",
        "print(index.query([1,1], 4, mode='similarity', return_cost=True))\n",
        "print(index)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\"Base LSH\"\n",
            "x=\n",
            "[[[-0.18783918  0.75334016]\n",
            "  [ 0.12190565 -0.14548194]]\n",
            "\n",
            " [[-0.40398417  0.01557776]\n",
            "  [-1.83078914 -0.86391799]]]\n",
            "w=\n",
            "[[[4.]\n",
            "  [4.]]\n",
            "\n",
            " [[4.]\n",
            "  [4.]]]\n",
            "b=\n",
            "[[[2.63705556]\n",
            "  [0.37983413]]\n",
            "\n",
            " [[1.12068416]\n",
            "  [2.0950663 ]]]\n",
            "ps =\n",
            "[[1.   1.  ]\n",
            " [1.1  1.2 ]\n",
            " [1.4  1.44]\n",
            " [3.   4.  ]]\n",
            "insert\n",
            "hash calculated\n",
            "(2, 4, 2)\n",
            "join 1.5020370483398438e-05\n",
            "not in bucket 5.8650970458984375e-05\n",
            "inner for time: 0.00010347366333007812\n",
            "inner for time: 2.09808349609375e-05\n",
            "(3, 2)\n",
            "(1, 2)\n",
            "(1, 2)\n",
            "{'0,0': {'features': array([[1.  , 1.  ],\n",
            "       [1.1 , 1.2 ],\n",
            "       [1.4 , 1.44]]), 'ids': array(['uno', 'due', 'tre'], dtype='<U3'), 'labels': array([0, 0, 1])}, '1,0': {'features': array([[3., 4.]]), 'ids': array(['quattro'], dtype='<U7'), 'labels': array([1])}, '0,-1': {'features': array([[1., 1.]]), 'ids': array(['uno'], dtype='<U3'), 'labels': array([0])}}\n",
            "query euclidean\n",
            "0,0\n",
            "dist shape (3,) and dist size 3\n",
            "0,0\n",
            "({'ids': array(['uno', 'due', 'tre'], dtype='<U3'), 'labels': array([0, 0, 1]), 'distances': array([0.        , 0.2236068 , 0.59464275])}, 3)\n",
            "query similarity\n",
            "0,0\n",
            "sim shape (3,) and sim size 3\n",
            "0,0\n",
            "({'ids': array(['uno', 'tre', 'due'], dtype='<U3'), 'labels': array([0, 1, 0]), 'similarities': array([1.        , 0.99990083, 0.99905616])}, 3)\n",
            "<__main__.LSH object at 0x7fcb0f1e2048>\n",
            "\"Differentiate g LSH\"\n",
            "x=\n",
            "[[[ 0.18562552  0.83795084]\n",
            "  [-0.17527784  0.61969643]]\n",
            "\n",
            " [[-0.9837992  -0.74429985]\n",
            "  [-0.93631863 -0.40627389]]]\n",
            "w=\n",
            "[[[4.]\n",
            "  [4.]]\n",
            "\n",
            " [[4.]\n",
            "  [4.]]]\n",
            "b=\n",
            "[[[3.37143889]\n",
            "  [0.76579054]]\n",
            "\n",
            " [[0.8795414 ]\n",
            "  [1.73489817]]]\n",
            "ps =\n",
            "[[1.   1.  ]\n",
            " [1.1  1.2 ]\n",
            " [1.4  1.44]\n",
            " [3.   4.  ]]\n",
            "insert\n",
            "hash calculated\n",
            "(2, 4, 2)\n",
            "join 2.86102294921875e-05\n",
            "not in bucket 6.413459777832031e-05\n",
            "inner for time: 0.00012063980102539062\n",
            "inner for time: 3.910064697265625e-05\n",
            "(4, 2)\n",
            "(3, 2)\n",
            "(1, 2)\n",
            "{'0-1,0': {'features': array([[1.  , 1.  ],\n",
            "       [1.1 , 1.2 ],\n",
            "       [1.4 , 1.44],\n",
            "       [3.  , 4.  ]]), 'ids': array(['uno', 'due', 'tre', 'quattro'], dtype='<U7'), 'labels': array([0, 0, 1, 1])}, '1-0,0': {'features': array([[1.  , 1.  ],\n",
            "       [1.1 , 1.2 ],\n",
            "       [1.4 , 1.44]]), 'ids': array(['uno', 'due', 'tre'], dtype='<U3'), 'labels': array([0, 0, 1])}, '1--1,0': {'features': array([[3., 4.]]), 'ids': array(['quattro'], dtype='<U7'), 'labels': array([1])}}\n",
            "query\n",
            "0-1,0\n",
            "dist shape (4,) and dist size 4\n",
            "1-0,0\n",
            "{'ids': array(['uno', 'due', 'tre', 'quattro'], dtype='<U7'), 'labels': array([0, 0, 1, 1]), 'distances': array([0.        , 0.2236068 , 0.59464275, 3.60555128])}\n",
            "<__main__.LSH object at 0x7fcb0f1e2160>\n",
            "\"bitwise hash LSH\"\n",
            "x=\n",
            "[[[-1.03503814 -0.72817154]\n",
            "  [-0.65927344  1.06775052]]\n",
            "\n",
            " [[-0.82641984 -1.37153895]\n",
            "  [ 1.907652    0.69592635]]]\n",
            "w=\n",
            "[[[4.]\n",
            "  [4.]]\n",
            "\n",
            " [[4.]\n",
            "  [4.]]]\n",
            "b=\n",
            "[[[3.39393692]\n",
            "  [0.26424792]]\n",
            "\n",
            " [[2.83644976]\n",
            "  [1.44840641]]]\n",
            "ps =\n",
            "[[1.   1.  ]\n",
            " [1.1  1.2 ]\n",
            " [1.4  1.44]\n",
            " [3.   4.  ]]\n",
            "insert\n",
            "hash calculated\n",
            "(2, 4, 2)\n",
            "join 1.1205673217773438e-05\n",
            "not in bucket 6.890296936035156e-05\n",
            "inner for time: 0.00012445449829101562\n",
            "inner for time: 2.1457672119140625e-05\n",
            "(4, 2)\n",
            "{'0,1': {'features': array([[1.  , 1.  ],\n",
            "       [1.1 , 1.2 ],\n",
            "       [1.4 , 1.44],\n",
            "       [3.  , 4.  ]]), 'ids': array(['uno', 'due', 'tre', 'quattro'], dtype='<U7'), 'labels': array([0, 0, 1, 1])}}\n",
            "query\n",
            "0,1\n",
            "dist shape (4,) and dist size 4\n",
            "0,1\n",
            "{'ids': array(['uno', 'due', 'tre', 'quattro'], dtype='<U7'), 'labels': array([0, 0, 1, 1]), 'distances': array([0.        , 0.2236068 , 0.59464275, 3.60555128])}\n",
            "<__main__.LSH object at 0x7fcb0f1e23c8>\n",
            "NO INDEX\n",
            "[[1.   1.  ]\n",
            " [1.1  1.2 ]\n",
            " [1.4  1.44]\n",
            " [3.   4.  ]]\n",
            "insert\n",
            "query euclidean\n",
            "({'ids': array(['uno', 'due', 'tre', 'quattro'], dtype='<U7'), 'labels': array([0, 0, 1, 1]), 'distances': array([0.        , 0.2236068 , 0.59464275, 3.60555128])}, 4)\n",
            "query similarity\n",
            "4\n",
            "({'ids': array(['uno', 'tre', 'due', 'quattro'], dtype='<U7'), 'labels': array([0, 1, 0, 1]), 'similarities': array([1.        , 0.99990083, 0.99905616, 0.98994949])}, 4)\n",
            "<__main__.NO_INDEX object at 0x7fcb0f1e2160>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ut8ym0mOkwrq"
      },
      "source": [
        "### Loading images DATA\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b94Vh0jSDjLi"
      },
      "source": [
        "import os \r\n",
        "from IPython.display import display\r\n",
        "from ipywidgets import Image\r\n",
        "\r\n",
        "#data loading\r\n",
        "# reading from unzipped\r\n",
        "BASE_DIR = \"/content/content/gdrive/Shareddrives/COMPUTER_VISION/MIRCV\"\r\n",
        "# FILELIST_PATH = BASE_DIR + \"/filelist.txt\"\r\n",
        "SKETCHES_DIR = BASE_DIR + \"/sketches/png\"\r\n",
        "MIRFLICKR_DIR = BASE_DIR + \"/mirflickr/mirflickr25k\"\r\n",
        "\r\n",
        "#print(FILELIST_PATH)\r\n",
        "\r\n",
        "#num_folders = os.listdir(SKETCHES_DIR)\r\n",
        "#print(num_folders)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325,
          "referenced_widgets": [
            "7cf20dfc36584b989acb0b73c8b788c6",
            "51c9455d96e44c19bcc0107e366482dc"
          ]
        },
        "id": "Oa7UA7SiIVqN",
        "outputId": "22c53dd7-cee6-42f7-b34a-e1302d7c0dac"
      },
      "source": [
        "# sketch image displaying \r\n",
        "filename = \"airplane/1.png\"\r\n",
        "image1 = os.path.join(SKETCHES_DIR, filename)\r\n",
        "display(Image.from_file(image1, width=300, height=400))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7cf20dfc36584b989acb0b73c8b788c6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x04W\\x00\\x00\\x04W\\x08\\x00\\x00\\x00\\x00\\x105\\xd1!\\x00\\…"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425,
          "referenced_widgets": [
            "73781e25a871407780b982b8554422aa",
            "48d8e0cbccc64d0985cd16ffc8396353"
          ]
        },
        "id": "xrM9vmb8ZEE7",
        "outputId": "760083c5-82d1-4750-f2c3-4c457a10c30e"
      },
      "source": [
        "# mirflickr image displaying \r\n",
        "filename = \"png/im20.jpg\"\r\n",
        "image1 = os.path.join(MIRFLICKR_DIR, filename)\r\n",
        "display(Image.from_file(image1, width=300, height=400))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "73781e25a871407780b982b8554422aa",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Image(value=b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01\\x01,\\x01,\\x00\\x00\\xff\\xe2\\x0cXICC_PROFILE\\x00\\x01\\x…"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktkpOhauamCP"
      },
      "source": [
        "IMG_HEIGHT = 229\r\n",
        "IMG_WIDTH = 229\r\n",
        "INPUT_SHAPE = (IMG_WIDTH, IMG_HEIGHT, 3)\r\n",
        "BATCH_SIZE = 512"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DS0FuulCNrkH",
        "outputId": "272dca89-afe7-4378-8b5a-5a56884e12e6"
      },
      "source": [
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\r\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\r\n",
        "from tensorflow.keras.preprocessing import image\r\n",
        "from tensorflow.keras.applications.inception_v3 import preprocess_input\r\n",
        "#yields batches of images from the subdirectories \r\n",
        "#found in the sketches directory [class_0 ... class_250]\r\n",
        "#together with class labels.\r\n",
        "\r\n",
        "#images normalization \r\n",
        "sketches_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\r\n",
        "mirflickr_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\r\n",
        "\r\n",
        "sketches_generator = sketches_datagen.flow_from_directory(\r\n",
        "        # This is the target directory\r\n",
        "        SKETCHES_DIR,\r\n",
        "        shuffle=False,\r\n",
        "        target_size=(IMG_HEIGHT, IMG_WIDTH),\r\n",
        "        batch_size=BATCH_SIZE)\r\n",
        "\r\n",
        "mirflickr_generator = mirflickr_datagen.flow_from_directory(\r\n",
        "        # This is the target directory\r\n",
        "        MIRFLICKR_DIR,\r\n",
        "        shuffle=False,\r\n",
        "        target_size=(IMG_HEIGHT, IMG_WIDTH),\r\n",
        "        batch_size=BATCH_SIZE)\r\n",
        "\r\n",
        "\r\n",
        "# unique, counts = np.unique(sketches_generator.classes, return_counts=True)\r\n",
        "# labels_dict = dict(zip(unique, counts))\r\n",
        "# print(labels_dict)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 20000 images belonging to 250 classes.\n",
            "Found 25000 images belonging to 1 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NsH-5M_il69S"
      },
      "source": [
        "### Loading DNN for features extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-80xyrZJlLB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04883c6a-3100-4ef2-a3d0-89a835dbbc4f"
      },
      "source": [
        "#loading Inception DNN\r\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\r\n",
        "\r\n",
        "conv_base = InceptionV3(weights='imagenet',\r\n",
        "                  include_top=False,\r\n",
        "                  input_shape=INPUT_SHAPE,\r\n",
        "                  pooling='avg')\r\n",
        "\r\n",
        "conv_base.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"inception_v3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 229, 229, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 114, 114, 32) 864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 114, 114, 32) 96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 114, 114, 32) 0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 112, 112, 32) 9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 112, 112, 32) 96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 112, 112, 32) 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 112, 112, 64) 18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 112, 112, 64) 192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 112, 112, 64) 0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 55, 55, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 55, 55, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 55, 55, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 55, 55, 80)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 53, 53, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 53, 53, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 53, 53, 192)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 26, 26, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 26, 26, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 26, 26, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 26, 26, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 26, 26, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 26, 26, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 26, 26, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 26, 26, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 26, 26, 48)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 26, 26, 96)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 26, 26, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 26, 26, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 26, 26, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 26, 26, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 26, 26, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 26, 26, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 26, 26, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 26, 26, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 26, 26, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 26, 26, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 26, 26, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 26, 26, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 26, 26, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 26, 26, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 26, 26, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 26, 26, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 26, 26, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 26, 26, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 26, 26, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 26, 26, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 26, 26, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 26, 26, 48)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 26, 26, 96)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 26, 26, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 26, 26, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 26, 26, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 26, 26, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 26, 26, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 26, 26, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 26, 26, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 26, 26, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 26, 26, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 26, 26, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 26, 26, 64)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 26, 26, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 26, 26, 64)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 26, 26, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 26, 26, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 26, 26, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 26, 26, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 26, 26, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 26, 26, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 26, 26, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 26, 26, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 26, 26, 48)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 26, 26, 96)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 26, 26, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 26, 26, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 26, 26, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 26, 26, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 26, 26, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 26, 26, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 26, 26, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 26, 26, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 26, 26, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 26, 26, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 26, 26, 64)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 26, 26, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 26, 26, 64)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 26, 26, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 26, 26, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 26, 26, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 26, 26, 64)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 26, 26, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 26, 26, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 26, 26, 96)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 12, 12, 384)  995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 12, 12, 96)   82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 12, 12, 384)  1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 12, 12, 96)   288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 12, 12, 384)  0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 12, 12, 96)   0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 12, 12, 288)  0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 12, 12, 768)  0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 12, 12, 128)  384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 12, 12, 128)  0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 12, 12, 128)  114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 12, 12, 128)  384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 12, 12, 128)  0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 12, 12, 128)  114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 12, 12, 128)  384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 12, 12, 128)  384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 12, 12, 128)  0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 12, 12, 128)  0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 12, 12, 128)  114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 12, 12, 128)  114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 12, 12, 128)  384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 12, 12, 128)  384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 12, 12, 128)  0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 12, 12, 128)  0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 12, 12, 768)  0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 12, 12, 192)  147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 12, 12, 192)  172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 12, 12, 192)  172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 12, 12, 192)  576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 12, 12, 192)  576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 12, 12, 192)  576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 12, 12, 192)  576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 12, 12, 192)  0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 12, 12, 192)  0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 12, 12, 192)  0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 12, 12, 192)  0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 12, 12, 768)  0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 12, 12, 160)  480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 12, 12, 160)  0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 12, 12, 160)  179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 12, 12, 160)  480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 12, 12, 160)  0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 12, 12, 160)  179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 12, 12, 160)  480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 12, 12, 160)  480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 12, 12, 160)  0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 12, 12, 160)  0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 12, 12, 160)  179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 12, 12, 160)  179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 12, 12, 160)  480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 12, 12, 160)  480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 12, 12, 160)  0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 12, 12, 160)  0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 12, 12, 768)  0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 12, 12, 192)  147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 12, 12, 192)  215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 12, 12, 192)  215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 12, 12, 192)  576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 12, 12, 192)  576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 12, 12, 192)  576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 12, 12, 192)  576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 12, 12, 192)  0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 12, 12, 192)  0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 12, 12, 192)  0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 12, 12, 192)  0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 12, 12, 768)  0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 12, 12, 160)  480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 12, 12, 160)  0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 12, 12, 160)  179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 12, 12, 160)  480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 12, 12, 160)  0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 12, 12, 160)  179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 12, 12, 160)  480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 12, 12, 160)  480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 12, 12, 160)  0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 12, 12, 160)  0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 12, 12, 160)  179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 12, 12, 160)  179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 12, 12, 160)  480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 12, 12, 160)  480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 12, 12, 160)  0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 12, 12, 160)  0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 12, 12, 768)  0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 12, 12, 192)  147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 12, 12, 192)  215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 12, 12, 192)  215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 12, 12, 192)  576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 12, 12, 192)  576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 12, 12, 192)  576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 12, 12, 192)  576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 12, 12, 192)  0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 12, 12, 192)  0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 12, 12, 192)  0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 12, 12, 192)  0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 12, 12, 768)  0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 12, 12, 192)  576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 12, 12, 192)  0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 12, 12, 192)  258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 12, 12, 192)  576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 12, 12, 192)  0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 12, 12, 192)  258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 12, 12, 192)  576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 12, 12, 192)  576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 12, 12, 192)  0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 12, 12, 192)  0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 12, 12, 192)  258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 12, 12, 192)  258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 12, 12, 192)  576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 12, 12, 192)  576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 12, 12, 192)  0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 12, 12, 192)  0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 12, 12, 768)  0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 12, 12, 192)  258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 12, 12, 192)  258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 12, 12, 192)  576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 12, 12, 192)  576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 12, 12, 192)  576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 12, 12, 192)  576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 12, 12, 192)  0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 12, 12, 192)  0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 12, 12, 192)  0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 12, 12, 192)  0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 12, 12, 768)  0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 12, 12, 192)  576         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 12, 12, 192)  0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 12, 12, 192)  258048      activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 12, 12, 192)  576         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 12, 12, 192)  0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 12, 12, 192)  258048      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 12, 12, 192)  576         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 12, 12, 192)  576         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 12, 12, 192)  0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 12, 12, 192)  0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 5, 5, 320)    552960      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 5, 5, 192)    331776      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 5, 5, 320)    960         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 5, 5, 192)    576         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 5, 5, 320)    0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 5, 5, 192)    0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 5, 5, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 5, 5, 1280)   0           activation_71[0][0]              \n",
            "                                                                 activation_75[0][0]              \n",
            "                                                                 max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 5, 5, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 5, 5, 448)    1344        conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 5, 5, 448)    0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 5, 5, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 5, 5, 384)    1548288     activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 5, 5, 384)    1152        conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 5, 5, 384)    1152        conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 5, 5, 384)    0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 5, 5, 384)    0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 5, 5, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 5, 5, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 5, 5, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 5, 5, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 5, 5, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 5, 5, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 5, 5, 384)    1152        conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 5, 5, 384)    1152        conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 5, 5, 384)    1152        conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 5, 5, 384)    1152        conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 5, 5, 192)    245760      average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 5, 5, 320)    960         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 5, 5, 384)    0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 5, 5, 384)    0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 5, 5, 384)    0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 5, 5, 384)    0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 5, 5, 192)    576         conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 5, 5, 320)    0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 5, 5, 768)    0           activation_78[0][0]              \n",
            "                                                                 activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 5, 5, 768)    0           activation_82[0][0]              \n",
            "                                                                 activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 5, 5, 192)    0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 5, 5, 2048)   0           activation_76[0][0]              \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate[0][0]                \n",
            "                                                                 activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 5, 5, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 5, 5, 448)    1344        conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 5, 5, 448)    0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 5, 5, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 5, 5, 384)    1548288     activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 5, 5, 384)    1152        conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 5, 5, 384)    1152        conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 5, 5, 384)    0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 5, 5, 384)    0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 5, 5, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 5, 5, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 5, 5, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 5, 5, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, 5, 5, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 5, 5, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 5, 5, 384)    1152        conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 5, 5, 384)    1152        conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 5, 5, 384)    1152        conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 5, 5, 384)    1152        conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 5, 5, 192)    393216      average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 5, 5, 320)    960         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 5, 5, 384)    0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 5, 5, 384)    0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 5, 5, 384)    0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 5, 5, 384)    0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 5, 5, 192)    576         conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 5, 5, 320)    0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 5, 5, 768)    0           activation_87[0][0]              \n",
            "                                                                 activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 5, 5, 768)    0           activation_91[0][0]              \n",
            "                                                                 activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 5, 5, 192)    0           batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 5, 5, 2048)   0           activation_85[0][0]              \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_1[0][0]              \n",
            "                                                                 activation_93[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d (Globa (None, 2048)         0           mixed10[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 21,802,784\n",
            "Trainable params: 21,768,352\n",
            "Non-trainable params: 34,432\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xtk0zua6G5jC"
      },
      "source": [
        "#Extracting features using the pretrained convolutional base \r\n",
        "\r\n",
        "def extract_features(extractor, generator, sample_count, dim=2048):\r\n",
        "  features = np.zeros((sample_count, dim)) #extractor output shape \r\n",
        "  i = 0\r\n",
        "  for inputs_batch, labels_batch in generator:\r\n",
        "    print([np.where(r==1)[0][0] for r in labels_batch])\r\n",
        "    start = time.time()\r\n",
        "    features_batch = extractor.predict(inputs_batch)\r\n",
        "    print(f'predict = {time.time() - start}')\r\n",
        "    start = time.time()\r\n",
        "    if (i + 1) * BATCH_SIZE > sample_count:\r\n",
        "      features[i * BATCH_SIZE : sample_count , :] = features_batch\r\n",
        "    else:\r\n",
        "      features[i * BATCH_SIZE : (i + 1) * BATCH_SIZE, : ] = features_batch\r\n",
        "    i += 1\r\n",
        "    if i * BATCH_SIZE >= sample_count:\r\n",
        "      break\r\n",
        "    print(f'assign = {time.time() - start}')\r\n",
        "  \r\n",
        "  return features\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQvkN0w1L_Z0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac4fdf92-01ef-46ac-dcde-938eee963c68"
      },
      "source": [
        "sketches_features = extract_features(conv_base, sketches_generator, 20000)\n",
        "mirflickr_features = extract_features(conv_base, mirflickr_generator, 25000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]\n",
            "predict = 9.506867170333862\n",
            "assign = 0.0026226043701171875\n",
            "[6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12]\n",
            "predict = 1.1403400897979736\n",
            "assign = 0.002657175064086914\n",
            "[12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]\n",
            "predict = 1.1323919296264648\n",
            "assign = 0.0024569034576416016\n",
            "[19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25]\n",
            "predict = 1.1426787376403809\n",
            "assign = 0.0026702880859375\n",
            "[25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31]\n",
            "predict = 1.139359474182129\n",
            "assign = 0.002779245376586914\n",
            "[32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38]\n",
            "predict = 1.1311140060424805\n",
            "assign = 0.002514362335205078\n",
            "[38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44]\n",
            "predict = 1.157562494277954\n",
            "assign = 0.0025398731231689453\n",
            "[44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51]\n",
            "predict = 1.235109806060791\n",
            "assign = 0.0025005340576171875\n",
            "[51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57]\n",
            "predict = 1.1683290004730225\n",
            "assign = 0.0027687549591064453\n",
            "[57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63]\n",
            "predict = 1.1823508739471436\n",
            "assign = 0.002461671829223633\n",
            "[64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70]\n",
            "predict = 1.1831121444702148\n",
            "assign = 0.002528667449951172\n",
            "[70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76]\n",
            "predict = 1.1692688465118408\n",
            "assign = 0.0026776790618896484\n",
            "[76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83]\n",
            "predict = 1.1727514266967773\n",
            "assign = 0.002660036087036133\n",
            "[83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89]\n",
            "predict = 1.1552526950836182\n",
            "assign = 0.0025157928466796875\n",
            "[89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95]\n",
            "predict = 1.1849396228790283\n",
            "assign = 0.002516508102416992\n",
            "[96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]\n",
            "predict = 1.1743478775024414\n",
            "assign = 0.002600431442260742\n",
            "[102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108]\n",
            "predict = 1.2174944877624512\n",
            "assign = 0.002466440200805664\n",
            "[108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115]\n",
            "predict = 1.1852288246154785\n",
            "assign = 0.0025949478149414062\n",
            "[115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121]\n",
            "predict = 1.196470022201538\n",
            "assign = 0.0026595592498779297\n",
            "[121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127]\n",
            "predict = 1.2066247463226318\n",
            "assign = 0.0025463104248046875\n",
            "[128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134]\n",
            "predict = 1.1947054862976074\n",
            "assign = 0.0024857521057128906\n",
            "[134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140]\n",
            "predict = 1.185718297958374\n",
            "assign = 0.0025458335876464844\n",
            "[140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147]\n",
            "predict = 1.1804416179656982\n",
            "assign = 0.0025854110717773438\n",
            "[147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153]\n",
            "predict = 1.1744327545166016\n",
            "assign = 0.002397298812866211\n",
            "[153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159]\n",
            "predict = 1.144057035446167\n",
            "assign = 0.002503633499145508\n",
            "[160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166]\n",
            "predict = 1.17240571975708\n",
            "assign = 0.002467632293701172\n",
            "[166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 167, 167, 167, 167, 167, 167, 167, 167, 167, 167, 167, 167, 167, 167, 167, 167, 167, 167, 167, 167, 167, 167, 167, 167, 167, 167, 167, 167, 167, 167, 167, 167, 167, 167, 167, 167, 167, 167, 167, 167, 167, 167, 167, 167, 167, 167, 167, 167, 167, 167, 167, 167, 167, 167, 167, 167, 167, 167, 167, 167, 167, 167, 167, 167, 167, 167, 167, 167, 167, 167, 167, 167, 167, 167, 167, 167, 167, 167, 167, 167, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 170, 170, 170, 170, 170, 170, 170, 170, 170, 170, 170, 170, 170, 170, 170, 170, 170, 170, 170, 170, 170, 170, 170, 170, 170, 170, 170, 170, 170, 170, 170, 170, 170, 170, 170, 170, 170, 170, 170, 170, 170, 170, 170, 170, 170, 170, 170, 170, 170, 170, 170, 170, 170, 170, 170, 170, 170, 170, 170, 170, 170, 170, 170, 170, 170, 170, 170, 170, 170, 170, 170, 170, 170, 170, 170, 170, 170, 170, 170, 170, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 172, 172, 172, 172, 172, 172, 172, 172, 172, 172, 172, 172, 172, 172, 172, 172, 172, 172, 172, 172, 172, 172, 172, 172, 172, 172, 172, 172, 172, 172, 172, 172, 172, 172, 172, 172, 172, 172, 172, 172, 172, 172, 172, 172, 172, 172, 172, 172, 172, 172, 172, 172, 172, 172, 172, 172, 172, 172, 172, 172, 172, 172, 172, 172]\n",
            "predict = 1.1558914184570312\n",
            "assign = 0.0025343894958496094\n",
            "[172, 172, 172, 172, 172, 172, 172, 172, 172, 172, 172, 172, 172, 172, 172, 172, 173, 173, 173, 173, 173, 173, 173, 173, 173, 173, 173, 173, 173, 173, 173, 173, 173, 173, 173, 173, 173, 173, 173, 173, 173, 173, 173, 173, 173, 173, 173, 173, 173, 173, 173, 173, 173, 173, 173, 173, 173, 173, 173, 173, 173, 173, 173, 173, 173, 173, 173, 173, 173, 173, 173, 173, 173, 173, 173, 173, 173, 173, 173, 173, 173, 173, 173, 173, 173, 173, 173, 173, 173, 173, 173, 173, 173, 173, 173, 173, 174, 174, 174, 174, 174, 174, 174, 174, 174, 174, 174, 174, 174, 174, 174, 174, 174, 174, 174, 174, 174, 174, 174, 174, 174, 174, 174, 174, 174, 174, 174, 174, 174, 174, 174, 174, 174, 174, 174, 174, 174, 174, 174, 174, 174, 174, 174, 174, 174, 174, 174, 174, 174, 174, 174, 174, 174, 174, 174, 174, 174, 174, 174, 174, 174, 174, 174, 174, 174, 174, 174, 174, 174, 174, 174, 174, 174, 174, 174, 174, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 178, 178, 178, 178, 178, 178, 178, 178, 178, 178, 178, 178, 178, 178, 178, 178, 178, 178, 178, 178, 178, 178, 178, 178, 178, 178, 178, 178, 178, 178, 178, 178, 178, 178, 178, 178, 178, 178, 178, 178, 178, 178, 178, 178, 178, 178, 178, 178, 178, 178, 178, 178, 178, 178, 178, 178, 178, 178, 178, 178, 178, 178, 178, 178, 178, 178, 178, 178, 178, 178, 178, 178, 178, 178, 178, 178, 178, 178, 178, 178, 179, 179, 179, 179, 179, 179, 179, 179, 179, 179, 179, 179, 179, 179, 179, 179]\n",
            "predict = 1.1518502235412598\n",
            "assign = 0.0026826858520507812\n",
            "[179, 179, 179, 179, 179, 179, 179, 179, 179, 179, 179, 179, 179, 179, 179, 179, 179, 179, 179, 179, 179, 179, 179, 179, 179, 179, 179, 179, 179, 179, 179, 179, 179, 179, 179, 179, 179, 179, 179, 179, 179, 179, 179, 179, 179, 179, 179, 179, 179, 179, 179, 179, 179, 179, 179, 179, 179, 179, 179, 179, 179, 179, 179, 179, 180, 180, 180, 180, 180, 180, 180, 180, 180, 180, 180, 180, 180, 180, 180, 180, 180, 180, 180, 180, 180, 180, 180, 180, 180, 180, 180, 180, 180, 180, 180, 180, 180, 180, 180, 180, 180, 180, 180, 180, 180, 180, 180, 180, 180, 180, 180, 180, 180, 180, 180, 180, 180, 180, 180, 180, 180, 180, 180, 180, 180, 180, 180, 180, 180, 180, 180, 180, 180, 180, 180, 180, 180, 180, 180, 180, 180, 180, 180, 180, 181, 181, 181, 181, 181, 181, 181, 181, 181, 181, 181, 181, 181, 181, 181, 181, 181, 181, 181, 181, 181, 181, 181, 181, 181, 181, 181, 181, 181, 181, 181, 181, 181, 181, 181, 181, 181, 181, 181, 181, 181, 181, 181, 181, 181, 181, 181, 181, 181, 181, 181, 181, 181, 181, 181, 181, 181, 181, 181, 181, 181, 181, 181, 181, 181, 181, 181, 181, 181, 181, 181, 181, 181, 181, 181, 181, 181, 181, 181, 181, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 183, 183, 183, 183, 183, 183, 183, 183, 183, 183, 183, 183, 183, 183, 183, 183, 183, 183, 183, 183, 183, 183, 183, 183, 183, 183, 183, 183, 183, 183, 183, 183, 183, 183, 183, 183, 183, 183, 183, 183, 183, 183, 183, 183, 183, 183, 183, 183, 183, 183, 183, 183, 183, 183, 183, 183, 183, 183, 183, 183, 183, 183, 183, 183, 183, 183, 183, 183, 183, 183, 183, 183, 183, 183, 183, 183, 183, 183, 183, 183, 184, 184, 184, 184, 184, 184, 184, 184, 184, 184, 184, 184, 184, 184, 184, 184, 184, 184, 184, 184, 184, 184, 184, 184, 184, 184, 184, 184, 184, 184, 184, 184, 184, 184, 184, 184, 184, 184, 184, 184, 184, 184, 184, 184, 184, 184, 184, 184, 184, 184, 184, 184, 184, 184, 184, 184, 184, 184, 184, 184, 184, 184, 184, 184, 184, 184, 184, 184, 184, 184, 184, 184, 184, 184, 184, 184, 184, 184, 184, 184, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185]\n",
            "predict = 1.1803338527679443\n",
            "assign = 0.0026683807373046875\n",
            "[185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 187, 187, 187, 187, 187, 187, 187, 187, 187, 187, 187, 187, 187, 187, 187, 187, 187, 187, 187, 187, 187, 187, 187, 187, 187, 187, 187, 187, 187, 187, 187, 187, 187, 187, 187, 187, 187, 187, 187, 187, 187, 187, 187, 187, 187, 187, 187, 187, 187, 187, 187, 187, 187, 187, 187, 187, 187, 187, 187, 187, 187, 187, 187, 187, 187, 187, 187, 187, 187, 187, 187, 187, 187, 187, 187, 187, 187, 187, 187, 187, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 191, 191, 191, 191, 191, 191, 191, 191, 191, 191, 191, 191, 191, 191, 191, 191, 191, 191, 191, 191, 191, 191, 191, 191, 191, 191, 191, 191, 191, 191, 191, 191, 191, 191, 191, 191, 191, 191, 191, 191, 191, 191, 191, 191, 191, 191, 191, 191, 191, 191, 191, 191, 191, 191, 191, 191, 191, 191, 191, 191, 191, 191, 191, 191, 191, 191, 191, 191, 191, 191, 191, 191, 191, 191, 191, 191, 191, 191, 191, 191]\n",
            "predict = 1.1823217868804932\n",
            "assign = 0.0023756027221679688\n",
            "[192, 192, 192, 192, 192, 192, 192, 192, 192, 192, 192, 192, 192, 192, 192, 192, 192, 192, 192, 192, 192, 192, 192, 192, 192, 192, 192, 192, 192, 192, 192, 192, 192, 192, 192, 192, 192, 192, 192, 192, 192, 192, 192, 192, 192, 192, 192, 192, 192, 192, 192, 192, 192, 192, 192, 192, 192, 192, 192, 192, 192, 192, 192, 192, 192, 192, 192, 192, 192, 192, 192, 192, 192, 192, 192, 192, 192, 192, 192, 192, 193, 193, 193, 193, 193, 193, 193, 193, 193, 193, 193, 193, 193, 193, 193, 193, 193, 193, 193, 193, 193, 193, 193, 193, 193, 193, 193, 193, 193, 193, 193, 193, 193, 193, 193, 193, 193, 193, 193, 193, 193, 193, 193, 193, 193, 193, 193, 193, 193, 193, 193, 193, 193, 193, 193, 193, 193, 193, 193, 193, 193, 193, 193, 193, 193, 193, 193, 193, 193, 193, 193, 193, 193, 193, 193, 193, 193, 193, 193, 193, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 195, 195, 195, 195, 195, 195, 195, 195, 195, 195, 195, 195, 195, 195, 195, 195, 195, 195, 195, 195, 195, 195, 195, 195, 195, 195, 195, 195, 195, 195, 195, 195, 195, 195, 195, 195, 195, 195, 195, 195, 195, 195, 195, 195, 195, 195, 195, 195, 195, 195, 195, 195, 195, 195, 195, 195, 195, 195, 195, 195, 195, 195, 195, 195, 195, 195, 195, 195, 195, 195, 195, 195, 195, 195, 195, 195, 195, 195, 195, 195, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 197, 197, 197, 197, 197, 197, 197, 197, 197, 197, 197, 197, 197, 197, 197, 197, 197, 197, 197, 197, 197, 197, 197, 197, 197, 197, 197, 197, 197, 197, 197, 197, 197, 197, 197, 197, 197, 197, 197, 197, 197, 197, 197, 197, 197, 197, 197, 197, 197, 197, 197, 197, 197, 197, 197, 197, 197, 197, 197, 197, 197, 197, 197, 197, 197, 197, 197, 197, 197, 197, 197, 197, 197, 197, 197, 197, 197, 197, 197, 197, 198, 198, 198, 198, 198, 198, 198, 198, 198, 198, 198, 198, 198, 198, 198, 198, 198, 198, 198, 198, 198, 198, 198, 198, 198, 198, 198, 198, 198, 198, 198, 198]\n",
            "predict = 1.1743299961090088\n",
            "assign = 0.0026082992553710938\n",
            "[198, 198, 198, 198, 198, 198, 198, 198, 198, 198, 198, 198, 198, 198, 198, 198, 198, 198, 198, 198, 198, 198, 198, 198, 198, 198, 198, 198, 198, 198, 198, 198, 198, 198, 198, 198, 198, 198, 198, 198, 198, 198, 198, 198, 198, 198, 198, 198, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 204, 204, 204, 204, 204, 204, 204, 204, 204, 204, 204, 204, 204, 204, 204, 204, 204, 204, 204, 204, 204, 204, 204, 204, 204, 204, 204, 204, 204, 204, 204, 204, 204, 204, 204, 204, 204, 204, 204, 204, 204, 204, 204, 204, 204, 204, 204, 204, 204, 204, 204, 204, 204, 204, 204, 204, 204, 204, 204, 204, 204, 204, 204, 204]\n",
            "predict = 1.161959171295166\n",
            "assign = 0.002606630325317383\n",
            "[204, 204, 204, 204, 204, 204, 204, 204, 204, 204, 204, 204, 204, 204, 204, 204, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211]\n",
            "predict = 1.1445200443267822\n",
            "assign = 0.002699136734008789\n",
            "[211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 214, 214, 214, 214, 214, 214, 214, 214, 214, 214, 214, 214, 214, 214, 214, 214, 214, 214, 214, 214, 214, 214, 214, 214, 214, 214, 214, 214, 214, 214, 214, 214, 214, 214, 214, 214, 214, 214, 214, 214, 214, 214, 214, 214, 214, 214, 214, 214, 214, 214, 214, 214, 214, 214, 214, 214, 214, 214, 214, 214, 214, 214, 214, 214, 214, 214, 214, 214, 214, 214, 214, 214, 214, 214, 214, 214, 214, 214, 214, 214, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 216, 216, 216, 216, 216, 216, 216, 216, 216, 216, 216, 216, 216, 216, 216, 216, 216, 216, 216, 216, 216, 216, 216, 216, 216, 216, 216, 216, 216, 216, 216, 216, 216, 216, 216, 216, 216, 216, 216, 216, 216, 216, 216, 216, 216, 216, 216, 216, 216, 216, 216, 216, 216, 216, 216, 216, 216, 216, 216, 216, 216, 216, 216, 216, 216, 216, 216, 216, 216, 216, 216, 216, 216, 216, 216, 216, 216, 216, 216, 216, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217]\n",
            "predict = 1.1562387943267822\n",
            "assign = 0.002802610397338867\n",
            "[217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 221, 221, 221, 221, 221, 221, 221, 221, 221, 221, 221, 221, 221, 221, 221, 221, 221, 221, 221, 221, 221, 221, 221, 221, 221, 221, 221, 221, 221, 221, 221, 221, 221, 221, 221, 221, 221, 221, 221, 221, 221, 221, 221, 221, 221, 221, 221, 221, 221, 221, 221, 221, 221, 221, 221, 221, 221, 221, 221, 221, 221, 221, 221, 221, 221, 221, 221, 221, 221, 221, 221, 221, 221, 221, 221, 221, 221, 221, 221, 221, 222, 222, 222, 222, 222, 222, 222, 222, 222, 222, 222, 222, 222, 222, 222, 222, 222, 222, 222, 222, 222, 222, 222, 222, 222, 222, 222, 222, 222, 222, 222, 222, 222, 222, 222, 222, 222, 222, 222, 222, 222, 222, 222, 222, 222, 222, 222, 222, 222, 222, 222, 222, 222, 222, 222, 222, 222, 222, 222, 222, 222, 222, 222, 222, 222, 222, 222, 222, 222, 222, 222, 222, 222, 222, 222, 222, 222, 222, 222, 222, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223]\n",
            "predict = 1.164586067199707\n",
            "assign = 0.0025763511657714844\n",
            "[224, 224, 224, 224, 224, 224, 224, 224, 224, 224, 224, 224, 224, 224, 224, 224, 224, 224, 224, 224, 224, 224, 224, 224, 224, 224, 224, 224, 224, 224, 224, 224, 224, 224, 224, 224, 224, 224, 224, 224, 224, 224, 224, 224, 224, 224, 224, 224, 224, 224, 224, 224, 224, 224, 224, 224, 224, 224, 224, 224, 224, 224, 224, 224, 224, 224, 224, 224, 224, 224, 224, 224, 224, 224, 224, 224, 224, 224, 224, 224, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 227, 227, 227, 227, 227, 227, 227, 227, 227, 227, 227, 227, 227, 227, 227, 227, 227, 227, 227, 227, 227, 227, 227, 227, 227, 227, 227, 227, 227, 227, 227, 227, 227, 227, 227, 227, 227, 227, 227, 227, 227, 227, 227, 227, 227, 227, 227, 227, 227, 227, 227, 227, 227, 227, 227, 227, 227, 227, 227, 227, 227, 227, 227, 227, 227, 227, 227, 227, 227, 227, 227, 227, 227, 227, 227, 227, 227, 227, 227, 227, 228, 228, 228, 228, 228, 228, 228, 228, 228, 228, 228, 228, 228, 228, 228, 228, 228, 228, 228, 228, 228, 228, 228, 228, 228, 228, 228, 228, 228, 228, 228, 228, 228, 228, 228, 228, 228, 228, 228, 228, 228, 228, 228, 228, 228, 228, 228, 228, 228, 228, 228, 228, 228, 228, 228, 228, 228, 228, 228, 228, 228, 228, 228, 228, 228, 228, 228, 228, 228, 228, 228, 228, 228, 228, 228, 228, 228, 228, 228, 228, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 230, 230, 230, 230, 230, 230, 230, 230, 230, 230, 230, 230, 230, 230, 230, 230, 230, 230, 230, 230, 230, 230, 230, 230, 230, 230, 230, 230, 230, 230, 230, 230]\n",
            "predict = 1.1994280815124512\n",
            "assign = 0.002712726593017578\n",
            "[230, 230, 230, 230, 230, 230, 230, 230, 230, 230, 230, 230, 230, 230, 230, 230, 230, 230, 230, 230, 230, 230, 230, 230, 230, 230, 230, 230, 230, 230, 230, 230, 230, 230, 230, 230, 230, 230, 230, 230, 230, 230, 230, 230, 230, 230, 230, 230, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 233, 233, 233, 233, 233, 233, 233, 233, 233, 233, 233, 233, 233, 233, 233, 233, 233, 233, 233, 233, 233, 233, 233, 233, 233, 233, 233, 233, 233, 233, 233, 233, 233, 233, 233, 233, 233, 233, 233, 233, 233, 233, 233, 233, 233, 233, 233, 233, 233, 233, 233, 233, 233, 233, 233, 233, 233, 233, 233, 233, 233, 233, 233, 233, 233, 233, 233, 233, 233, 233, 233, 233, 233, 233, 233, 233, 233, 233, 233, 233, 234, 234, 234, 234, 234, 234, 234, 234, 234, 234, 234, 234, 234, 234, 234, 234, 234, 234, 234, 234, 234, 234, 234, 234, 234, 234, 234, 234, 234, 234, 234, 234, 234, 234, 234, 234, 234, 234, 234, 234, 234, 234, 234, 234, 234, 234, 234, 234, 234, 234, 234, 234, 234, 234, 234, 234, 234, 234, 234, 234, 234, 234, 234, 234, 234, 234, 234, 234, 234, 234, 234, 234, 234, 234, 234, 234, 234, 234, 234, 234, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 236, 236, 236, 236, 236, 236, 236, 236, 236, 236, 236, 236, 236, 236, 236, 236, 236, 236, 236, 236, 236, 236, 236, 236, 236, 236, 236, 236, 236, 236, 236, 236, 236, 236, 236, 236, 236, 236, 236, 236, 236, 236, 236, 236, 236, 236, 236, 236, 236, 236, 236, 236, 236, 236, 236, 236, 236, 236, 236, 236, 236, 236, 236, 236]\n",
            "predict = 1.1612920761108398\n",
            "assign = 0.002699613571166992\n",
            "[236, 236, 236, 236, 236, 236, 236, 236, 236, 236, 236, 236, 236, 236, 236, 236, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 239, 239, 239, 239, 239, 239, 239, 239, 239, 239, 239, 239, 239, 239, 239, 239, 239, 239, 239, 239, 239, 239, 239, 239, 239, 239, 239, 239, 239, 239, 239, 239, 239, 239, 239, 239, 239, 239, 239, 239, 239, 239, 239, 239, 239, 239, 239, 239, 239, 239, 239, 239, 239, 239, 239, 239, 239, 239, 239, 239, 239, 239, 239, 239, 239, 239, 239, 239, 239, 239, 239, 239, 239, 239, 239, 239, 239, 239, 239, 239, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 241, 241, 241, 241, 241, 241, 241, 241, 241, 241, 241, 241, 241, 241, 241, 241, 241, 241, 241, 241, 241, 241, 241, 241, 241, 241, 241, 241, 241, 241, 241, 241, 241, 241, 241, 241, 241, 241, 241, 241, 241, 241, 241, 241, 241, 241, 241, 241, 241, 241, 241, 241, 241, 241, 241, 241, 241, 241, 241, 241, 241, 241, 241, 241, 241, 241, 241, 241, 241, 241, 241, 241, 241, 241, 241, 241, 241, 241, 241, 241, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 243, 243, 243, 243, 243, 243, 243, 243, 243, 243, 243, 243, 243, 243, 243, 243]\n",
            "predict = 1.153322458267212\n",
            "assign = 0.002798318862915039\n",
            "[243, 243, 243, 243, 243, 243, 243, 243, 243, 243, 243, 243, 243, 243, 243, 243, 243, 243, 243, 243, 243, 243, 243, 243, 243, 243, 243, 243, 243, 243, 243, 243, 243, 243, 243, 243, 243, 243, 243, 243, 243, 243, 243, 243, 243, 243, 243, 243, 243, 243, 243, 243, 243, 243, 243, 243, 243, 243, 243, 243, 243, 243, 243, 243, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 246, 246, 246, 246, 246, 246, 246, 246, 246, 246, 246, 246, 246, 246, 246, 246, 246, 246, 246, 246, 246, 246, 246, 246, 246, 246, 246, 246, 246, 246, 246, 246, 246, 246, 246, 246, 246, 246, 246, 246, 246, 246, 246, 246, 246, 246, 246, 246, 246, 246, 246, 246, 246, 246, 246, 246, 246, 246, 246, 246, 246, 246, 246, 246, 246, 246, 246, 246, 246, 246, 246, 246, 246, 246, 246, 246, 246, 246, 246, 246, 247, 247, 247, 247, 247, 247, 247, 247, 247, 247, 247, 247, 247, 247, 247, 247, 247, 247, 247, 247, 247, 247, 247, 247, 247, 247, 247, 247, 247, 247, 247, 247, 247, 247, 247, 247, 247, 247, 247, 247, 247, 247, 247, 247, 247, 247, 247, 247, 247, 247, 247, 247, 247, 247, 247, 247, 247, 247, 247, 247, 247, 247, 247, 247, 247, 247, 247, 247, 247, 247, 247, 247, 247, 247, 247, 247, 247, 247, 247, 247, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249]\n",
            "predict = 1.1584436893463135\n",
            "assign = 0.002737760543823242\n",
            "[249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249]\n",
            "predict = 0.10161781311035156\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "predict = 1.202279806137085\n",
            "assign = 0.0011143684387207031\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "predict = 1.184981346130371\n",
            "assign = 0.001168966293334961\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "predict = 1.1743884086608887\n",
            "assign = 0.0010929107666015625\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "predict = 1.1571519374847412\n",
            "assign = 0.001035451889038086\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "predict = 1.2171461582183838\n",
            "assign = 0.001016378402709961\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "predict = 1.200240135192871\n",
            "assign = 0.0010528564453125\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "predict = 1.2005290985107422\n",
            "assign = 0.0010728836059570312\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "predict = 1.1799790859222412\n",
            "assign = 0.0009946823120117188\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "predict = 1.1700305938720703\n",
            "assign = 0.0011212825775146484\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "predict = 1.1819086074829102\n",
            "assign = 0.0010471343994140625\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "predict = 1.1853270530700684\n",
            "assign = 0.00103759765625\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "predict = 1.1668245792388916\n",
            "assign = 0.000997304916381836\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "predict = 1.192039966583252\n",
            "assign = 0.0010073184967041016\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "predict = 1.1778180599212646\n",
            "assign = 0.001024007797241211\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "predict = 1.2106878757476807\n",
            "assign = 0.0014798641204833984\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "predict = 1.4111049175262451\n",
            "assign = 0.001621246337890625\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "predict = 1.1784944534301758\n",
            "assign = 0.0015804767608642578\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "predict = 1.185945987701416\n",
            "assign = 0.0016567707061767578\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "predict = 1.1807832717895508\n",
            "assign = 0.0016064643859863281\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "predict = 1.1611840724945068\n",
            "assign = 0.0015597343444824219\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "predict = 1.2059814929962158\n",
            "assign = 0.0015354156494140625\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "predict = 1.1889266967773438\n",
            "assign = 0.00156402587890625\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "predict = 1.1717143058776855\n",
            "assign = 0.0015876293182373047\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "predict = 1.1862132549285889\n",
            "assign = 0.0016977787017822266\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "predict = 1.2362680435180664\n",
            "assign = 0.001661539077758789\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "predict = 1.1980071067810059\n",
            "assign = 0.0017473697662353516\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "predict = 1.2066919803619385\n",
            "assign = 0.001806020736694336\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "predict = 1.188302755355835\n",
            "assign = 0.0018544197082519531\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "predict = 1.1684534549713135\n",
            "assign = 0.0018463134765625\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "predict = 1.197413682937622\n",
            "assign = 0.0016350746154785156\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "predict = 1.1909024715423584\n",
            "assign = 0.0019001960754394531\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "predict = 1.1803998947143555\n",
            "assign = 0.0017595291137695312\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "predict = 1.1759698390960693\n",
            "assign = 0.0017998218536376953\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "predict = 1.2194128036499023\n",
            "assign = 0.001687765121459961\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "predict = 1.1744961738586426\n",
            "assign = 0.001722097396850586\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "predict = 1.203552484512329\n",
            "assign = 0.001903533935546875\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "predict = 1.186103105545044\n",
            "assign = 0.0017418861389160156\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "predict = 1.1931300163269043\n",
            "assign = 0.0017082691192626953\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "predict = 1.206472396850586\n",
            "assign = 0.0017774105072021484\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "predict = 1.2051045894622803\n",
            "assign = 0.0018231868743896484\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "predict = 1.1628406047821045\n",
            "assign = 0.001802682876586914\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "predict = 1.1727819442749023\n",
            "assign = 0.00167083740234375\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "predict = 1.1720013618469238\n",
            "assign = 0.0017728805541992188\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "predict = 1.2205147743225098\n",
            "assign = 0.0017075538635253906\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "predict = 1.2017624378204346\n",
            "assign = 0.0017650127410888672\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "predict = 1.1963770389556885\n",
            "assign = 0.001734018325805664\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "predict = 1.2001376152038574\n",
            "assign = 0.001720428466796875\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "predict = 1.1728122234344482\n",
            "assign = 0.0018353462219238281\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "predict = 2.4031574726104736\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XeiCXhElMwKi",
        "outputId": "84372316-bf4e-4afb-8fda-8c0ebb21970f"
      },
      "source": [
        "print(sketches_features.shape)\r\n",
        "print(mirflickr_features.shape)\r\n",
        "print(sketches_features[0])\r\n",
        "print()\r\n",
        "print(mirflickr_features[0])\r\n",
        "print(sketches_features[0].nbytes)\r\n",
        "print(mirflickr_features[0].nbytes)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(20000, 2048)\n",
            "(25000, 2048)\n",
            "[0.78158373 0.3547062  0.07907477 ... 0.14706215 0.         0.37109551]\n",
            "\n",
            "[1.41843808 0.78591108 0.9991073  ... 1.24422574 1.79479325 0.25287843]\n",
            "16384\n",
            "16384\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-Tfn19PCjyW",
        "outputId": "54a15509-4e04-4232-abea-a2dc5420b000"
      },
      "source": [
        "sketches_features[0,0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7815837264060974"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAeL8Lxenn8J"
      },
      "source": [
        "all_features = np.vstack((sketches_features, mirflickr_features))\n",
        "lsh_base = LSH(feature_dim = all_features[0].shape[0], g=5, h=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GVZfJNInwaD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35c3e4d1-6945-432d-82cb-c5fc35c276e9"
      },
      "source": [
        "lsh_base.insert(np.vstack((sketches_features, mirflickr_features)), \n",
        "                np.concatenate((sketches_generator.filenames, mirflickr_generator.filenames)), \n",
        "                np.concatenate((sketches_generator.labels, np.array([250] * mirflickr_features.shape[0]))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hash calculated\n",
            "(5, 45000, 1)\n",
            "join 2.956390380859375e-05\n",
            "not in bucket 7.128715515136719e-05\n",
            "join 2.384185791015625e-06\n",
            "checking duplicates 9.870529174804688e-05\n",
            "stacking 0.00013065338134765625\n",
            "join 2.384185791015625e-06\n",
            "checking duplicates 9.465217590332031e-05\n",
            "stacking 0.00012946128845214844\n",
            "join 2.384185791015625e-06\n",
            "checking duplicates 0.0001266002655029297\n",
            "stacking 0.0001590251922607422\n",
            "join 2.384185791015625e-06\n",
            "checking duplicates 0.0001220703125\n",
            "stacking 0.00015211105346679688\n",
            "inner for time: 1.1818130016326904\n",
            "join 2.384185791015625e-06\n",
            "checking duplicates 0.00014138221740722656\n",
            "stacking 0.00017333030700683594\n",
            "join 3.337860107421875e-06\n",
            "checking duplicates 0.0002701282501220703\n",
            "stacking 0.0009310245513916016\n",
            "join 3.337860107421875e-06\n",
            "checking duplicates 0.00019502639770507812\n",
            "stacking 0.000255584716796875\n",
            "join 4.291534423828125e-06\n",
            "checking duplicates 0.0002999305725097656\n",
            "stacking 0.0003619194030761719\n",
            "inner for time: 3.327036142349243\n",
            "join 3.0994415283203125e-06\n",
            "checking duplicates 0.00018668174743652344\n",
            "stacking 0.0002288818359375\n",
            "join 3.337860107421875e-06\n",
            "checking duplicates 0.0001976490020751953\n",
            "stacking 0.0002465248107910156\n",
            "join 3.814697265625e-06\n",
            "checking duplicates 0.00030684471130371094\n",
            "stacking 0.00038051605224609375\n",
            "join 9.059906005859375e-06\n",
            "checking duplicates 0.0002071857452392578\n",
            "stacking 0.00024700164794921875\n",
            "inner for time: 4.85360312461853\n",
            "join 4.76837158203125e-06\n",
            "checking duplicates 0.00026798248291015625\n",
            "stacking 0.0008714199066162109\n",
            "join 3.0994415283203125e-06\n",
            "join 4.76837158203125e-06\n",
            "checking duplicates 0.00021076202392578125\n",
            "stacking 0.0002803802490234375\n",
            "join 3.337860107421875e-06\n",
            "checking duplicates 0.0002300739288330078\n",
            "stacking 0.0002765655517578125\n",
            "join 4.76837158203125e-06\n",
            "checking duplicates 0.0002982616424560547\n",
            "stacking 0.0003676414489746094\n",
            "inner for time: 5.768576145172119\n",
            "join 3.0994415283203125e-06\n",
            "checking duplicates 0.00037384033203125\n",
            "stacking 0.0004482269287109375\n",
            "join 4.76837158203125e-06\n",
            "checking duplicates 0.00047469139099121094\n",
            "stacking 0.0005655288696289062\n",
            "join 4.76837158203125e-06\n",
            "join 4.0531158447265625e-06\n",
            "checking duplicates 0.0002372264862060547\n",
            "stacking 0.0003483295440673828\n",
            "join 5.4836273193359375e-06\n",
            "checking duplicates 0.00048804283142089844\n",
            "stacking 0.0005743503570556641\n",
            "inner for time: 7.382158279418945\n",
            "(8152, 2048)\n",
            "(10839, 2048)\n",
            "(11558, 2048)\n",
            "(9817, 2048)\n",
            "(10807, 2048)\n",
            "(11328, 2048)\n",
            "(9869, 2048)\n",
            "(9165, 2048)\n",
            "(8253, 2048)\n",
            "(6985, 2048)\n",
            "(20088, 2048)\n",
            "(5983, 2048)\n",
            "(11777, 2048)\n",
            "(4839, 2048)\n",
            "(7081, 2048)\n",
            "(6180, 2048)\n",
            "(9342, 2048)\n",
            "(2890, 2048)\n",
            "(3911, 2048)\n",
            "(1173, 2048)\n",
            "(3675, 2048)\n",
            "(2268, 2048)\n",
            "(5385, 2048)\n",
            "(899, 2048)\n",
            "(1627, 2048)\n",
            "(4429, 2048)\n",
            "(3114, 2048)\n",
            "(87, 2048)\n",
            "(585, 2048)\n",
            "(587, 2048)\n",
            "(1330, 2048)\n",
            "(1076, 2048)\n",
            "(2035, 2048)\n",
            "(2481, 2048)\n",
            "(292, 2048)\n",
            "(1558, 2048)\n",
            "(406, 2048)\n",
            "(483, 2048)\n",
            "(258, 2048)\n",
            "(192, 2048)\n",
            "(793, 2048)\n",
            "(158, 2048)\n",
            "(187, 2048)\n",
            "(24, 2048)\n",
            "(347, 2048)\n",
            "(3, 2048)\n",
            "(15, 2048)\n",
            "(48, 2048)\n",
            "(120, 2048)\n",
            "(69, 2048)\n",
            "(27, 2048)\n",
            "(40, 2048)\n",
            "(36, 2048)\n",
            "(74, 2048)\n",
            "(10, 2048)\n",
            "(124, 2048)\n",
            "(8, 2048)\n",
            "(6, 2048)\n",
            "(1, 2048)\n",
            "(9, 2048)\n",
            "(1, 2048)\n",
            "(1, 2048)\n",
            "(11, 2048)\n",
            "(24, 2048)\n",
            "(8, 2048)\n",
            "(1, 2048)\n",
            "(8, 2048)\n",
            "(2, 2048)\n",
            "(3, 2048)\n",
            "(4, 2048)\n",
            "(3, 2048)\n",
            "(1, 2048)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mW1c07xUq_sm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a226877d-59b6-4171-ce66-4ab267e5904c"
      },
      "source": [
        "start = time.time()\n",
        "query_result_ed = lsh_base.query(sketches_features[0], 80, return_cost = True)\n",
        "end = time.time()\n",
        "print(f'query time {end - start}')\n",
        "query_result_sim = lsh_base.query(sketches_features[0], 80, mode='similarity', return_cost = True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7\n",
            "dist shape (8152,) and dist size 8152\n",
            "6\n",
            "dist shape (9154,) and dist size 9154\n",
            "-8\n",
            "dist shape (4421,) and dist size 4421\n",
            "-9\n",
            "dist shape (3667,) and dist size 3667\n",
            "7\n",
            "dist shape (8120,) and dist size 8120\n",
            "query time 0.43428802490234375\n",
            "7\n",
            "sim shape (8152,) and sim size 8152\n",
            "6\n",
            "sim shape (9144,) and sim size 9144\n",
            "-8\n",
            "sim shape (4421,) and sim size 4421\n",
            "-9\n",
            "sim shape (3668,) and sim size 3668\n",
            "7\n",
            "sim shape (8112,) and sim size 8112\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Q0R3jn23MNv",
        "outputId": "a89a9496-f45b-4748-9f91-d54057ed9b0f"
      },
      "source": [
        "print(query_result_ed)\n",
        "print(query_result_sim)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "({'ids': array(['airplane/1.png', 'ship/14915.png', 'bread/2460.png',\n",
            "       'airplane/74.png', 'lighter/9805.png', 'tablelamp/17327.png',\n",
            "       'cake/3105.png', 'sea turtle/14569.png', 'arm/414.png',\n",
            "       'hat/8058.png', 'tractor/18352.png', 'tractor/18388.png',\n",
            "       'bulldozer/2614.png', 'shark/14786.png', 'floor lamp/6735.png',\n",
            "       'mouth/10909.png', 'blimp/1892.png', 'squirrel/16217.png',\n",
            "       'head-phones/8235.png', 'bee/1413.png', 'ship/14959.png',\n",
            "       'airplane/12.png', 'bulldozer/2628.png', 'couch/4673.png',\n",
            "       'sheep/14828.png', 'trombone/18690.png', 'shark/14744.png',\n",
            "       'mouth/10881.png', 'snowboard/15538.png', 'parrot/11814.png',\n",
            "       'hot-dog/8661.png', 'suitcase/16698.png', 'sea turtle/14582.png',\n",
            "       'tree/18608.png', 'santa claus/14013.png', 'tractor/18397.png',\n",
            "       'parrot/11828.png', 'bee/1369.png', 'truck/18848.png',\n",
            "       'couch/4671.png', 'giraffe/7437.png', 'hamburger/7717.png',\n",
            "       'sailboat/13940.png', 'mouse (animal)/10803.png',\n",
            "       'pineapple/12581.png', 'shark/14775.png',\n",
            "       'computer-mouse/4564.png', 'windmill/19609.png',\n",
            "       'rabbit/13340.png', 'hamburger/7725.png', 'blimp/1895.png',\n",
            "       'shark/14790.png', 'seagull/14647.png', 'mouse (animal)/10839.png',\n",
            "       'bulldozer/2624.png', 'purse/13213.png', 'trombone/18662.png',\n",
            "       'seagull/14670.png', 'rabbit/13302.png', 'shoe/15031.png',\n",
            "       'airplane/30.png', 'eyeglasses/6196.png', 'sea turtle/14570.png',\n",
            "       'mushroom/11060.png', 'blimp/1917.png', 'penguin/12068.png',\n",
            "       'hat/8003.png', 'elephant/5949.png', 'armchair/511.png',\n",
            "       'stapler/16372.png', 'tablelamp/17307.png', 'squirrel/16176.png',\n",
            "       'zebra/19956.png', 'pumpkin/13144.png', 'car (sedan)/3606.png',\n",
            "       'truck/18831.png', 'trombone/18670.png', 'human-skeleton/8945.png',\n",
            "       'rabbit/13304.png', 'elephant/5995.png'], dtype='<U28'), 'labels': array([  0, 186,  30,   0, 122, 216,  38, 182,   5, 100, 229, 229,  32,\n",
            "       184,  84, 136,  23, 202, 102,  17, 186,   0,  32,  58, 185, 233,\n",
            "       184, 136, 194, 147, 108, 208, 182, 232, 175, 229, 147,  17, 235,\n",
            "        58,  92,  96, 174, 135, 157, 184,  57, 245, 166,  96,  23, 184,\n",
            "       183, 135,  32, 165, 233, 183, 166, 187,   0,  77, 182, 138,  23,\n",
            "       150, 100,  74,   6, 204, 216, 202, 249, 164,  45, 235, 233, 111,\n",
            "       166,  74]), 'distances': array([ 0.        , 19.15990317, 19.31599062, 19.47388896, 19.49892444,\n",
            "       19.50221171, 19.65230779, 19.85123579, 19.89757541, 19.90490339,\n",
            "       19.94341083, 20.01811228, 20.02381243, 20.0411698 , 20.11423262,\n",
            "       20.13232336, 20.13578557, 20.15375162, 20.17899963, 20.20874643,\n",
            "       20.23737354, 20.23802286, 20.24162041, 20.29597263, 20.340529  ,\n",
            "       20.34878725, 20.35306399, 20.36233594, 20.3801118 , 20.39358715,\n",
            "       20.39549139, 20.41409849, 20.41794043, 20.42763727, 20.43506502,\n",
            "       20.43900637, 20.44912658, 20.46213644, 20.47303746, 20.48165592,\n",
            "       20.4862033 , 20.49078829, 20.54152394, 20.54286076, 20.54865321,\n",
            "       20.55721148, 20.56247282, 20.57660632, 20.57854508, 20.59293583,\n",
            "       20.59554269, 20.60058417, 20.61865669, 20.6304302 , 20.63060738,\n",
            "       20.63066663, 20.63107556, 20.63109305, 20.6387152 , 20.66987158,\n",
            "       20.68085301, 20.68869062, 20.69142883, 20.69942925, 20.70151849,\n",
            "       20.70723452, 20.71000455, 20.71450947, 20.7176168 , 20.72116776,\n",
            "       20.74063768, 20.75020842, 20.76087549, 20.76442056, 20.76754863,\n",
            "       20.77758227, 20.78117469, 20.79327008, 20.80065319, 20.80607061])}, 33514)\n",
            "({'ids': array(['airplane/1.png', 'rollerblades/13801.png', 'airplane/54.png',\n",
            "       'bread/2460.png', 'sailboat/13932.png', 'airplane/12.png',\n",
            "       'airplane/74.png', 'lighter/9805.png', 'ship/14915.png',\n",
            "       'armchair/511.png', 'envelope/6034.png', 'axe/683.png',\n",
            "       'tablelamp/17327.png', 'leaf/9629.png', 'piano/12314.png',\n",
            "       'microphone/10330.png', 'hat/8058.png', 'bee/1413.png',\n",
            "       'toilet/18038.png', 'bell/1535.png', 'streetlight/16557.png',\n",
            "       'tv/18979.png', 'bed/1319.png', 'cake/3105.png',\n",
            "       'wheelbarrow/19558.png', 'shark/14775.png', 'floor lamp/6735.png',\n",
            "       'mouth/10881.png', 'axe/667.png', 'satellite/14136.png',\n",
            "       'radio/13483.png', 'arm/414.png', 'canoe/3548.png', 'tv/19011.png',\n",
            "       'airplane/76.png', 'crane (machine)/4927.png', 'airplane/44.png',\n",
            "       'sea turtle/14569.png', 'tv/18993.png', 'sponge bob/16023.png',\n",
            "       'shark/14744.png', 'hammer/7813.png', 'speed-boat/15884.png',\n",
            "       'mouse (animal)/10803.png', 'microphone/10347.png',\n",
            "       'flying saucer/7036.png', 'beer-mug/1476.png', 'mouth/10909.png',\n",
            "       'helmet/8410.png', 'parking meter/11751.png', 'arm/416.png',\n",
            "       'giraffe/7437.png', 'stapler/16372.png', 'bulldozer/2628.png',\n",
            "       'sailboat/13926.png', 'hat/8034.png', 'wheelbarrow/19539.png',\n",
            "       'shoe/15028.png', 'blimp/1892.png', 'tractor/18388.png',\n",
            "       'candle/3377.png', 'mailbox/10146.png', 'dolphin/5402.png',\n",
            "       'shark/14739.png', 'tractor/18352.png', 'sailboat/13940.png',\n",
            "       'lighter/9822.png', 'socks/15719.png', 'snowboard/15538.png',\n",
            "       'couch/4671.png', 'laptop/9581.png', 'ashtray/629.png',\n",
            "       'parking meter/11698.png', 'tablelamp/17307.png',\n",
            "       'tablelamp/17281.png', 'hat/8053.png', 'motorbike/10744.png',\n",
            "       'church/4166.png', 'trousers/18782.png', 'sailboat/13971.png'],\n",
            "      dtype='<U28'), 'labels': array([  0, 172,   0,  30, 174,   0,   0, 122, 186,   6,  75,   8, 216,\n",
            "       120, 153, 129, 100,  17, 225,  19, 206, 237,  16,  38, 244, 184,\n",
            "        84, 136,   8, 176, 168,   5,  44, 237,   0,  61,   0, 182, 237,\n",
            "       200, 184,  97, 198, 135, 129,  87,  18, 136, 105, 146,   5,  92,\n",
            "       204,  32, 174, 100, 244, 187,  23, 229,  42, 126,  67, 184, 229,\n",
            "       174, 122, 196, 194,  58, 119,   7, 146, 216, 216, 100, 134,  52,\n",
            "       234, 174]), 'similarities': array([1.        , 0.75982625, 0.74830077, 0.74468636, 0.74191745,\n",
            "       0.7418463 , 0.74056391, 0.73956039, 0.73744339, 0.73594225,\n",
            "       0.73563071, 0.73515421, 0.73438005, 0.73346137, 0.73309499,\n",
            "       0.73277041, 0.7305194 , 0.7293647 , 0.72852144, 0.72793627,\n",
            "       0.72780332, 0.72756585, 0.72723955, 0.72593951, 0.72506595,\n",
            "       0.72441884, 0.72414853, 0.72348169, 0.7226945 , 0.72267116,\n",
            "       0.72260764, 0.72238924, 0.72205192, 0.72189185, 0.7216424 ,\n",
            "       0.72158557, 0.72149357, 0.72099982, 0.72064437, 0.72025775,\n",
            "       0.72019285, 0.71942546, 0.71941529, 0.71857987, 0.71857198,\n",
            "       0.71852002, 0.71832739, 0.71830551, 0.71811156, 0.71768855,\n",
            "       0.71762157, 0.71737107, 0.71730335, 0.71696504, 0.71687833,\n",
            "       0.71647807, 0.71612801, 0.7160638 , 0.71576398, 0.71531179,\n",
            "       0.71504199, 0.71444997, 0.7144453 , 0.7143696 , 0.71423467,\n",
            "       0.71388606, 0.71373601, 0.71353128, 0.71317828, 0.71297803,\n",
            "       0.71250749, 0.71247276, 0.71239227, 0.71222993, 0.71206036,\n",
            "       0.71201258, 0.71196089, 0.71132322, 0.71123573, 0.71117234])}, 33497)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7AT_iXmeFIK",
        "outputId": "c08acd6e-7197-4fe0-af28-66c1478966b8"
      },
      "source": [
        "no_index_base = NO_INDEX()\r\n",
        "no_index_base.insert(np.vstack((sketches_features, mirflickr_features)), \r\n",
        "                np.concatenate((sketches_generator.filenames, mirflickr_generator.filenames)), \r\n",
        "                np.concatenate((sketches_generator.labels, np.array([250] * mirflickr_features.shape[0]))))\r\n",
        "start = time.time()\r\n",
        "query_result_ed_no_index = no_index_base.query(sketches_features[0], 80, return_cost = True)\r\n",
        "end = time.time()\r\n",
        "print(f'query time {end - start}')\r\n",
        "query_result_sim_no_index = no_index_base.query(sketches_features[0], 80, mode='similarity', return_cost = True)\r\n",
        "print(query_result_ed_no_index)\r\n",
        "print(query_result_sim_no_index)\r\n",
        "print(query_result_sim_no_index[0]['ids'].shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "query time 1.7094576358795166\n",
            "45000\n",
            "({'ids': array(['airplane/1.png', 'airplane/49.png', 'ship/14915.png',\n",
            "       'bread/2460.png', 'wheelbarrow/19552.png', 'airplane/74.png',\n",
            "       'lighter/9805.png', 'tablelamp/17327.png', 'cake/3105.png',\n",
            "       'hamburger/7709.png', 'arm/440.png', 'sea turtle/14569.png',\n",
            "       'arm/414.png', 'hat/8058.png', 'tractor/18352.png',\n",
            "       'submarine/16594.png', 'crown/5049.png', 'tractor/18388.png',\n",
            "       'leaf/9608.png', 'bulldozer/2614.png', 'shark/14786.png',\n",
            "       'helicopter/8382.png', 'flying saucer/7001.png',\n",
            "       'floor lamp/6735.png', 'mouth/10909.png', 'blimp/1892.png',\n",
            "       'pumpkin/13191.png', 'squirrel/16217.png', 'head-phones/8235.png',\n",
            "       'rainbow/13543.png', 'tv/19008.png', 'rollerblades/13803.png',\n",
            "       'bee/1413.png', 'ship/14959.png', 'airplane/12.png',\n",
            "       'bulldozer/2628.png', 'rainbow/13553.png', 'couch/4673.png',\n",
            "       'sheep/14828.png', 'trombone/18690.png', 'shark/14744.png',\n",
            "       'mouth/10881.png', 'arm/441.png', 'snowboard/15538.png',\n",
            "       'arm/443.png', 'bus/2680.png', 'parrot/11814.png',\n",
            "       'hot-dog/8661.png', 'speed-boat/15906.png', 'suitcase/16698.png',\n",
            "       'sea turtle/14582.png', 'tree/18608.png', 'santa claus/14013.png',\n",
            "       'tractor/18397.png', 'flashlight/6681.png', 'sheep/14831.png',\n",
            "       'parrot/11828.png', 'bee/1369.png', 'fish/6635.png',\n",
            "       'microscope/10452.png', 'truck/18848.png', 'ship/14884.png',\n",
            "       'couch/4671.png', 'giraffe/7437.png', 'hamburger/7700.png',\n",
            "       'hamburger/7717.png', 'hat/8038.png', 'monkey/10551.png',\n",
            "       'tractor/18361.png', 'pumpkin/13189.png', 'sailboat/13940.png',\n",
            "       'mouse (animal)/10803.png', 'guitar/7638.png',\n",
            "       'pineapple/12581.png', 'bulldozer/2629.png',\n",
            "       'standing bird/16276.png', 'shark/14775.png',\n",
            "       'computer-mouse/4564.png', 'blimp/1888.png', 'windmill/19609.png'],\n",
            "      dtype='<U28'), 'labels': array([  0,   0, 186,  30, 244,   0, 122, 216,  38,  96,   5, 182,   5,\n",
            "       100, 229, 207,  63, 229, 120,  32, 184, 104,  87,  84, 136,  23,\n",
            "       164, 202, 102, 169, 237, 172,  17, 186,   0,  32, 169,  58, 185,\n",
            "       233, 184, 136,   5, 194,   5,  33, 147, 108, 198, 208, 182, 232,\n",
            "       175, 229,  83, 185, 147,  17,  82, 130, 235, 186,  58,  92,  96,\n",
            "        96, 100, 131, 229, 164, 174, 135,  95, 157,  32, 203, 184,  57,\n",
            "        23, 245]), 'distances': array([ 0.        , 18.58403523, 19.15990317, 19.31599062, 19.41853398,\n",
            "       19.47388896, 19.49892444, 19.50221171, 19.65230779, 19.7686245 ,\n",
            "       19.82056657, 19.85123579, 19.89757541, 19.90490339, 19.94341083,\n",
            "       19.94740582, 19.99947007, 20.01811228, 20.02192403, 20.02381243,\n",
            "       20.0411698 , 20.07822896, 20.11230383, 20.11423262, 20.13232336,\n",
            "       20.13578557, 20.14476722, 20.15375162, 20.17899963, 20.19041596,\n",
            "       20.19285122, 20.20811667, 20.20874643, 20.23737354, 20.23802286,\n",
            "       20.24162041, 20.28694577, 20.29597263, 20.340529  , 20.34878725,\n",
            "       20.35306399, 20.36233594, 20.37380912, 20.3801118 , 20.38624793,\n",
            "       20.3882839 , 20.39358715, 20.39549139, 20.39748215, 20.41409849,\n",
            "       20.41794043, 20.42763727, 20.43506502, 20.43900637, 20.43963742,\n",
            "       20.44883195, 20.44912658, 20.46213644, 20.46423658, 20.46553031,\n",
            "       20.47303746, 20.47748605, 20.48165592, 20.4862033 , 20.48958581,\n",
            "       20.49078829, 20.49512887, 20.51095088, 20.51760413, 20.52592091,\n",
            "       20.54152394, 20.54286076, 20.54666089, 20.54865321, 20.55127409,\n",
            "       20.55143216, 20.55721148, 20.56247282, 20.57507679, 20.57660632])}, 45000)\n",
            "({'ids': array(['airplane/1.png', 'airplane/49.png', 'rollerblades/13801.png',\n",
            "       'submarine/16594.png', 'submarine/16577.png', 'airplane/54.png',\n",
            "       'bread/2460.png', 'sailboat/13932.png', 'airplane/12.png',\n",
            "       'airplane/74.png', 'lighter/9805.png', 'ship/14915.png',\n",
            "       'armchair/511.png', 'envelope/6034.png', 'axe/683.png',\n",
            "       'crown/5049.png', 'tablelamp/17327.png', 'potted plant/12815.png',\n",
            "       'leaf/9629.png', 'piano/12314.png', 'microphone/10330.png',\n",
            "       'flying bird/6891.png', 'streetlight/16498.png', 'shoe/14985.png',\n",
            "       'hat/8058.png', 'flying saucer/7000.png', 'wheelbarrow/19552.png',\n",
            "       'tablelamp/17299.png', 'shoe/14989.png', 'bee/1413.png',\n",
            "       'paper clip/11600.png', 'toilet/18038.png', 'pear/11891.png',\n",
            "       'arm/441.png', 'fan/6396.png', 'space shuttle/15832.png',\n",
            "       'bell/1535.png', 'streetlight/16557.png', 'tv/18979.png',\n",
            "       'mailbox/10143.png', 'bed/1319.png', 'shoe/14968.png',\n",
            "       'arm/443.png', 'sailboat/14000.png', 'cake/3105.png',\n",
            "       'flashlight/6681.png', 'computer-mouse/4594.png',\n",
            "       'wheelbarrow/19558.png', 'shark/14775.png', 'tooth/18180.png',\n",
            "       'floor lamp/6735.png', 'axe/680.png', 't-shirt/17180.png',\n",
            "       'mouth/10881.png', 'cell phone/3932.png', 'axe/667.png',\n",
            "       'satellite/14136.png', 'radio/13483.png', 'arm/414.png',\n",
            "       'bell/1549.png', 'canoe/3548.png', 'tv/19011.png',\n",
            "       'scissors/14393.png', 'rollerblades/13778.png', 'airplane/76.png',\n",
            "       'crane (machine)/4927.png', 'airplane/44.png',\n",
            "       'wheelbarrow/19528.png', 'mug/10982.png', 'sea turtle/14569.png',\n",
            "       'helicopter/8382.png', 'canoe/3582.png', 'tv/18993.png',\n",
            "       'sponge bob/16023.png', 'shark/14744.png', 't-shirt/17145.png',\n",
            "       'hammer/7813.png', 'speed-boat/15884.png', 'shark/14738.png',\n",
            "       'arm/440.png'], dtype='<U28'), 'labels': array([  0,   0, 172, 207, 207,   0,  30, 174,   0,   0, 122, 186,   6,\n",
            "        75,   8,  63, 216, 160, 120, 153, 129,  86, 206, 187, 100,  87,\n",
            "       244, 216, 187,  17, 144, 225, 148,   5,  79, 197,  19, 206, 237,\n",
            "       126,  16, 187,   5, 174,  38,  83,  57, 244, 184, 227,  84,   8,\n",
            "       214, 136,  49,   8, 176, 168,   5,  19,  44, 237, 179, 172,   0,\n",
            "        61,   0, 244, 137, 182, 104,  44, 237, 200, 184, 214,  97, 198,\n",
            "       184,   5]), 'similarities': array([1.        , 0.78619141, 0.75982625, 0.75871622, 0.75547825,\n",
            "       0.74830077, 0.74468636, 0.74191745, 0.7418463 , 0.74056391,\n",
            "       0.73956039, 0.73744339, 0.73594225, 0.73563071, 0.73515421,\n",
            "       0.73477283, 0.73438005, 0.73366662, 0.73346137, 0.73309499,\n",
            "       0.73277041, 0.73241389, 0.73165337, 0.73163353, 0.7305194 ,\n",
            "       0.73051919, 0.73035468, 0.73007564, 0.72951436, 0.7293647 ,\n",
            "       0.72855491, 0.72852144, 0.72831162, 0.72817808, 0.72805891,\n",
            "       0.72798992, 0.72793627, 0.72780332, 0.72756585, 0.72755895,\n",
            "       0.72723955, 0.72660115, 0.72616825, 0.72605372, 0.72593951,\n",
            "       0.7257788 , 0.72554746, 0.72506595, 0.72441884, 0.72418815,\n",
            "       0.72414853, 0.72363894, 0.72351262, 0.72348169, 0.72280088,\n",
            "       0.7226945 , 0.72267116, 0.72260764, 0.72238924, 0.72214399,\n",
            "       0.72205192, 0.72189185, 0.72172917, 0.72170076, 0.7216424 ,\n",
            "       0.72158557, 0.72149357, 0.72135349, 0.72132871, 0.72099982,\n",
            "       0.72086811, 0.72083435, 0.72064437, 0.72025775, 0.72019285,\n",
            "       0.71978031, 0.71942546, 0.71941529, 0.71889768, 0.71867197])}, 45000)\n",
            "(80,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q73P_SRRfuqc",
        "outputId": "76d41b5e-9cac-4e8c-8718-24c4cea47694"
      },
      "source": [
        "all_features = np.vstack((sketches_features, mirflickr_features))\r\n",
        "lsh_bitwise = LSH(feature_dim = all_features[0].shape[0], g=5, h=1, bitwise_hash=True)\r\n",
        "lsh_bitwise.insert(np.vstack((sketches_features, mirflickr_features)), \r\n",
        "                np.concatenate((sketches_generator.filenames, mirflickr_generator.filenames)), \r\n",
        "                np.concatenate((sketches_generator.labels, np.array([250] * mirflickr_features.shape[0]))))\r\n",
        "start = time.time()\r\n",
        "query_result_ed_bitwise = lsh_bitwise.query(sketches_features[0], 80, return_cost = True)\r\n",
        "end = time.time()\r\n",
        "print(f'query time {end - start}')\r\n",
        "query_result_sim_bitwise = lsh_bitwise.query(sketches_features[0], 80, mode='similarity', return_cost = True)\r\n",
        "print(query_result_ed_bitwise)\r\n",
        "print(query_result_sim_bitwise)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "join 3.337860107421875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 8.344650268554688e-06\n",
            "join 2.86102294921875e-06\n",
            "join 7.152557373046875e-06\n",
            "join 4.0531158447265625e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 8.106231689453125e-06\n",
            "join 3.814697265625e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 8.344650268554688e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 9.059906005859375e-06\n",
            "join 3.814697265625e-06\n",
            "join 1.8358230590820312e-05\n",
            "join 9.5367431640625e-06\n",
            "join 4.291534423828125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 8.106231689453125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 8.58306884765625e-06\n",
            "join 3.337860107421875e-06\n",
            "join 1.5974044799804688e-05\n",
            "join 4.5299530029296875e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 8.344650268554688e-06\n",
            "join 1.0013580322265625e-05\n",
            "join 8.821487426757812e-06\n",
            "join 3.814697265625e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 8.344650268554688e-06\n",
            "join 9.5367431640625e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.814697265625e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.814697265625e-06\n",
            "join 8.58306884765625e-06\n",
            "join 4.0531158447265625e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 7.62939453125e-06\n",
            "join 4.0531158447265625e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 8.58306884765625e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 8.344650268554688e-06\n",
            "join 8.821487426757812e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 2.6464462280273438e-05\n",
            "join 3.814697265625e-06\n",
            "join 9.059906005859375e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 8.58306884765625e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 8.58306884765625e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 8.344650268554688e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 1.1205673217773438e-05\n",
            "join 4.5299530029296875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 8.821487426757812e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 9.5367431640625e-06\n",
            "join 3.814697265625e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 7.867813110351562e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 9.5367431640625e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 1.0013580322265625e-05\n",
            "join 3.5762786865234375e-06\n",
            "join 2.86102294921875e-06\n",
            "join 8.106231689453125e-06\n",
            "join 4.291534423828125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 9.298324584960938e-06\n",
            "join 1.0251998901367188e-05\n",
            "join 3.814697265625e-06\n",
            "join 5.4836273193359375e-06\n",
            "join 1.0013580322265625e-05\n",
            "join 4.291534423828125e-06\n",
            "join 5.7220458984375e-06\n",
            "join 3.814697265625e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 9.5367431640625e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 8.58306884765625e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 2.86102294921875e-06\n",
            "join 8.58306884765625e-06\n",
            "join 4.291534423828125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 7.867813110351562e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 7.867813110351562e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 1.430511474609375e-05\n",
            "join 2.6226043701171875e-06\n",
            "join 7.62939453125e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 9.059906005859375e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 8.344650268554688e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 7.62939453125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 8.58306884765625e-06\n",
            "join 7.867813110351562e-06\n",
            "join 3.814697265625e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 8.344650268554688e-06\n",
            "join 3.337860107421875e-06\n",
            "join 7.152557373046875e-06\n",
            "join 3.814697265625e-06\n",
            "join 3.814697265625e-06\n",
            "join 8.821487426757812e-06\n",
            "join 9.298324584960938e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 8.106231689453125e-06\n",
            "join 8.821487426757812e-06\n",
            "join 3.814697265625e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 9.059906005859375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 8.106231689453125e-06\n",
            "join 3.814697265625e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 7.867813110351562e-06\n",
            "join 3.814697265625e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 8.344650268554688e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 8.821487426757812e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 8.58306884765625e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 8.821487426757812e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.86102294921875e-06\n",
            "join 8.106231689453125e-06\n",
            "join 3.814697265625e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 8.344650268554688e-06\n",
            "join 4.291534423828125e-06\n",
            "join 2.8848648071289062e-05\n",
            "join 3.5762786865234375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 8.58306884765625e-06\n",
            "join 3.814697265625e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 4.0531158447265625e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 9.298324584960938e-06\n",
            "join 5.4836273193359375e-06\n",
            "join 3.814697265625e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 1.5497207641601562e-05\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 8.106231689453125e-06\n",
            "join 3.814697265625e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 8.821487426757812e-06\n",
            "join 3.814697265625e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 1.1205673217773438e-05\n",
            "join 4.291534423828125e-06\n",
            "join 3.814697265625e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 1.5020370483398438e-05\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 1.1682510375976562e-05\n",
            "join 3.5762786865234375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 6.198883056640625e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 8.344650268554688e-06\n",
            "join 3.814697265625e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.814697265625e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.1457672119140625e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 1.3589859008789062e-05\n",
            "join 3.814697265625e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 9.298324584960938e-06\n",
            "join 3.814697265625e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.1457672119140625e-06\n",
            "join 2.86102294921875e-06\n",
            "join 9.775161743164062e-06\n",
            "join 1.4543533325195312e-05\n",
            "join 3.814697265625e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 1.2874603271484375e-05\n",
            "join 4.291534423828125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 1.33514404296875e-05\n",
            "join 3.5762786865234375e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.1457672119140625e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 9.775161743164062e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 1.9073486328125e-06\n",
            "join 1.9073486328125e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.384185791015625e-05\n",
            "join 2.6226043701171875e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.1457672119140625e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.384185791015625e-06\n",
            "join 1.9073486328125e-06\n",
            "join 2.1457672119140625e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.384185791015625e-06\n",
            "join 1.9073486328125e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.1457672119140625e-06\n",
            "join 1.9073486328125e-06\n",
            "join 2.1457672119140625e-06\n",
            "join 2.1457672119140625e-06\n",
            "join 1.9073486328125e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.1457672119140625e-06\n",
            "join 1.9073486328125e-06\n",
            "join 2.1457672119140625e-06\n",
            "join 2.384185791015625e-06\n",
            "join 9.775161743164062e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.1457672119140625e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 8.58306884765625e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 1.9073486328125e-06\n",
            "join 2.1457672119140625e-06\n",
            "join 2.1457672119140625e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.384185791015625e-06\n",
            "join 1.9073486328125e-06\n",
            "join 2.1457672119140625e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.2172927856445312e-05\n",
            "join 2.86102294921875e-06\n",
            "join 2.1457672119140625e-06\n",
            "join 1.0967254638671875e-05\n",
            "join 2.384185791015625e-06\n",
            "join 2.1457672119140625e-06\n",
            "join 1.9073486328125e-06\n",
            "join 1.9073486328125e-06\n",
            "join 2.1457672119140625e-06\n",
            "join 2.1457672119140625e-06\n",
            "join 2.1457672119140625e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 8.344650268554688e-06\n",
            "join 1.049041748046875e-05\n",
            "join 2.6226043701171875e-06\n",
            "join 2.1457672119140625e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.1457672119140625e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.1457672119140625e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.1457672119140625e-06\n",
            "join 2.1457672119140625e-06\n",
            "join 1.9073486328125e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.1457672119140625e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.384185791015625e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.1457672119140625e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.1457672119140625e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 8.821487426757812e-06\n",
            "join 2.86102294921875e-06\n",
            "join 1.1682510375976562e-05\n",
            "join 3.0994415283203125e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.1457672119140625e-06\n",
            "join 1.0251998901367188e-05\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.1457672119140625e-06\n",
            "join 2.1457672119140625e-06\n",
            "join 2.1457672119140625e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 1.3828277587890625e-05\n",
            "join 4.0531158447265625e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 1.5735626220703125e-05\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 1.1920928955078125e-05\n",
            "join 3.814697265625e-06\n",
            "join 9.775161743164062e-06\n",
            "join 3.814697265625e-06\n",
            "join 3.337860107421875e-06\n",
            "join 8.821487426757812e-06\n",
            "join 1.0728836059570312e-05\n",
            "join 3.5762786865234375e-06\n",
            "join 1.0251998901367188e-05\n",
            "join 4.291534423828125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 1.1444091796875e-05\n",
            "join 4.0531158447265625e-06\n",
            "join 9.298324584960938e-06\n",
            "join 2.6226043701171875e-05\n",
            "join 3.337860107421875e-06\n",
            "join 7.152557373046875e-06\n",
            "join 4.291534423828125e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 7.3909759521484375e-06\n",
            "join 1.3589859008789062e-05\n",
            "join 3.5762786865234375e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 9.5367431640625e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 8.344650268554688e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 9.059906005859375e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 2.86102294921875e-06\n",
            "join 4.0531158447265625e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 8.344650268554688e-06\n",
            "join 4.0531158447265625e-06\n",
            "join 8.344650268554688e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 2.86102294921875e-06\n",
            "join 8.344650268554688e-06\n",
            "join 8.106231689453125e-06\n",
            "join 4.0531158447265625e-06\n",
            "join 7.867813110351562e-06\n",
            "join 7.867813110351562e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 9.059906005859375e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 8.106231689453125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 1.0967254638671875e-05\n",
            "join 4.5299530029296875e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 9.059906005859375e-06\n",
            "join 3.814697265625e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 7.62939453125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 8.344650268554688e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 9.298324584960938e-06\n",
            "join 4.0531158447265625e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 8.821487426757812e-06\n",
            "join 3.814697265625e-06\n",
            "join 6.9141387939453125e-06\n",
            "join 4.0531158447265625e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 1.049041748046875e-05\n",
            "join 4.0531158447265625e-06\n",
            "join 3.814697265625e-06\n",
            "join 3.337860107421875e-06\n",
            "join 8.58306884765625e-06\n",
            "join 3.814697265625e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 8.58306884765625e-06\n",
            "join 3.814697265625e-06\n",
            "join 3.814697265625e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 9.059906005859375e-06\n",
            "join 3.814697265625e-06\n",
            "join 4.0531158447265625e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.4557113647460938e-05\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 8.821487426757812e-06\n",
            "join 1.049041748046875e-05\n",
            "join 3.5762786865234375e-06\n",
            "join 1.0013580322265625e-05\n",
            "join 4.0531158447265625e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.814697265625e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 7.867813110351562e-06\n",
            "join 2.7418136596679688e-05\n",
            "join 3.814697265625e-06\n",
            "join 7.867813110351562e-06\n",
            "join 4.0531158447265625e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 9.059906005859375e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 8.344650268554688e-06\n",
            "join 3.814697265625e-06\n",
            "join 7.867813110351562e-06\n",
            "join 4.0531158447265625e-06\n",
            "join 3.814697265625e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 8.821487426757812e-06\n",
            "join 4.291534423828125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 4.0531158447265625e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 9.298324584960938e-06\n",
            "join 4.0531158447265625e-06\n",
            "join 8.821487426757812e-06\n",
            "join 3.814697265625e-06\n",
            "join 6.67572021484375e-06\n",
            "join 4.0531158447265625e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 1.6689300537109375e-05\n",
            "join 4.291534423828125e-06\n",
            "join 9.775161743164062e-06\n",
            "join 3.814697265625e-06\n",
            "join 7.867813110351562e-06\n",
            "join 3.814697265625e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 8.344650268554688e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 7.3909759521484375e-06\n",
            "join 4.0531158447265625e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 8.821487426757812e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 8.106231689453125e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 7.867813110351562e-06\n",
            "join 4.0531158447265625e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 8.821487426757812e-06\n",
            "join 3.814697265625e-06\n",
            "join 2.384185791015625e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 7.867813110351562e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 8.58306884765625e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 7.62939453125e-06\n",
            "join 3.814697265625e-06\n",
            "join 8.344650268554688e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 7.867813110351562e-06\n",
            "join 7.867813110351562e-06\n",
            "join 3.337860107421875e-06\n",
            "join 7.152557373046875e-06\n",
            "join 4.0531158447265625e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 7.867813110351562e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 8.344650268554688e-06\n",
            "join 3.814697265625e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 9.059906005859375e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 8.106231689453125e-06\n",
            "join 3.814697265625e-06\n",
            "join 2.86102294921875e-06\n",
            "join 9.298324584960938e-06\n",
            "join 3.814697265625e-06\n",
            "join 3.814697265625e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 8.821487426757812e-06\n",
            "join 3.337860107421875e-06\n",
            "join 8.344650268554688e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 2.86102294921875e-06\n",
            "join 8.58306884765625e-06\n",
            "join 3.814697265625e-06\n",
            "join 4.0531158447265625e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 8.106231689453125e-06\n",
            "join 1.0013580322265625e-05\n",
            "join 3.814697265625e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 8.58306884765625e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 9.059906005859375e-06\n",
            "join 4.291534423828125e-06\n",
            "join 9.775161743164062e-06\n",
            "join 4.291534423828125e-06\n",
            "join 4.0531158447265625e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 8.106231689453125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 4.0531158447265625e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 8.58306884765625e-06\n",
            "join 4.5299530029296875e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 7.867813110351562e-06\n",
            "join 3.337860107421875e-06\n",
            "join 7.3909759521484375e-06\n",
            "join 3.814697265625e-06\n",
            "join 3.814697265625e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 8.344650268554688e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 1.0013580322265625e-05\n",
            "join 3.814697265625e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 7.867813110351562e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 8.344650268554688e-06\n",
            "join 3.814697265625e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 8.58306884765625e-06\n",
            "join 4.0531158447265625e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 9.059906005859375e-06\n",
            "join 3.814697265625e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 9.298324584960938e-06\n",
            "join 3.814697265625e-06\n",
            "join 6.9141387939453125e-06\n",
            "join 4.291534423828125e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 8.821487426757812e-06\n",
            "join 9.5367431640625e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 8.106231689453125e-06\n",
            "join 4.5299530029296875e-06\n",
            "join 8.821487426757812e-06\n",
            "join 8.58306884765625e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 9.059906005859375e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 8.344650268554688e-06\n",
            "join 4.0531158447265625e-06\n",
            "join 5.9604644775390625e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 7.3909759521484375e-06\n",
            "join 4.291534423828125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 7.867813110351562e-06\n",
            "join 8.106231689453125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 1.5020370483398438e-05\n",
            "join 4.0531158447265625e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.5033950805664062e-05\n",
            "join 3.337860107421875e-06\n",
            "join 5.7220458984375e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 4.0531158447265625e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 1.1205673217773438e-05\n",
            "join 4.291534423828125e-06\n",
            "join 3.814697265625e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 8.106231689453125e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 8.58306884765625e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 7.62939453125e-06\n",
            "join 3.814697265625e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 8.344650268554688e-06\n",
            "join 3.814697265625e-06\n",
            "join 8.106231689453125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 1.7642974853515625e-05\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 8.344650268554688e-06\n",
            "join 8.58306884765625e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 7.62939453125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 7.867813110351562e-06\n",
            "join 4.291534423828125e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 1.4543533325195312e-05\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 8.106231689453125e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 7.867813110351562e-06\n",
            "join 9.298324584960938e-06\n",
            "join 3.814697265625e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 9.059906005859375e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 9.059906005859375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 8.58306884765625e-06\n",
            "join 9.059906005859375e-06\n",
            "join 8.821487426757812e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 8.106231689453125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 1.3828277587890625e-05\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.1457672119140625e-06\n",
            "join 1.9073486328125e-06\n",
            "join 2.1457672119140625e-06\n",
            "join 2.384185791015625e-06\n",
            "join 3.457069396972656e-05\n",
            "join 1.52587890625e-05\n",
            "join 2.6226043701171875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.1457672119140625e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 1.9073486328125e-06\n",
            "join 1.9073486328125e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.1457672119140625e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.1457672119140625e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 7.62939453125e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 7.62939453125e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 9.298324584960938e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 7.867813110351562e-06\n",
            "join 9.059906005859375e-06\n",
            "join 3.814697265625e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 1.9788742065429688e-05\n",
            "join 3.814697265625e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.814697265625e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 7.867813110351562e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 7.62939453125e-06\n",
            "join 3.814697265625e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 7.867813110351562e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 1.1920928955078125e-05\n",
            "join 4.0531158447265625e-06\n",
            "join 7.152557373046875e-06\n",
            "join 8.821487426757812e-06\n",
            "join 4.0531158447265625e-06\n",
            "join 1.2636184692382812e-05\n",
            "join 7.3909759521484375e-06\n",
            "join 4.0531158447265625e-06\n",
            "join 7.3909759521484375e-06\n",
            "join 8.344650268554688e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 7.152557373046875e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 8.106231689453125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 7.3909759521484375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 1.3113021850585938e-05\n",
            "join 4.76837158203125e-06\n",
            "join 3.1948089599609375e-05\n",
            "join 4.291534423828125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.1457672119140625e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 9.059906005859375e-06\n",
            "join 3.814697265625e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 1.621246337890625e-05\n",
            "join 3.337860107421875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 8.106231689453125e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.384185791015625e-06\n",
            "join 1.9073486328125e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 1.33514404296875e-05\n",
            "join 3.337860107421875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.1457672119140625e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.384185791015625e-06\n",
            "join 1.4066696166992188e-05\n",
            "join 3.814697265625e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.1457672119140625e-06\n",
            "join 2.1457672119140625e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.384185791015625e-06\n",
            "join 1.52587890625e-05\n",
            "join 4.5299530029296875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 4.291534423828125e-06\n",
            "join 4.0531158447265625e-06\n",
            "join 3.337860107421875e-06\n",
            "join 4.0531158447265625e-06\n",
            "join 3.814697265625e-06\n",
            "join 1.0967254638671875e-05\n",
            "join 3.5762786865234375e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 8.821487426757812e-06\n",
            "join 4.76837158203125e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.814697265625e-06\n",
            "join 1.811981201171875e-05\n",
            "join 3.337860107421875e-06\n",
            "join 7.867813110351562e-06\n",
            "join 7.867813110351562e-06\n",
            "join 4.0531158447265625e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 1.0013580322265625e-05\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 8.58306884765625e-06\n",
            "join 3.814697265625e-06\n",
            "join 3.814697265625e-06\n",
            "join 8.106231689453125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.7179718017578125e-05\n",
            "join 3.814697265625e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 1.1682510375976562e-05\n",
            "join 3.814697265625e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 4.291534423828125e-06\n",
            "join 3.814697265625e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 4.0531158447265625e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 1.1444091796875e-05\n",
            "join 4.0531158447265625e-06\n",
            "join 9.298324584960938e-06\n",
            "join 4.5299530029296875e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 2.86102294921875e-06\n",
            "join 1.3589859008789062e-05\n",
            "join 3.814697265625e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 1.0728836059570312e-05\n",
            "join 1.9073486328125e-05\n",
            "join 4.76837158203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 1.33514404296875e-05\n",
            "join 4.291534423828125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 1.239776611328125e-05\n",
            "join 4.0531158447265625e-06\n",
            "join 1.4066696166992188e-05\n",
            "join 1.0967254638671875e-05\n",
            "join 4.5299530029296875e-06\n",
            "join 1.0013580322265625e-05\n",
            "join 4.291534423828125e-06\n",
            "join 3.814697265625e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 8.344650268554688e-06\n",
            "join 3.814697265625e-06\n",
            "join 7.152557373046875e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 7.867813110351562e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.814697265625e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 9.775161743164062e-06\n",
            "join 4.5299530029296875e-06\n",
            "join 3.814697265625e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 1.0013580322265625e-05\n",
            "join 3.814697265625e-06\n",
            "join 9.298324584960938e-06\n",
            "join 1.0251998901367188e-05\n",
            "join 4.291534423828125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 8.344650268554688e-06\n",
            "join 3.814697265625e-06\n",
            "join 5.9604644775390625e-06\n",
            "join 3.814697265625e-06\n",
            "join 7.3909759521484375e-06\n",
            "join 8.106231689453125e-06\n",
            "join 3.814697265625e-06\n",
            "join 1.1205673217773438e-05\n",
            "join 3.337860107421875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 8.58306884765625e-06\n",
            "join 3.814697265625e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 7.62939453125e-06\n",
            "join 9.059906005859375e-06\n",
            "join 4.5299530029296875e-06\n",
            "join 8.344650268554688e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.814697265625e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 7.62939453125e-06\n",
            "join 4.0531158447265625e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 7.62939453125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 8.58306884765625e-06\n",
            "join 4.291534423828125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 1.71661376953125e-05\n",
            "join 4.291534423828125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 8.106231689453125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 8.58306884765625e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 7.62939453125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 8.58306884765625e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 8.344650268554688e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 9.775161743164062e-06\n",
            "join 4.291534423828125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 9.5367431640625e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 4.0531158447265625e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 8.106231689453125e-06\n",
            "join 4.5299530029296875e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 9.5367431640625e-06\n",
            "join 3.814697265625e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 8.106231689453125e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.193450927734375e-05\n",
            "join 2.86102294921875e-06\n",
            "join 4.5299530029296875e-06\n",
            "join 1.52587890625e-05\n",
            "join 3.337860107421875e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 7.867813110351562e-06\n",
            "join 4.5299530029296875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 1.1205673217773438e-05\n",
            "join 4.0531158447265625e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 9.5367431640625e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 7.867813110351562e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 9.775161743164062e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 7.62939453125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 7.62939453125e-06\n",
            "join 7.62939453125e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 8.821487426757812e-06\n",
            "join 3.337860107421875e-06\n",
            "join 6.9141387939453125e-06\n",
            "join 4.0531158447265625e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 1.0728836059570312e-05\n",
            "join 4.0531158447265625e-06\n",
            "join 3.814697265625e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 5.245208740234375e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 6.9141387939453125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 5.7220458984375e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 7.3909759521484375e-06\n",
            "join 7.867813110351562e-06\n",
            "join 9.059906005859375e-06\n",
            "join 4.291534423828125e-06\n",
            "join 6.67572021484375e-06\n",
            "join 4.5299530029296875e-06\n",
            "join 2.1696090698242188e-05\n",
            "join 3.5762786865234375e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 7.62939453125e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.814697265625e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 1.71661376953125e-05\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 8.106231689453125e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 7.867813110351562e-06\n",
            "join 4.291534423828125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 2.86102294921875e-06\n",
            "join 7.867813110351562e-06\n",
            "join 3.814697265625e-06\n",
            "join 2.86102294921875e-06\n",
            "join 7.867813110351562e-06\n",
            "join 4.5299530029296875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.814697265625e-06\n",
            "join 8.344650268554688e-06\n",
            "join 8.106231689453125e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 7.867813110351562e-06\n",
            "join 3.814697265625e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 8.821487426757812e-06\n",
            "join 3.814697265625e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.1457672119140625e-06\n",
            "join 9.298324584960938e-06\n",
            "join 4.0531158447265625e-06\n",
            "join 3.337860107421875e-06\n",
            "join 4.5299530029296875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 1.4781951904296875e-05\n",
            "join 5.0067901611328125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 1.3589859008789062e-05\n",
            "join 3.337860107421875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.1457672119140625e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.1457672119140625e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.384185791015625e-06\n",
            "join 3.814697265625e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.384185791015625e-06\n",
            "join 1.9073486328125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.384185791015625e-06\n",
            "join 3.814697265625e-05\n",
            "join 5.245208740234375e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 1.2636184692382812e-05\n",
            "join 3.0994415283203125e-06\n",
            "join 1.4066696166992188e-05\n",
            "join 1.33514404296875e-05\n",
            "join 3.5762786865234375e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.384185791015625e-06\n",
            "join 8.58306884765625e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.1457672119140625e-06\n",
            "join 2.1457672119140625e-06\n",
            "join 2.384185791015625e-06\n",
            "join 1.9073486328125e-06\n",
            "join 1.9073486328125e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.384185791015625e-06\n",
            "join 1.0728836059570312e-05\n",
            "join 2.86102294921875e-06\n",
            "join 1.0013580322265625e-05\n",
            "join 2.86102294921875e-06\n",
            "join 2.1457672119140625e-06\n",
            "join 2.384185791015625e-06\n",
            "join 3.6716461181640625e-05\n",
            "join 2.384185791015625e-06\n",
            "join 1.9073486328125e-06\n",
            "join 2.384185791015625e-06\n",
            "join 8.58306884765625e-06\n",
            "join 2.1457672119140625e-06\n",
            "join 2.1457672119140625e-06\n",
            "join 2.1457672119140625e-06\n",
            "join 1.9073486328125e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.1457672119140625e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.1457672119140625e-06\n",
            "join 2.1457672119140625e-06\n",
            "join 2.1457672119140625e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.1457672119140625e-06\n",
            "join 2.384185791015625e-06\n",
            "join 9.298324584960938e-06\n",
            "join 3.814697265625e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 9.298324584960938e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.384185791015625e-06\n",
            "join 9.775161743164062e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 9.298324584960938e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.1457672119140625e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.1457672119140625e-06\n",
            "join 2.1457672119140625e-06\n",
            "join 1.4781951904296875e-05\n",
            "join 2.1457672119140625e-06\n",
            "join 1.1920928955078125e-05\n",
            "join 3.337860107421875e-06\n",
            "join 2.1457672119140625e-06\n",
            "join 2.1457672119140625e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.1457672119140625e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.1457672119140625e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.384185791015625e-06\n",
            "join 1.049041748046875e-05\n",
            "join 3.0994415283203125e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.1457672119140625e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 9.059906005859375e-06\n",
            "join 0.0001475811004638672\n",
            "join 1.1444091796875e-05\n",
            "join 4.76837158203125e-06\n",
            "join 1.3113021850585938e-05\n",
            "join 3.337860107421875e-06\n",
            "join 2.384185791015625e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.384185791015625e-06\n",
            "join 1.3589859008789062e-05\n",
            "join 2.384185791015625e-06\n",
            "join 2.1457672119140625e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 1.9073486328125e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.384185791015625e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 1.2874603271484375e-05\n",
            "join 5.245208740234375e-06\n",
            "join 2.9087066650390625e-05\n",
            "join 2.86102294921875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.384185791015625e-06\n",
            "join 1.9073486328125e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.1457672119140625e-06\n",
            "join 9.775161743164062e-06\n",
            "join 9.775161743164062e-06\n",
            "join 3.814697265625e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 7.3909759521484375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.384185791015625e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 9.298324584960938e-06\n",
            "join 8.58306884765625e-06\n",
            "join 4.0531158447265625e-06\n",
            "join 1.049041748046875e-05\n",
            "join 3.814697265625e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 9.5367431640625e-06\n",
            "join 3.814697265625e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 9.775161743164062e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 7.867813110351562e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 8.106231689453125e-06\n",
            "join 2.002716064453125e-05\n",
            "join 3.5762786865234375e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 9.775161743164062e-06\n",
            "join 3.814697265625e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 1.4066696166992188e-05\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 7.152557373046875e-06\n",
            "join 4.291534423828125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.814697265625e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 9.775161743164062e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 6.4373016357421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 1.0013580322265625e-05\n",
            "join 3.814697265625e-06\n",
            "join 3.337860107421875e-06\n",
            "join 7.867813110351562e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 8.821487426757812e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 9.059906005859375e-06\n",
            "join 4.0531158447265625e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.814697265625e-06\n",
            "join 3.814697265625e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 1.7404556274414062e-05\n",
            "join 3.814697265625e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 1.0967254638671875e-05\n",
            "join 4.5299530029296875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 9.298324584960938e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 5.245208740234375e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 1.9311904907226562e-05\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.384185791015625e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 1.0013580322265625e-05\n",
            "join 4.291534423828125e-06\n",
            "join 9.059906005859375e-06\n",
            "join 8.58306884765625e-06\n",
            "join 3.814697265625e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 8.821487426757812e-06\n",
            "join 9.5367431640625e-06\n",
            "join 1.4781951904296875e-05\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 1.0251998901367188e-05\n",
            "join 4.76837158203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 1.811981201171875e-05\n",
            "join 4.5299530029296875e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 1.0728836059570312e-05\n",
            "join 4.291534423828125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 8.344650268554688e-06\n",
            "join 8.106231689453125e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.814697265625e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 8.821487426757812e-06\n",
            "join 1.049041748046875e-05\n",
            "join 1.5497207641601562e-05\n",
            "join 4.291534423828125e-06\n",
            "join 3.814697265625e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 7.3909759521484375e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 7.3909759521484375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 8.58306884765625e-06\n",
            "join 4.291534423828125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.814697265625e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 7.867813110351562e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 1.9073486328125e-05\n",
            "join 9.059906005859375e-06\n",
            "join 3.814697265625e-06\n",
            "join 8.58306884765625e-06\n",
            "join 3.814697265625e-06\n",
            "join 1.0728836059570312e-05\n",
            "join 3.814697265625e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 8.58306884765625e-06\n",
            "join 1.9073486328125e-05\n",
            "join 9.298324584960938e-06\n",
            "join 4.0531158447265625e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 1.4543533325195312e-05\n",
            "join 3.0994415283203125e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.384185791015625e-06\n",
            "join 9.059906005859375e-06\n",
            "join 3.814697265625e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 9.298324584960938e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 8.58306884765625e-06\n",
            "join 4.0531158447265625e-06\n",
            "join 1.1205673217773438e-05\n",
            "join 4.0531158447265625e-06\n",
            "join 3.814697265625e-06\n",
            "join 4.291534423828125e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 5.4836273193359375e-06\n",
            "join 4.0531158447265625e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 6.9141387939453125e-06\n",
            "join 4.291534423828125e-06\n",
            "join 4.291534423828125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 9.775161743164062e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.814697265625e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 5.9604644775390625e-06\n",
            "join 4.291534423828125e-06\n",
            "join 1.3589859008789062e-05\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 8.58306884765625e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 9.059906005859375e-06\n",
            "join 9.298324584960938e-06\n",
            "join 3.814697265625e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 1.7642974853515625e-05\n",
            "join 4.0531158447265625e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 1.5497207641601562e-05\n",
            "join 3.814697265625e-06\n",
            "join 2.86102294921875e-06\n",
            "join 1.049041748046875e-05\n",
            "join 3.5762786865234375e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 8.58306884765625e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 8.58306884765625e-06\n",
            "join 8.821487426757812e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 8.58306884765625e-06\n",
            "join 4.76837158203125e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 5.4836273193359375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 1.33514404296875e-05\n",
            "join 4.5299530029296875e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 8.58306884765625e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.814697265625e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 8.106231689453125e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 1.1205673217773438e-05\n",
            "join 7.62939453125e-06\n",
            "join 4.0531158447265625e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 1.0728836059570312e-05\n",
            "join 3.814697265625e-06\n",
            "join 3.337860107421875e-06\n",
            "join 1.0967254638671875e-05\n",
            "join 1.1444091796875e-05\n",
            "join 3.5762786865234375e-06\n",
            "join 1.049041748046875e-05\n",
            "join 5.9604644775390625e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 9.775161743164062e-06\n",
            "join 8.344650268554688e-06\n",
            "join 3.814697265625e-06\n",
            "join 1.1920928955078125e-05\n",
            "join 7.3909759521484375e-06\n",
            "join 3.814697265625e-06\n",
            "join 1.2159347534179688e-05\n",
            "join 5.7220458984375e-06\n",
            "join 1.1205673217773438e-05\n",
            "join 4.5299530029296875e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 1.049041748046875e-05\n",
            "join 4.291534423828125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 7.62939453125e-06\n",
            "join 1.0728836059570312e-05\n",
            "join 4.291534423828125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 7.62939453125e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 7.3909759521484375e-06\n",
            "join 5.9604644775390625e-06\n",
            "join 3.814697265625e-06\n",
            "join 1.0013580322265625e-05\n",
            "join 3.5762786865234375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.814697265625e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 7.867813110351562e-06\n",
            "join 3.814697265625e-06\n",
            "join 3.814697265625e-06\n",
            "join 2.002716064453125e-05\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 8.58306884765625e-06\n",
            "join 4.291534423828125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 4.76837158203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 4.0531158447265625e-06\n",
            "join 3.337860107421875e-06\n",
            "join 7.62939453125e-06\n",
            "join 9.298324584960938e-06\n",
            "join 3.814697265625e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 9.298324584960938e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 8.344650268554688e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.814697265625e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 8.344650268554688e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 1.0013580322265625e-05\n",
            "join 3.814697265625e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 9.059906005859375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 8.344650268554688e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 7.867813110351562e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 9.775161743164062e-06\n",
            "join 3.814697265625e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 1.049041748046875e-05\n",
            "join 3.814697265625e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.1219253540039062e-05\n",
            "join 3.5762786865234375e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 9.298324584960938e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 1.0728836059570312e-05\n",
            "join 3.814697265625e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 9.5367431640625e-06\n",
            "join 1.1682510375976562e-05\n",
            "join 4.291534423828125e-06\n",
            "join 9.775161743164062e-06\n",
            "join 7.867813110351562e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 7.152557373046875e-06\n",
            "join 3.814697265625e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 9.775161743164062e-06\n",
            "join 4.291534423828125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 1.430511474609375e-05\n",
            "join 3.5762786865234375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.814697265625e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 7.867813110351562e-06\n",
            "join 3.814697265625e-06\n",
            "join 1.1920928955078125e-05\n",
            "join 4.0531158447265625e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 1.3589859008789062e-05\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 8.344650268554688e-06\n",
            "join 9.298324584960938e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 1.049041748046875e-05\n",
            "join 4.0531158447265625e-06\n",
            "join 3.337860107421875e-06\n",
            "join 4.291534423828125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 1.5974044799804688e-05\n",
            "join 3.814697265625e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.814697265625e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 8.58306884765625e-06\n",
            "join 4.0531158447265625e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 8.821487426757812e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 9.5367431640625e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 1.4543533325195312e-05\n",
            "join 3.0994415283203125e-06\n",
            "join 1.049041748046875e-05\n",
            "join 4.0531158447265625e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 1.0013580322265625e-05\n",
            "join 3.814697265625e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 1.33514404296875e-05\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 9.298324584960938e-06\n",
            "join 4.0531158447265625e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 7.62939453125e-06\n",
            "join 1.1444091796875e-05\n",
            "join 4.291534423828125e-06\n",
            "join 9.775161743164062e-06\n",
            "join 4.0531158447265625e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 8.821487426757812e-06\n",
            "join 3.814697265625e-06\n",
            "join 3.814697265625e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 1.1920928955078125e-05\n",
            "join 1.7642974853515625e-05\n",
            "join 3.5762786865234375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 1.0967254638671875e-05\n",
            "join 4.0531158447265625e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 8.821487426757812e-06\n",
            "join 4.0531158447265625e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 7.3909759521484375e-06\n",
            "join 4.0531158447265625e-06\n",
            "join 8.821487426757812e-06\n",
            "join 3.814697265625e-06\n",
            "join 1.049041748046875e-05\n",
            "join 3.5762786865234375e-06\n",
            "join 4.0531158447265625e-06\n",
            "join 6.4373016357421875e-06\n",
            "join 9.775161743164062e-06\n",
            "join 4.0531158447265625e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 9.775161743164062e-06\n",
            "join 4.0531158447265625e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 1.0251998901367188e-05\n",
            "join 2.2172927856445312e-05\n",
            "join 3.814697265625e-06\n",
            "join 3.814697265625e-06\n",
            "join 3.337860107421875e-06\n",
            "join 1.049041748046875e-05\n",
            "join 3.814697265625e-06\n",
            "join 6.9141387939453125e-06\n",
            "join 4.0531158447265625e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 1.2636184692382812e-05\n",
            "join 5.4836273193359375e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 1.0013580322265625e-05\n",
            "join 7.62939453125e-06\n",
            "join 3.814697265625e-06\n",
            "join 1.3113021850585938e-05\n",
            "join 4.5299530029296875e-06\n",
            "join 7.867813110351562e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.814697265625e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 1.0013580322265625e-05\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.0503997802734375e-05\n",
            "join 3.814697265625e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 1.2159347534179688e-05\n",
            "join 6.4373016357421875e-06\n",
            "join 5.4836273193359375e-06\n",
            "join 4.76837158203125e-06\n",
            "join 1.5497207641601562e-05\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.552436828613281e-05\n",
            "join 1.5020370483398438e-05\n",
            "join 4.291534423828125e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 5.4836273193359375e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.1696090698242188e-05\n",
            "join 9.059906005859375e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 1.049041748046875e-05\n",
            "join 3.5762786865234375e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 6.4373016357421875e-06\n",
            "join 1.4543533325195312e-05\n",
            "join 4.5299530029296875e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 1.3828277587890625e-05\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 4.0531158447265625e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 1.0013580322265625e-05\n",
            "join 3.814697265625e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 8.821487426757812e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 9.059906005859375e-06\n",
            "join 3.814697265625e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 8.344650268554688e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 7.867813110351562e-06\n",
            "join 2.0265579223632812e-05\n",
            "join 3.5762786865234375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 5.9604644775390625e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 9.5367431640625e-06\n",
            "join 4.5299530029296875e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.814697265625e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 7.3909759521484375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 8.106231689453125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.384185791015625e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 1.430511474609375e-05\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 1.5497207641601562e-05\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 8.58306884765625e-06\n",
            "join 3.814697265625e-06\n",
            "join 8.821487426757812e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 2.86102294921875e-06\n",
            "join 8.106231689453125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 5.7220458984375e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 7.867813110351562e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 7.152557373046875e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 8.344650268554688e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 6.4373016357421875e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 8.344650268554688e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 8.58306884765625e-06\n",
            "join 4.5299530029296875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 8.821487426757812e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 2.384185791015625e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 8.106231689453125e-06\n",
            "join 3.814697265625e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 1.8596649169921875e-05\n",
            "join 8.58306884765625e-06\n",
            "join 3.814697265625e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 8.821487426757812e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 7.867813110351562e-06\n",
            "join 4.0531158447265625e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 7.62939453125e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 8.106231689453125e-06\n",
            "join 9.059906005859375e-06\n",
            "join 3.814697265625e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 1.1920928955078125e-05\n",
            "join 2.0503997802734375e-05\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 8.58306884765625e-06\n",
            "join 3.814697265625e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.814697265625e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 7.867813110351562e-06\n",
            "join 3.814697265625e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 8.58306884765625e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 2.86102294921875e-06\n",
            "join 7.3909759521484375e-06\n",
            "join 8.58306884765625e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 7.867813110351562e-06\n",
            "join 3.814697265625e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 1.0728836059570312e-05\n",
            "join 8.58306884765625e-06\n",
            "join 4.5299530029296875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 9.059906005859375e-06\n",
            "join 3.814697265625e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 8.344650268554688e-06\n",
            "join 3.814697265625e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 9.059906005859375e-06\n",
            "join 3.814697265625e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 8.106231689453125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.814697265625e-06\n",
            "join 2.384185791015625e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 8.344650268554688e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 8.58306884765625e-06\n",
            "join 4.291534423828125e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 7.867813110351562e-06\n",
            "join 8.58306884765625e-06\n",
            "join 3.814697265625e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 1.33514404296875e-05\n",
            "join 3.5762786865234375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.002716064453125e-05\n",
            "join 1.6927719116210938e-05\n",
            "join 3.337860107421875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 8.106231689453125e-06\n",
            "join 3.814697265625e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 1.1920928955078125e-05\n",
            "join 1.1920928955078125e-05\n",
            "join 3.337860107421875e-06\n",
            "join 1.1682510375976562e-05\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 1.1682510375976562e-05\n",
            "join 3.0994415283203125e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.1457672119140625e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.384185791015625e-06\n",
            "join 1.9073486328125e-06\n",
            "join 2.1457672119140625e-06\n",
            "join 1.9073486328125e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.384185791015625e-06\n",
            "join 1.9073486328125e-06\n",
            "join 2.1457672119140625e-06\n",
            "join 2.384185791015625e-06\n",
            "join 1.9073486328125e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.1457672119140625e-06\n",
            "join 2.384185791015625e-06\n",
            "join 8.821487426757812e-06\n",
            "join 2.86102294921875e-06\n",
            "join 9.298324584960938e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.1457672119140625e-06\n",
            "join 1.9073486328125e-06\n",
            "join 2.1457672119140625e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.1457672119140625e-06\n",
            "join 2.1457672119140625e-06\n",
            "join 2.384185791015625e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.1457672119140625e-06\n",
            "join 1.9073486328125e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.1457672119140625e-06\n",
            "join 1.9073486328125e-06\n",
            "join 8.821487426757812e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.384185791015625e-06\n",
            "join 7.62939453125e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.1457672119140625e-06\n",
            "join 9.059906005859375e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.384185791015625e-06\n",
            "join 9.059906005859375e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.1457672119140625e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.1457672119140625e-06\n",
            "join 1.9073486328125e-06\n",
            "join 2.1457672119140625e-06\n",
            "join 2.86102294921875e-06\n",
            "join 1.1444091796875e-05\n",
            "join 2.86102294921875e-06\n",
            "join 2.1457672119140625e-06\n",
            "join 1.9073486328125e-06\n",
            "join 1.6689300537109375e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.1457672119140625e-06\n",
            "join 2.384185791015625e-06\n",
            "join 9.298324584960938e-06\n",
            "join 2.86102294921875e-06\n",
            "join 1.1682510375976562e-05\n",
            "join 3.814697265625e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.384185791015625e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.384185791015625e-06\n",
            "join 1.9073486328125e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 1.2636184692382812e-05\n",
            "join 3.0994415283203125e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.384185791015625e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 1.2636184692382812e-05\n",
            "join 1.0251998901367188e-05\n",
            "join 4.5299530029296875e-06\n",
            "join 6.4373016357421875e-06\n",
            "join 4.291534423828125e-06\n",
            "join 3.814697265625e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 9.298324584960938e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 8.821487426757812e-06\n",
            "join 4.0531158447265625e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 8.58306884765625e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 8.106231689453125e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 8.821487426757812e-06\n",
            "join 9.775161743164062e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 9.059906005859375e-06\n",
            "join 3.814697265625e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 8.106231689453125e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 8.344650268554688e-06\n",
            "join 2.193450927734375e-05\n",
            "join 4.0531158447265625e-06\n",
            "join 3.814697265625e-06\n",
            "join 1.0013580322265625e-05\n",
            "join 4.291534423828125e-06\n",
            "join 6.67572021484375e-06\n",
            "join 4.0531158447265625e-06\n",
            "join 3.814697265625e-06\n",
            "join 3.814697265625e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 9.298324584960938e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.814697265625e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 7.867813110351562e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 7.867813110351562e-06\n",
            "join 3.814697265625e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 8.106231689453125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.86102294921875e-06\n",
            "join 8.58306884765625e-06\n",
            "join 8.821487426757812e-06\n",
            "join 4.5299530029296875e-06\n",
            "join 9.059906005859375e-06\n",
            "join 4.291534423828125e-06\n",
            "join 4.0531158447265625e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 8.344650268554688e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 2.86102294921875e-06\n",
            "join 7.62939453125e-06\n",
            "join 1.049041748046875e-05\n",
            "join 4.0531158447265625e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 8.106231689453125e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.384185791015625e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 7.62939453125e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 7.867813110351562e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.814697265625e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 8.344650268554688e-06\n",
            "join 8.106231689453125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 9.298324584960938e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 1.1920928955078125e-05\n",
            "join 3.5762786865234375e-06\n",
            "join 8.106231689453125e-06\n",
            "join 4.291534423828125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 8.344650268554688e-06\n",
            "join 3.814697265625e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 8.58306884765625e-06\n",
            "join 4.0531158447265625e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 8.106231689453125e-06\n",
            "join 4.291534423828125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 1.0967254638671875e-05\n",
            "join 3.5762786865234375e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 8.821487426757812e-06\n",
            "join 3.814697265625e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 8.106231689453125e-06\n",
            "join 3.814697265625e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 9.059906005859375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 7.62939453125e-06\n",
            "join 4.0531158447265625e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 8.821487426757812e-06\n",
            "join 8.58306884765625e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 8.58306884765625e-06\n",
            "join 1.9788742065429688e-05\n",
            "join 3.5762786865234375e-06\n",
            "join 7.3909759521484375e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 8.821487426757812e-06\n",
            "join 4.291534423828125e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 8.58306884765625e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.814697265625e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.002716064453125e-05\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.075599670410156e-05\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 7.867813110351562e-06\n",
            "join 3.814697265625e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 8.344650268554688e-06\n",
            "join 4.291534423828125e-06\n",
            "join 1.0967254638671875e-05\n",
            "join 3.814697265625e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 7.3909759521484375e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 1.0967254638671875e-05\n",
            "join 4.291534423828125e-06\n",
            "join 8.58306884765625e-06\n",
            "join 9.298324584960938e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 9.059906005859375e-06\n",
            "join 8.58306884765625e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 8.58306884765625e-06\n",
            "join 4.0531158447265625e-06\n",
            "join 7.3909759521484375e-06\n",
            "join 8.821487426757812e-06\n",
            "join 3.337860107421875e-06\n",
            "join 1.0728836059570312e-05\n",
            "join 3.814697265625e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 8.821487426757812e-06\n",
            "join 3.814697265625e-06\n",
            "join 2.86102294921875e-06\n",
            "join 7.152557373046875e-06\n",
            "join 8.58306884765625e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 7.62939453125e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 7.62939453125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 8.58306884765625e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 8.58306884765625e-06\n",
            "join 4.0531158447265625e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 8.344650268554688e-06\n",
            "join 5.0067901611328125e-06\n",
            "join 9.059906005859375e-06\n",
            "join 3.814697265625e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 1.5497207641601562e-05\n",
            "join 3.5762786865234375e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 8.106231689453125e-06\n",
            "join 3.814697265625e-06\n",
            "join 3.337860107421875e-06\n",
            "join 8.58306884765625e-06\n",
            "join 8.821487426757812e-06\n",
            "join 5.0067901611328125e-06\n",
            "join 8.58306884765625e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 1.4543533325195312e-05\n",
            "join 8.821487426757812e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 1.9550323486328125e-05\n",
            "join 4.0531158447265625e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.814697265625e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 8.58306884765625e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 9.775161743164062e-06\n",
            "join 4.0531158447265625e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.814697265625e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 9.059906005859375e-06\n",
            "join 3.814697265625e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 7.867813110351562e-06\n",
            "join 4.291534423828125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.814697265625e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 4.291534423828125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 8.344650268554688e-06\n",
            "join 4.0531158447265625e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 8.106231689453125e-06\n",
            "join 3.814697265625e-06\n",
            "join 8.344650268554688e-06\n",
            "join 2.4318695068359375e-05\n",
            "join 4.5299530029296875e-06\n",
            "join 3.814697265625e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 8.344650268554688e-06\n",
            "join 4.5299530029296875e-06\n",
            "join 4.0531158447265625e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 8.344650268554688e-06\n",
            "join 3.814697265625e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 1.5497207641601562e-05\n",
            "join 3.337860107421875e-06\n",
            "join 8.344650268554688e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 8.58306884765625e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 8.344650268554688e-06\n",
            "join 4.0531158447265625e-06\n",
            "join 8.344650268554688e-06\n",
            "join 3.814697265625e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.0265579223632812e-05\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 8.821487426757812e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 9.5367431640625e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 5.4836273193359375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 7.62939453125e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.814697265625e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.6226043701171875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 8.344650268554688e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 9.298324584960938e-06\n",
            "join 4.291534423828125e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 9.298324584960938e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 7.867813110351562e-06\n",
            "join 3.5762786865234375e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 8.58306884765625e-06\n",
            "join 3.337860107421875e-06\n",
            "join 2.86102294921875e-06\n",
            "join 3.337860107421875e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 3.0994415283203125e-06\n",
            "join 7.867813110351562e-06\n",
            "join 3.814697265625e-06\n",
            "inner for time: 8.471322774887085\n",
            "(45000, 2048)\n",
            "(45000, 2048)\n",
            "0\n",
            "dist shape (45000,) and dist size 45000\n",
            "0\n",
            "dist shape (44920,) and dist size 44920\n",
            "1\n",
            "dist shape (44920,) and dist size 44920\n",
            "0\n",
            "dist shape (44920,) and dist size 44920\n",
            "0\n",
            "dist shape (44920,) and dist size 44920\n",
            "query time 4.084296226501465\n",
            "0\n",
            "sim shape (45000,) and sim size 45000\n",
            "0\n",
            "sim shape (44920,) and sim size 44920\n",
            "1\n",
            "sim shape (44920,) and sim size 44920\n",
            "0\n",
            "sim shape (44920,) and sim size 44920\n",
            "0\n",
            "sim shape (44920,) and sim size 44920\n",
            "({'ids': array(['airplane/1.png', 'airplane/49.png', 'ship/14915.png',\n",
            "       'bread/2460.png', 'wheelbarrow/19552.png', 'airplane/74.png',\n",
            "       'lighter/9805.png', 'tablelamp/17327.png', 'cake/3105.png',\n",
            "       'hamburger/7709.png', 'arm/440.png', 'sea turtle/14569.png',\n",
            "       'arm/414.png', 'hat/8058.png', 'tractor/18352.png',\n",
            "       'submarine/16594.png', 'crown/5049.png', 'tractor/18388.png',\n",
            "       'leaf/9608.png', 'bulldozer/2614.png', 'shark/14786.png',\n",
            "       'helicopter/8382.png', 'flying saucer/7001.png',\n",
            "       'floor lamp/6735.png', 'mouth/10909.png', 'blimp/1892.png',\n",
            "       'pumpkin/13191.png', 'squirrel/16217.png', 'head-phones/8235.png',\n",
            "       'rainbow/13543.png', 'tv/19008.png', 'rollerblades/13803.png',\n",
            "       'bee/1413.png', 'ship/14959.png', 'airplane/12.png',\n",
            "       'bulldozer/2628.png', 'rainbow/13553.png', 'couch/4673.png',\n",
            "       'sheep/14828.png', 'trombone/18690.png', 'shark/14744.png',\n",
            "       'mouth/10881.png', 'arm/441.png', 'snowboard/15538.png',\n",
            "       'arm/443.png', 'bus/2680.png', 'parrot/11814.png',\n",
            "       'hot-dog/8661.png', 'speed-boat/15906.png', 'suitcase/16698.png',\n",
            "       'sea turtle/14582.png', 'tree/18608.png', 'santa claus/14013.png',\n",
            "       'tractor/18397.png', 'flashlight/6681.png', 'sheep/14831.png',\n",
            "       'parrot/11828.png', 'bee/1369.png', 'fish/6635.png',\n",
            "       'microscope/10452.png', 'truck/18848.png', 'ship/14884.png',\n",
            "       'couch/4671.png', 'giraffe/7437.png', 'hamburger/7700.png',\n",
            "       'hamburger/7717.png', 'hat/8038.png', 'monkey/10551.png',\n",
            "       'tractor/18361.png', 'pumpkin/13189.png', 'sailboat/13940.png',\n",
            "       'mouse (animal)/10803.png', 'guitar/7638.png',\n",
            "       'pineapple/12581.png', 'bulldozer/2629.png',\n",
            "       'standing bird/16276.png', 'shark/14775.png',\n",
            "       'computer-mouse/4564.png', 'blimp/1888.png', 'windmill/19609.png'],\n",
            "      dtype='<U28'), 'labels': array([  0,   0, 186,  30, 244,   0, 122, 216,  38,  96,   5, 182,   5,\n",
            "       100, 229, 207,  63, 229, 120,  32, 184, 104,  87,  84, 136,  23,\n",
            "       164, 202, 102, 169, 237, 172,  17, 186,   0,  32, 169,  58, 185,\n",
            "       233, 184, 136,   5, 194,   5,  33, 147, 108, 198, 208, 182, 232,\n",
            "       175, 229,  83, 185, 147,  17,  82, 130, 235, 186,  58,  92,  96,\n",
            "        96, 100, 131, 229, 164, 174, 135,  95, 157,  32, 203, 184,  57,\n",
            "        23, 245]), 'distances': array([ 0.        , 18.58403523, 19.15990317, 19.31599062, 19.41853398,\n",
            "       19.47388896, 19.49892444, 19.50221171, 19.65230779, 19.7686245 ,\n",
            "       19.82056657, 19.85123579, 19.89757541, 19.90490339, 19.94341083,\n",
            "       19.94740582, 19.99947007, 20.01811228, 20.02192403, 20.02381243,\n",
            "       20.0411698 , 20.07822896, 20.11230383, 20.11423262, 20.13232336,\n",
            "       20.13578557, 20.14476722, 20.15375162, 20.17899963, 20.19041596,\n",
            "       20.19285122, 20.20811667, 20.20874643, 20.23737354, 20.23802286,\n",
            "       20.24162041, 20.28694577, 20.29597263, 20.340529  , 20.34878725,\n",
            "       20.35306399, 20.36233594, 20.37380912, 20.3801118 , 20.38624793,\n",
            "       20.3882839 , 20.39358715, 20.39549139, 20.39748215, 20.41409849,\n",
            "       20.41794043, 20.42763727, 20.43506502, 20.43900637, 20.43963742,\n",
            "       20.44883195, 20.44912658, 20.46213644, 20.46423658, 20.46553031,\n",
            "       20.47303746, 20.47748605, 20.48165592, 20.4862033 , 20.48958581,\n",
            "       20.49078829, 20.49512887, 20.51095088, 20.51760413, 20.52592091,\n",
            "       20.54152394, 20.54286076, 20.54666089, 20.54865321, 20.55127409,\n",
            "       20.55143216, 20.55721148, 20.56247282, 20.57507679, 20.57660632])}, 224680)\n",
            "({'ids': array(['airplane/1.png', 'airplane/49.png', 'rollerblades/13801.png',\n",
            "       'submarine/16594.png', 'submarine/16577.png', 'airplane/54.png',\n",
            "       'bread/2460.png', 'sailboat/13932.png', 'airplane/12.png',\n",
            "       'airplane/74.png', 'lighter/9805.png', 'ship/14915.png',\n",
            "       'armchair/511.png', 'envelope/6034.png', 'axe/683.png',\n",
            "       'crown/5049.png', 'tablelamp/17327.png', 'potted plant/12815.png',\n",
            "       'leaf/9629.png', 'piano/12314.png', 'microphone/10330.png',\n",
            "       'flying bird/6891.png', 'streetlight/16498.png', 'shoe/14985.png',\n",
            "       'hat/8058.png', 'flying saucer/7000.png', 'wheelbarrow/19552.png',\n",
            "       'tablelamp/17299.png', 'shoe/14989.png', 'bee/1413.png',\n",
            "       'paper clip/11600.png', 'toilet/18038.png', 'pear/11891.png',\n",
            "       'arm/441.png', 'fan/6396.png', 'space shuttle/15832.png',\n",
            "       'bell/1535.png', 'streetlight/16557.png', 'tv/18979.png',\n",
            "       'mailbox/10143.png', 'bed/1319.png', 'shoe/14968.png',\n",
            "       'arm/443.png', 'sailboat/14000.png', 'cake/3105.png',\n",
            "       'flashlight/6681.png', 'computer-mouse/4594.png',\n",
            "       'wheelbarrow/19558.png', 'shark/14775.png', 'tooth/18180.png',\n",
            "       'floor lamp/6735.png', 'axe/680.png', 't-shirt/17180.png',\n",
            "       'mouth/10881.png', 'cell phone/3932.png', 'axe/667.png',\n",
            "       'satellite/14136.png', 'radio/13483.png', 'arm/414.png',\n",
            "       'bell/1549.png', 'canoe/3548.png', 'tv/19011.png',\n",
            "       'scissors/14393.png', 'rollerblades/13778.png', 'airplane/76.png',\n",
            "       'crane (machine)/4927.png', 'airplane/44.png',\n",
            "       'wheelbarrow/19528.png', 'mug/10982.png', 'sea turtle/14569.png',\n",
            "       'helicopter/8382.png', 'canoe/3582.png', 'tv/18993.png',\n",
            "       'sponge bob/16023.png', 'shark/14744.png', 't-shirt/17145.png',\n",
            "       'hammer/7813.png', 'speed-boat/15884.png', 'shark/14738.png',\n",
            "       'arm/440.png'], dtype='<U28'), 'labels': array([  0,   0, 172, 207, 207,   0,  30, 174,   0,   0, 122, 186,   6,\n",
            "        75,   8,  63, 216, 160, 120, 153, 129,  86, 206, 187, 100,  87,\n",
            "       244, 216, 187,  17, 144, 225, 148,   5,  79, 197,  19, 206, 237,\n",
            "       126,  16, 187,   5, 174,  38,  83,  57, 244, 184, 227,  84,   8,\n",
            "       214, 136,  49,   8, 176, 168,   5,  19,  44, 237, 179, 172,   0,\n",
            "        61,   0, 244, 137, 182, 104,  44, 237, 200, 184, 214,  97, 198,\n",
            "       184,   5]), 'similarities': array([1.        , 0.78619141, 0.75982625, 0.75871622, 0.75547825,\n",
            "       0.74830077, 0.74468636, 0.74191745, 0.7418463 , 0.74056391,\n",
            "       0.73956039, 0.73744339, 0.73594225, 0.73563071, 0.73515421,\n",
            "       0.73477283, 0.73438005, 0.73366662, 0.73346137, 0.73309499,\n",
            "       0.73277041, 0.73241389, 0.73165337, 0.73163353, 0.7305194 ,\n",
            "       0.73051919, 0.73035468, 0.73007564, 0.72951436, 0.7293647 ,\n",
            "       0.72855491, 0.72852144, 0.72831162, 0.72817808, 0.72805891,\n",
            "       0.72798992, 0.72793627, 0.72780332, 0.72756585, 0.72755895,\n",
            "       0.72723955, 0.72660115, 0.72616825, 0.72605372, 0.72593951,\n",
            "       0.7257788 , 0.72554746, 0.72506595, 0.72441884, 0.72418815,\n",
            "       0.72414853, 0.72363894, 0.72351262, 0.72348169, 0.72280088,\n",
            "       0.7226945 , 0.72267116, 0.72260764, 0.72238924, 0.72214399,\n",
            "       0.72205192, 0.72189185, 0.72172917, 0.72170076, 0.7216424 ,\n",
            "       0.72158557, 0.72149357, 0.72135349, 0.72132871, 0.72099982,\n",
            "       0.72086811, 0.72083435, 0.72064437, 0.72025775, 0.72019285,\n",
            "       0.71978031, 0.71942546, 0.71941529, 0.71889768, 0.71867197])}, 224680)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Efqs1H1ngO2"
      },
      "source": [
        "def compare(a, b):\r\n",
        "  for comp in zip(a, b):\r\n",
        "    if comp[0] != comp[1]:\r\n",
        "      print(comp)\r\n",
        "      return False\r\n",
        "  return True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LpPe6XS5p5qQ"
      },
      "source": [
        "del lsh_bitwise"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBloot7C-iqH"
      },
      "source": [
        "### Fine tuning with classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r91ej_YbC5v7"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import numpy as np\n",
        "from keras.models import Model\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.applications.inception_v3 import preprocess_input"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sQ5vVpnTbzZ"
      },
      "source": [
        "MODEL_PATH = \"/content/gdrive/Shareddrives/COMPUTER_VISION/models\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-PmgVb_GGzZd",
        "outputId": "26023ccb-ec71-45c4-c2b9-801604411d9b"
      },
      "source": [
        "inception = InceptionV3(weights='imagenet',\r\n",
        "                  include_top=False,\r\n",
        "                  input_shape=INPUT_SHAPE)\r\n",
        "inception.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"inception_v3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 229, 229, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 114, 114, 32) 864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 114, 114, 32) 96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 114, 114, 32) 0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 112, 112, 32) 9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 112, 112, 32) 96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 112, 112, 32) 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 112, 112, 64) 18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 112, 112, 64) 192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 112, 112, 64) 0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 55, 55, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 55, 55, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 55, 55, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 55, 55, 80)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 53, 53, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 53, 53, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 53, 53, 192)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 26, 26, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 26, 26, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 26, 26, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 26, 26, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 26, 26, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 26, 26, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 26, 26, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 26, 26, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 26, 26, 48)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 26, 26, 96)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 26, 26, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 26, 26, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 26, 26, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 26, 26, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 26, 26, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 26, 26, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 26, 26, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 26, 26, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 26, 26, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 26, 26, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 26, 26, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 26, 26, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 26, 26, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 26, 26, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 26, 26, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 26, 26, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 26, 26, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 26, 26, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 26, 26, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 26, 26, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 26, 26, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 26, 26, 48)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 26, 26, 96)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 26, 26, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 26, 26, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 26, 26, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 26, 26, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 26, 26, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 26, 26, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 26, 26, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 26, 26, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 26, 26, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 26, 26, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 26, 26, 64)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 26, 26, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 26, 26, 64)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 26, 26, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 26, 26, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 26, 26, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 26, 26, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 26, 26, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 26, 26, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 26, 26, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 26, 26, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 26, 26, 48)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 26, 26, 96)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 26, 26, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 26, 26, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 26, 26, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 26, 26, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 26, 26, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 26, 26, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 26, 26, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 26, 26, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 26, 26, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 26, 26, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 26, 26, 64)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 26, 26, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 26, 26, 64)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 26, 26, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 26, 26, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 26, 26, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 26, 26, 64)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 26, 26, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 26, 26, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 26, 26, 96)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 12, 12, 384)  995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 12, 12, 96)   82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 12, 12, 384)  1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 12, 12, 96)   288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 12, 12, 384)  0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 12, 12, 96)   0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 12, 12, 288)  0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 12, 12, 768)  0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 12, 12, 128)  384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 12, 12, 128)  0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 12, 12, 128)  114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 12, 12, 128)  384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 12, 12, 128)  0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 12, 12, 128)  114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 12, 12, 128)  384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 12, 12, 128)  384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 12, 12, 128)  0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 12, 12, 128)  0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 12, 12, 128)  114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 12, 12, 128)  114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 12, 12, 128)  384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 12, 12, 128)  384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 12, 12, 128)  0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 12, 12, 128)  0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 12, 12, 768)  0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 12, 12, 192)  147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 12, 12, 192)  172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 12, 12, 192)  172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 12, 12, 192)  576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 12, 12, 192)  576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 12, 12, 192)  576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 12, 12, 192)  576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 12, 12, 192)  0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 12, 12, 192)  0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 12, 12, 192)  0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 12, 12, 192)  0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 12, 12, 768)  0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 12, 12, 160)  480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 12, 12, 160)  0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 12, 12, 160)  179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 12, 12, 160)  480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 12, 12, 160)  0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 12, 12, 160)  179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 12, 12, 160)  480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 12, 12, 160)  480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 12, 12, 160)  0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 12, 12, 160)  0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 12, 12, 160)  179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 12, 12, 160)  179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 12, 12, 160)  480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 12, 12, 160)  480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 12, 12, 160)  0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 12, 12, 160)  0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 12, 12, 768)  0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 12, 12, 192)  147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 12, 12, 192)  215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 12, 12, 192)  215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 12, 12, 192)  576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 12, 12, 192)  576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 12, 12, 192)  576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 12, 12, 192)  576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 12, 12, 192)  0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 12, 12, 192)  0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 12, 12, 192)  0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 12, 12, 192)  0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 12, 12, 768)  0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 12, 12, 160)  480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 12, 12, 160)  0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 12, 12, 160)  179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 12, 12, 160)  480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 12, 12, 160)  0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 12, 12, 160)  179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 12, 12, 160)  480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 12, 12, 160)  480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 12, 12, 160)  0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 12, 12, 160)  0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 12, 12, 160)  179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 12, 12, 160)  179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 12, 12, 160)  480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 12, 12, 160)  480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 12, 12, 160)  0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 12, 12, 160)  0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 12, 12, 768)  0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 12, 12, 192)  147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 12, 12, 192)  215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 12, 12, 192)  215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 12, 12, 192)  576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 12, 12, 192)  576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 12, 12, 192)  576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 12, 12, 192)  576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 12, 12, 192)  0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 12, 12, 192)  0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 12, 12, 192)  0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 12, 12, 192)  0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 12, 12, 768)  0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 12, 12, 192)  576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 12, 12, 192)  0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 12, 12, 192)  258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 12, 12, 192)  576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 12, 12, 192)  0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 12, 12, 192)  258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 12, 12, 192)  576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 12, 12, 192)  576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 12, 12, 192)  0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 12, 12, 192)  0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 12, 12, 192)  258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 12, 12, 192)  258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 12, 12, 192)  576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 12, 12, 192)  576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 12, 12, 192)  0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 12, 12, 192)  0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 12, 12, 768)  0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 12, 12, 192)  258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 12, 12, 192)  258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 12, 12, 192)  576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 12, 12, 192)  576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 12, 12, 192)  576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 12, 12, 192)  576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 12, 12, 192)  0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 12, 12, 192)  0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 12, 12, 192)  0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 12, 12, 192)  0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 12, 12, 768)  0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 12, 12, 192)  576         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 12, 12, 192)  0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 12, 12, 192)  258048      activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 12, 12, 192)  576         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 12, 12, 192)  0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 12, 12, 192)  258048      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 12, 12, 192)  576         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 12, 12, 192)  576         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 12, 12, 192)  0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 12, 12, 192)  0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 5, 5, 320)    552960      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 5, 5, 192)    331776      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 5, 5, 320)    960         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 5, 5, 192)    576         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 5, 5, 320)    0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 5, 5, 192)    0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 5, 5, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 5, 5, 1280)   0           activation_71[0][0]              \n",
            "                                                                 activation_75[0][0]              \n",
            "                                                                 max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 5, 5, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 5, 5, 448)    1344        conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 5, 5, 448)    0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 5, 5, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 5, 5, 384)    1548288     activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 5, 5, 384)    1152        conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 5, 5, 384)    1152        conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 5, 5, 384)    0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 5, 5, 384)    0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 5, 5, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 5, 5, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 5, 5, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 5, 5, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 5, 5, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 5, 5, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 5, 5, 384)    1152        conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 5, 5, 384)    1152        conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 5, 5, 384)    1152        conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 5, 5, 384)    1152        conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 5, 5, 192)    245760      average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 5, 5, 320)    960         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 5, 5, 384)    0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 5, 5, 384)    0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 5, 5, 384)    0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 5, 5, 384)    0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 5, 5, 192)    576         conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 5, 5, 320)    0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 5, 5, 768)    0           activation_78[0][0]              \n",
            "                                                                 activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 5, 5, 768)    0           activation_82[0][0]              \n",
            "                                                                 activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 5, 5, 192)    0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 5, 5, 2048)   0           activation_76[0][0]              \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate[0][0]                \n",
            "                                                                 activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 5, 5, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 5, 5, 448)    1344        conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 5, 5, 448)    0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 5, 5, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 5, 5, 384)    1548288     activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 5, 5, 384)    1152        conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 5, 5, 384)    1152        conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 5, 5, 384)    0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 5, 5, 384)    0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 5, 5, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 5, 5, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 5, 5, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 5, 5, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, 5, 5, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 5, 5, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 5, 5, 384)    1152        conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 5, 5, 384)    1152        conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 5, 5, 384)    1152        conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 5, 5, 384)    1152        conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 5, 5, 192)    393216      average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 5, 5, 320)    960         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 5, 5, 384)    0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 5, 5, 384)    0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 5, 5, 384)    0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 5, 5, 384)    0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 5, 5, 192)    576         conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 5, 5, 320)    0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 5, 5, 768)    0           activation_87[0][0]              \n",
            "                                                                 activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 5, 5, 768)    0           activation_91[0][0]              \n",
            "                                                                 activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 5, 5, 192)    0           batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 5, 5, 2048)   0           activation_85[0][0]              \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_1[0][0]              \n",
            "                                                                 activation_93[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 21,802,784\n",
            "Trainable params: 21,768,352\n",
            "Non-trainable params: 34,432\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFYzt4LV-vBL",
        "outputId": "b27d392a-a52d-47d9-9c3a-044df1fb9e21"
      },
      "source": [
        "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input,\n",
        "    validation_split=0.1,\n",
        "    zoom_range=0.1,\n",
        "    rotation_range=180,\n",
        "    vertical_flip = True,\n",
        "    horizontal_flip = True\n",
        "    ) # set validation split\n",
        "\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    SKETCHES_DIR,\n",
        "    shuffle=True,\n",
        "    # All images will be resized to 150x150\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    subset='training') # set as training data\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    SKETCHES_DIR,\n",
        "    shuffle=True,\n",
        "    # All images will be resized to 150x150\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    subset='validation') \n",
        "\n",
        "inception = InceptionV3(weights='imagenet',\n",
        "                  include_top=False,\n",
        "                  pooling='avg',\n",
        "                  input_shape=INPUT_SHAPE)\n",
        "\n",
        "set_trainable = False\n",
        "for layer in inception.layers:\n",
        "  print(layer.name)\n",
        "  if layer.name == 'mixed9':\n",
        "    print('ok')\n",
        "    set_trainable = True\n",
        "  layer.trainable = set_trainable\n",
        "\n",
        "\n",
        "model_classification = keras.models.Sequential()\n",
        "model_classification.add(inception)\n",
        "model_classification.add(layers.Dropout(0.5))\n",
        "model_classification.add(layers.Dense(250, activation='softmax'))\n",
        "model_classification.compile(loss='categorical_crossentropy',\n",
        "              # optimizer=keras.optimizers.RMSprop(lr=2e-5),\n",
        "              optimizer=keras.optimizers.Adam(),\n",
        "              metrics=['acc'])\n",
        "model_classification.summary()\n",
        "\n",
        "\n",
        "model_checkpoint = ModelCheckpoint('checkpoint.h5', save_best_only=True, save_weights_only=True, verbose=1)\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_acc', patience=10)\n",
        "\n",
        "\n",
        "history = model_classification.fit(\n",
        "  train_generator,\n",
        "  steps_per_epoch = 20000 * 0.9 // BATCH_SIZE,\n",
        "  epochs=20,\n",
        "  validation_data = validation_generator,\n",
        "  validation_steps =  20000 * 0.1 // BATCH_SIZE,\n",
        "  callbacks = [callback, model_checkpoint]\n",
        "  )\n",
        "model_classification.load_weights('checkpoint.h5')\n",
        "models.save_model(model_classification, os.path.join(MODEL_PATH, 'inception_finetuning_classification.h5'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 18000 images belonging to 250 classes.\n",
            "Found 2000 images belonging to 250 classes.\n",
            "input_3\n",
            "conv2d_188\n",
            "batch_normalization_188\n",
            "activation_188\n",
            "conv2d_189\n",
            "batch_normalization_189\n",
            "activation_189\n",
            "conv2d_190\n",
            "batch_normalization_190\n",
            "activation_190\n",
            "max_pooling2d_8\n",
            "conv2d_191\n",
            "batch_normalization_191\n",
            "activation_191\n",
            "conv2d_192\n",
            "batch_normalization_192\n",
            "activation_192\n",
            "max_pooling2d_9\n",
            "conv2d_196\n",
            "batch_normalization_196\n",
            "activation_196\n",
            "conv2d_194\n",
            "conv2d_197\n",
            "batch_normalization_194\n",
            "batch_normalization_197\n",
            "activation_194\n",
            "activation_197\n",
            "average_pooling2d_18\n",
            "conv2d_193\n",
            "conv2d_195\n",
            "conv2d_198\n",
            "conv2d_199\n",
            "batch_normalization_193\n",
            "batch_normalization_195\n",
            "batch_normalization_198\n",
            "batch_normalization_199\n",
            "activation_193\n",
            "activation_195\n",
            "activation_198\n",
            "activation_199\n",
            "mixed0\n",
            "conv2d_203\n",
            "batch_normalization_203\n",
            "activation_203\n",
            "conv2d_201\n",
            "conv2d_204\n",
            "batch_normalization_201\n",
            "batch_normalization_204\n",
            "activation_201\n",
            "activation_204\n",
            "average_pooling2d_19\n",
            "conv2d_200\n",
            "conv2d_202\n",
            "conv2d_205\n",
            "conv2d_206\n",
            "batch_normalization_200\n",
            "batch_normalization_202\n",
            "batch_normalization_205\n",
            "batch_normalization_206\n",
            "activation_200\n",
            "activation_202\n",
            "activation_205\n",
            "activation_206\n",
            "mixed1\n",
            "conv2d_210\n",
            "batch_normalization_210\n",
            "activation_210\n",
            "conv2d_208\n",
            "conv2d_211\n",
            "batch_normalization_208\n",
            "batch_normalization_211\n",
            "activation_208\n",
            "activation_211\n",
            "average_pooling2d_20\n",
            "conv2d_207\n",
            "conv2d_209\n",
            "conv2d_212\n",
            "conv2d_213\n",
            "batch_normalization_207\n",
            "batch_normalization_209\n",
            "batch_normalization_212\n",
            "batch_normalization_213\n",
            "activation_207\n",
            "activation_209\n",
            "activation_212\n",
            "activation_213\n",
            "mixed2\n",
            "conv2d_215\n",
            "batch_normalization_215\n",
            "activation_215\n",
            "conv2d_216\n",
            "batch_normalization_216\n",
            "activation_216\n",
            "conv2d_214\n",
            "conv2d_217\n",
            "batch_normalization_214\n",
            "batch_normalization_217\n",
            "activation_214\n",
            "activation_217\n",
            "max_pooling2d_10\n",
            "mixed3\n",
            "conv2d_222\n",
            "batch_normalization_222\n",
            "activation_222\n",
            "conv2d_223\n",
            "batch_normalization_223\n",
            "activation_223\n",
            "conv2d_219\n",
            "conv2d_224\n",
            "batch_normalization_219\n",
            "batch_normalization_224\n",
            "activation_219\n",
            "activation_224\n",
            "conv2d_220\n",
            "conv2d_225\n",
            "batch_normalization_220\n",
            "batch_normalization_225\n",
            "activation_220\n",
            "activation_225\n",
            "average_pooling2d_21\n",
            "conv2d_218\n",
            "conv2d_221\n",
            "conv2d_226\n",
            "conv2d_227\n",
            "batch_normalization_218\n",
            "batch_normalization_221\n",
            "batch_normalization_226\n",
            "batch_normalization_227\n",
            "activation_218\n",
            "activation_221\n",
            "activation_226\n",
            "activation_227\n",
            "mixed4\n",
            "conv2d_232\n",
            "batch_normalization_232\n",
            "activation_232\n",
            "conv2d_233\n",
            "batch_normalization_233\n",
            "activation_233\n",
            "conv2d_229\n",
            "conv2d_234\n",
            "batch_normalization_229\n",
            "batch_normalization_234\n",
            "activation_229\n",
            "activation_234\n",
            "conv2d_230\n",
            "conv2d_235\n",
            "batch_normalization_230\n",
            "batch_normalization_235\n",
            "activation_230\n",
            "activation_235\n",
            "average_pooling2d_22\n",
            "conv2d_228\n",
            "conv2d_231\n",
            "conv2d_236\n",
            "conv2d_237\n",
            "batch_normalization_228\n",
            "batch_normalization_231\n",
            "batch_normalization_236\n",
            "batch_normalization_237\n",
            "activation_228\n",
            "activation_231\n",
            "activation_236\n",
            "activation_237\n",
            "mixed5\n",
            "conv2d_242\n",
            "batch_normalization_242\n",
            "activation_242\n",
            "conv2d_243\n",
            "batch_normalization_243\n",
            "activation_243\n",
            "conv2d_239\n",
            "conv2d_244\n",
            "batch_normalization_239\n",
            "batch_normalization_244\n",
            "activation_239\n",
            "activation_244\n",
            "conv2d_240\n",
            "conv2d_245\n",
            "batch_normalization_240\n",
            "batch_normalization_245\n",
            "activation_240\n",
            "activation_245\n",
            "average_pooling2d_23\n",
            "conv2d_238\n",
            "conv2d_241\n",
            "conv2d_246\n",
            "conv2d_247\n",
            "batch_normalization_238\n",
            "batch_normalization_241\n",
            "batch_normalization_246\n",
            "batch_normalization_247\n",
            "activation_238\n",
            "activation_241\n",
            "activation_246\n",
            "activation_247\n",
            "mixed6\n",
            "conv2d_252\n",
            "batch_normalization_252\n",
            "activation_252\n",
            "conv2d_253\n",
            "batch_normalization_253\n",
            "activation_253\n",
            "conv2d_249\n",
            "conv2d_254\n",
            "batch_normalization_249\n",
            "batch_normalization_254\n",
            "activation_249\n",
            "activation_254\n",
            "conv2d_250\n",
            "conv2d_255\n",
            "batch_normalization_250\n",
            "batch_normalization_255\n",
            "activation_250\n",
            "activation_255\n",
            "average_pooling2d_24\n",
            "conv2d_248\n",
            "conv2d_251\n",
            "conv2d_256\n",
            "conv2d_257\n",
            "batch_normalization_248\n",
            "batch_normalization_251\n",
            "batch_normalization_256\n",
            "batch_normalization_257\n",
            "activation_248\n",
            "activation_251\n",
            "activation_256\n",
            "activation_257\n",
            "mixed7\n",
            "conv2d_260\n",
            "batch_normalization_260\n",
            "activation_260\n",
            "conv2d_261\n",
            "batch_normalization_261\n",
            "activation_261\n",
            "conv2d_258\n",
            "conv2d_262\n",
            "batch_normalization_258\n",
            "batch_normalization_262\n",
            "activation_258\n",
            "activation_262\n",
            "conv2d_259\n",
            "conv2d_263\n",
            "batch_normalization_259\n",
            "batch_normalization_263\n",
            "activation_259\n",
            "activation_263\n",
            "max_pooling2d_11\n",
            "mixed8\n",
            "conv2d_268\n",
            "batch_normalization_268\n",
            "activation_268\n",
            "conv2d_265\n",
            "conv2d_269\n",
            "batch_normalization_265\n",
            "batch_normalization_269\n",
            "activation_265\n",
            "activation_269\n",
            "conv2d_266\n",
            "conv2d_267\n",
            "conv2d_270\n",
            "conv2d_271\n",
            "average_pooling2d_25\n",
            "conv2d_264\n",
            "batch_normalization_266\n",
            "batch_normalization_267\n",
            "batch_normalization_270\n",
            "batch_normalization_271\n",
            "conv2d_272\n",
            "batch_normalization_264\n",
            "activation_266\n",
            "activation_267\n",
            "activation_270\n",
            "activation_271\n",
            "batch_normalization_272\n",
            "activation_264\n",
            "mixed9_0\n",
            "concatenate_4\n",
            "activation_272\n",
            "mixed9\n",
            "ok\n",
            "conv2d_277\n",
            "batch_normalization_277\n",
            "activation_277\n",
            "conv2d_274\n",
            "conv2d_278\n",
            "batch_normalization_274\n",
            "batch_normalization_278\n",
            "activation_274\n",
            "activation_278\n",
            "conv2d_275\n",
            "conv2d_276\n",
            "conv2d_279\n",
            "conv2d_280\n",
            "average_pooling2d_26\n",
            "conv2d_273\n",
            "batch_normalization_275\n",
            "batch_normalization_276\n",
            "batch_normalization_279\n",
            "batch_normalization_280\n",
            "conv2d_281\n",
            "batch_normalization_273\n",
            "activation_275\n",
            "activation_276\n",
            "activation_279\n",
            "activation_280\n",
            "batch_normalization_281\n",
            "activation_273\n",
            "mixed9_1\n",
            "concatenate_5\n",
            "activation_281\n",
            "mixed10\n",
            "global_average_pooling2d_1\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "inception_v3 (Functional)    (None, 2048)              21802784  \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 250)               512250    \n",
            "=================================================================\n",
            "Total params: 22,315,034\n",
            "Trainable params: 6,585,786\n",
            "Non-trainable params: 15,729,248\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "35/35 [==============================] - 317s 9s/step - loss: 4.7396 - acc: 0.1012 - val_loss: 3.6480 - val_acc: 0.2786\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 3.64801, saving model to checkpoint.h5\n",
            "Epoch 2/20\n",
            "35/35 [==============================] - 283s 8s/step - loss: 2.8780 - acc: 0.3252 - val_loss: 2.6836 - val_acc: 0.3783\n",
            "\n",
            "Epoch 00002: val_loss improved from 3.64801 to 2.68364, saving model to checkpoint.h5\n",
            "Epoch 3/20\n",
            "35/35 [==============================] - 281s 8s/step - loss: 2.4413 - acc: 0.3964 - val_loss: 2.4396 - val_acc: 0.4173\n",
            "\n",
            "Epoch 00003: val_loss improved from 2.68364 to 2.43963, saving model to checkpoint.h5\n",
            "Epoch 4/20\n",
            "35/35 [==============================] - 281s 8s/step - loss: 2.1640 - acc: 0.4585 - val_loss: 2.2004 - val_acc: 0.4557\n",
            "\n",
            "Epoch 00004: val_loss improved from 2.43963 to 2.20041, saving model to checkpoint.h5\n",
            "Epoch 5/20\n",
            "35/35 [==============================] - 273s 8s/step - loss: 1.9176 - acc: 0.5107 - val_loss: 2.1722 - val_acc: 0.4538\n",
            "\n",
            "Epoch 00005: val_loss improved from 2.20041 to 2.17224, saving model to checkpoint.h5\n",
            "Epoch 6/20\n",
            "35/35 [==============================] - 273s 8s/step - loss: 1.8345 - acc: 0.5253 - val_loss: 2.0785 - val_acc: 0.4740\n",
            "\n",
            "Epoch 00006: val_loss improved from 2.17224 to 2.07854, saving model to checkpoint.h5\n",
            "Epoch 7/20\n",
            "35/35 [==============================] - 273s 8s/step - loss: 1.7367 - acc: 0.5396 - val_loss: 2.0046 - val_acc: 0.4876\n",
            "\n",
            "Epoch 00007: val_loss improved from 2.07854 to 2.00461, saving model to checkpoint.h5\n",
            "Epoch 8/20\n",
            "35/35 [==============================] - 282s 8s/step - loss: 1.6421 - acc: 0.5613 - val_loss: 1.9860 - val_acc: 0.5072\n",
            "\n",
            "Epoch 00008: val_loss improved from 2.00461 to 1.98597, saving model to checkpoint.h5\n",
            "Epoch 9/20\n",
            "35/35 [==============================] - 274s 8s/step - loss: 1.5938 - acc: 0.5790 - val_loss: 1.9727 - val_acc: 0.5007\n",
            "\n",
            "Epoch 00009: val_loss improved from 1.98597 to 1.97274, saving model to checkpoint.h5\n",
            "Epoch 10/20\n",
            "35/35 [==============================] - 271s 8s/step - loss: 1.5179 - acc: 0.6005 - val_loss: 1.8761 - val_acc: 0.5260\n",
            "\n",
            "Epoch 00010: val_loss improved from 1.97274 to 1.87607, saving model to checkpoint.h5\n",
            "Epoch 11/20\n",
            "35/35 [==============================] - 270s 8s/step - loss: 1.4323 - acc: 0.6120 - val_loss: 1.9500 - val_acc: 0.4987\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 1.87607\n",
            "Epoch 12/20\n",
            "35/35 [==============================] - 270s 8s/step - loss: 1.3600 - acc: 0.6286 - val_loss: 1.8713 - val_acc: 0.5299\n",
            "\n",
            "Epoch 00012: val_loss improved from 1.87607 to 1.87132, saving model to checkpoint.h5\n",
            "Epoch 13/20\n",
            "35/35 [==============================] - 269s 8s/step - loss: 1.3325 - acc: 0.6348 - val_loss: 1.9127 - val_acc: 0.5228\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 1.87132\n",
            "Epoch 14/20\n",
            "35/35 [==============================] - 269s 8s/step - loss: 1.2677 - acc: 0.6432 - val_loss: 1.8858 - val_acc: 0.5104\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 1.87132\n",
            "Epoch 15/20\n",
            "35/35 [==============================] - 268s 8s/step - loss: 1.2378 - acc: 0.6561 - val_loss: 1.8215 - val_acc: 0.5521\n",
            "\n",
            "Epoch 00015: val_loss improved from 1.87132 to 1.82146, saving model to checkpoint.h5\n",
            "Epoch 16/20\n",
            "35/35 [==============================] - 270s 8s/step - loss: 1.1832 - acc: 0.6709 - val_loss: 1.8761 - val_acc: 0.5345\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 1.82146\n",
            "Epoch 17/20\n",
            "35/35 [==============================] - 268s 8s/step - loss: 1.1299 - acc: 0.6816 - val_loss: 1.8348 - val_acc: 0.5273\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 1.82146\n",
            "Epoch 18/20\n",
            "35/35 [==============================] - 269s 8s/step - loss: 1.1359 - acc: 0.6837 - val_loss: 1.8208 - val_acc: 0.5488\n",
            "\n",
            "Epoch 00018: val_loss improved from 1.82146 to 1.82085, saving model to checkpoint.h5\n",
            "Epoch 19/20\n",
            "35/35 [==============================] - 270s 8s/step - loss: 1.1165 - acc: 0.6858 - val_loss: 1.8953 - val_acc: 0.5332\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 1.82085\n",
            "Epoch 20/20\n",
            "35/35 [==============================] - 267s 8s/step - loss: 1.0712 - acc: 0.6947 - val_loss: 1.7959 - val_acc: 0.5404\n",
            "\n",
            "Epoch 00020: val_loss improved from 1.82085 to 1.79590, saving model to checkpoint.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DsUap_nHbKWM",
        "outputId": "1e98547a-3540-4494-aa26-b87d902dad95"
      },
      "source": [
        "loaded = models.load_model(os.path.join(MODEL_PATH, 'inception_finetuning_classification.h5'))\n",
        "finetuned_extactor = Model(loaded.input, loaded.layers[-2].output)\n",
        "finetuned_extactor.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "inception_v3_input (InputLay [(None, 229, 229, 3)]     0         \n",
            "_________________________________________________________________\n",
            "inception_v3 (Functional)    (None, 2048)              21802784  \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 2048)              0         \n",
            "=================================================================\n",
            "Total params: 21,802,784\n",
            "Trainable params: 6,073,536\n",
            "Non-trainable params: 15,729,248\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGQbT6SRVqHn",
        "outputId": "7d877d28-d805-4acd-ccc0-f2cd370b1d2e"
      },
      "source": [
        "import time\n",
        "sketches_features_finetuned = extract_features(finetuned_extactor, sketches_generator, 20000)\n",
        "mirflickr_features_finetuned = extract_features(finetuned_extactor, mirflickr_generator, 25000)\n",
        "all_features = np.vstack((sketches_features_finetuned, mirflickr_features_finetuned))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]\n",
            "predict = 53.34745502471924\n",
            "assign = 0.0014383792877197266\n",
            "[6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12]\n",
            "predict = 52.093236207962036\n",
            "assign = 0.0014865398406982422\n",
            "[12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYsLJrm0azKL"
      },
      "source": [
        "no_index_finetuned = NO_INDEX()\n",
        "no_index_finetuned.insert(np.vstack((sketches_features_finetuned, mirflickr_features_finetuned)), \n",
        "                np.concatenate((sketches_generator.filenames, mirflickr_generator.filenames)), \n",
        "                np.concatenate((sketches_generator.labels, np.array([250] * mirflickr_features_finetuned.shape[0]))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKP_SSS9ay4H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67197647-f019-4b7b-c22b-8de4dc24311a"
      },
      "source": [
        "query_result_ed = no_index_finetuned.query(sketches_features_finetuned[0], 80)\n",
        "query_result_sim = no_index_finetuned.query(sketches_features_finetuned[0], 80, mode='similarity')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "45000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "noj1woMMX7jn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "258a723f-0980-4e56-9aed-8d4889f4c22a"
      },
      "source": [
        "print(sketches_features_finetuned.shape)\n",
        "print(mirflickr_features_finetuned.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(20000, 2048)\n",
            "(25000, 2048)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5n1yvVApWPVN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02e432eb-7590-4dc0-eff2-6269c4e8fcee"
      },
      "source": [
        "print(query_result_ed)\n",
        "print(query_result_sim)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'ids': array(['airplane/1.png', 'submarine/16597.png', 'flying saucer/6979.png',\n",
            "       'airplane/54.png', 'airplane/44.png', 'ship/14933.png',\n",
            "       'submarine/16568.png', 'airplane/18.png', 'ship/14927.png',\n",
            "       'flying saucer/7036.png', 'airplane/53.png', 'airplane/49.png',\n",
            "       'flying saucer/6999.png', 'flying saucer/7029.png',\n",
            "       'sailboat/13972.png', 'space shuttle/15812.png', 'airplane/12.png',\n",
            "       'mushroom/11060.png', 'ship/14923.png', 'submarine/16582.png',\n",
            "       'pretzel/13102.png', 'ship/14906.png', 'cake/3105.png',\n",
            "       'flying saucer/7007.png', 'airplane/8.png', 'flying bird/6909.png',\n",
            "       'hamburger/7717.png', 'crown/5091.png', 'purse/13213.png',\n",
            "       'ship/14955.png', 'sailboat/13940.png', 'mushroom/11073.png',\n",
            "       'hamburger/7755.png', 'airplane/56.png',\n",
            "       'satellite dish/14204.png', 'flying saucer/7014.png',\n",
            "       'flying saucer/7002.png', 'rollerblades/13803.png',\n",
            "       'flying saucer/7005.png', 'butterfly/2854.png', 'carrot/3696.png',\n",
            "       'flying saucer/6975.png', 'png/im17198.jpg', 'cake/3063.png',\n",
            "       'hamburger/7720.png', 'crown/5078.png', 'airplane/71.png',\n",
            "       'skull/15269.png', 'ship/14884.png', 'crown/5087.png',\n",
            "       'cactus/2977.png', 'flying saucer/6980.png', 'airplane/5.png',\n",
            "       'ship/14959.png', 'walkie talkie/19377.png', 'butterfly/2829.png',\n",
            "       'speed-boat/15906.png', 'mushroom/11059.png',\n",
            "       'flying saucer/6995.png', 'diamond/5215.png', 'octopus/11212.png',\n",
            "       'cake/3048.png', 'airplane/26.png', 'mushroom/11103.png',\n",
            "       'ashtray/635.png', 'dragon/5684.png', 'ashtray/587.png',\n",
            "       'airplane/69.png', 'flying saucer/7031.png', 'airplane/63.png',\n",
            "       'ship/14960.png', 'submarine/16591.png', 'airplane/32.png',\n",
            "       'airplane/76.png', 'bee/1386.png', 'airplane/28.png',\n",
            "       'bulldozer/2628.png', 'png/im462.jpg', 'airplane/31.png',\n",
            "       'cake/3052.png'], dtype='<U28'), 'labels': array([  0, 207,  87,   0,   0, 186, 207,   0, 186,  87,   0,   0,  87,\n",
            "        87, 174, 197,   0, 138, 186, 207, 163, 186,  38,  87,   0,  86,\n",
            "        96,  63, 165, 186, 174, 138,  96,   0, 177,  87,  87, 172,  87,\n",
            "        35,  46,  87, 250,  38,  96,  63,   0, 190, 186,  63,  37,  87,\n",
            "         0, 186, 242,  35, 198, 138,  87,  65, 140,  38,   0, 138,   7,\n",
            "        71,   7,   0,  87,   0, 186, 207,   0,   0,  17,   0,  32, 250,\n",
            "         0,  38]), 'distances': array([ 0.        , 17.42512079, 17.89737072, 18.33478566, 18.78244739,\n",
            "       18.84973063, 19.07140618, 19.5890931 , 19.5970925 , 19.60377942,\n",
            "       19.70118637, 19.70973701, 19.78738403, 19.81402981, 19.9156182 ,\n",
            "       20.03072778, 20.05264601, 20.11036323, 20.11331358, 20.1182414 ,\n",
            "       20.191215  , 20.20750852, 20.33206393, 20.38833539, 20.45328117,\n",
            "       20.49936175, 20.52256687, 20.52702495, 20.53224455, 20.55536694,\n",
            "       20.6037805 , 20.60879053, 20.65869185, 20.66410907, 20.70572205,\n",
            "       20.77020001, 20.84865604, 20.88201352, 20.89306566, 20.89793737,\n",
            "       20.90351421, 20.98793591, 21.00191485, 21.00400863, 21.08437684,\n",
            "       21.08743976, 21.10778237, 21.12532335, 21.19071033, 21.20162172,\n",
            "       21.28595286, 21.29331197, 21.30419223, 21.32956757, 21.33427716,\n",
            "       21.33593904, 21.34884271, 21.39254371, 21.40021292, 21.40603924,\n",
            "       21.41036758, 21.41851809, 21.4202197 , 21.43435173, 21.47358567,\n",
            "       21.47391964, 21.48391283, 21.48994095, 21.49590722, 21.50089202,\n",
            "       21.5064903 , 21.51418822, 21.52101101, 21.52598679, 21.52963856,\n",
            "       21.53588688, 21.54122822, 21.54610359, 21.55546316, 21.55790324])}\n",
            "{'ids': array(['airplane/1.png', 'airplane/54.png', 'submarine/16597.png',\n",
            "       'airplane/53.png', 'airplane/49.png', 'flying saucer/6979.png',\n",
            "       'airplane/44.png', 'airplane/18.png', 'airplane/12.png',\n",
            "       'submarine/16582.png', 'hamburger/7720.png', 'ship/14933.png',\n",
            "       'submarine/16568.png', 'flying bird/6909.png',\n",
            "       'submarine/16594.png', 'flying saucer/7036.png',\n",
            "       'flying saucer/7031.png', 'airplane/74.png', 'ship/14955.png',\n",
            "       'sailboat/13940.png', 'airplane/58.png', 'ship/14927.png',\n",
            "       'hamburger/7755.png', 'flying saucer/6999.png', 'shark/14775.png',\n",
            "       'hamburger/7704.png', 'airplane/31.png', 'ship/14923.png',\n",
            "       'bread/2409.png', 'flying saucer/6975.png',\n",
            "       'flying saucer/7029.png', 'mushroom/11050.png',\n",
            "       'flying saucer/7007.png', 'hamburger/7713.png', 'airplane/8.png',\n",
            "       'flying saucer/7035.png', 'flying saucer/7005.png',\n",
            "       'hamburger/7757.png', 'ship/14906.png', 'hamburger/7709.png',\n",
            "       'hamburger/7695.png', 'hamburger/7717.png', 'parachute/11661.png',\n",
            "       'sailboat/13972.png', 'airplane/76.png', 'flying saucer/7002.png',\n",
            "       'airplane/28.png', 'hamburger/7749.png', 'airplane/2.png',\n",
            "       'hamburger/7747.png', 'flying saucer/7000.png', 'airplane/21.png',\n",
            "       'airplane/26.png', 'space shuttle/15812.png', 'pretzel/13102.png',\n",
            "       'submarine/16581.png', 'mushroom/11059.png', 'submarine/16577.png',\n",
            "       'submarine/16591.png', 'airplane/75.png', 'airplane/70.png',\n",
            "       'mushroom/11060.png', 'bathtub/1132.png', 'hot-dog/8690.png',\n",
            "       'cake/3105.png', 'ship/14959.png', 'satellite dish/14204.png',\n",
            "       'mushroom/11073.png', 'sailboat/13984.png', 'airplane/5.png',\n",
            "       'flying saucer/6967.png', 'mushroom/11084.png', 'png/im17198.jpg',\n",
            "       'submarine/16580.png', 'flying saucer/7012.png', 'crown/5091.png',\n",
            "       'armchair/493.png', 'cake/3063.png', 'bulldozer/2628.png',\n",
            "       'mushroom/11091.png'], dtype='<U28'), 'labels': array([  0,   0, 207,   0,   0,  87,   0,   0,   0, 207,  96, 186, 207,\n",
            "        86, 207,  87,  87,   0, 186, 174,   0, 186,  96,  87, 184,  96,\n",
            "         0, 186,  30,  87,  87, 138,  87,  96,   0,  87,  87,  96, 186,\n",
            "        96,  96,  96, 145, 174,   0,  87,   0,  96,   0,  96,  87,   0,\n",
            "         0, 197, 163, 207, 138, 207, 207,   0,   0, 138,  14, 108,  38,\n",
            "       186, 177, 138, 174,   0,  87, 138, 250, 207,  87,  63,   6,  38,\n",
            "        32, 138]), 'similarities': array([1.        , 0.77969349, 0.76139621, 0.75687069, 0.74601845,\n",
            "       0.73927149, 0.73670316, 0.72957905, 0.726141  , 0.72495878,\n",
            "       0.72009328, 0.71971917, 0.71883497, 0.71053698, 0.70866784,\n",
            "       0.70767243, 0.70520475, 0.69482374, 0.69397776, 0.68972955,\n",
            "       0.68563165, 0.6845847 , 0.68348072, 0.68333228, 0.68233865,\n",
            "       0.68060497, 0.68003412, 0.67726403, 0.67611671, 0.67535258,\n",
            "       0.67481938, 0.6715005 , 0.67105556, 0.67044803, 0.66946676,\n",
            "       0.66908723, 0.66883157, 0.66794838, 0.66756189, 0.66737671,\n",
            "       0.6666645 , 0.66632011, 0.66476161, 0.6642303 , 0.66416793,\n",
            "       0.66367559, 0.66256005, 0.66232256, 0.66228549, 0.66177535,\n",
            "       0.66163268, 0.66132396, 0.66044226, 0.66033115, 0.65944186,\n",
            "       0.65805165, 0.65795191, 0.65698092, 0.65663827, 0.65489085,\n",
            "       0.65486472, 0.65467338, 0.65462873, 0.65386075, 0.65324516,\n",
            "       0.65269402, 0.65216035, 0.65175818, 0.65052748, 0.6504227 ,\n",
            "       0.65013921, 0.65004483, 0.64909738, 0.64891538, 0.6484397 ,\n",
            "       0.64838973, 0.64793031, 0.64710845, 0.64687278, 0.64673434])}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xu_6rnSAK-P2"
      },
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzNlhBp9LKje"
      },
      "source": [
        "def average_precision(requested_label, result_labels, n_ground_truth = 80):\n",
        "  \"\"\"\n",
        "  label ricercata, label ottenute, il numero di oggetti che ci sono quella label\n",
        "  \"\"\"\n",
        "  return np.sum((requested_label == result_labels).astype(int) / np.arange(1, result_labels.size + 1)) / n_ground_truth"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDZ5UXRNYMNx"
      },
      "source": [
        "query_result_ed = no_index_base.query(sketches_features[0], 80)\n",
        "query_result_sim = no_index_base.query(sketches_features[0], 80, mode='similarity')\n",
        "print('euclidean')\n",
        "print(query_result_ed)\n",
        "print(average_precision(0, query_result_ed['labels']))\n",
        "print('similarity')\n",
        "print(query_result_ed)\n",
        "print(average_precision(0, query_result_ed['labels']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiDv7shafyxe"
      },
      "source": [
        "from random import random\n",
        "def mAP(index, features, n_queries = 500, n_labels = 250, img_per_labels = 80, mode = 'euclidean'):\n",
        "  sum = 0\n",
        "  for i in range(n_queries):\n",
        "    label = i % n_labels\n",
        "    image_idx = ((i * img_per_labels) + int(random() * img_per_labels)) % (n_labels * img_per_labels)\n",
        "    # print('QUERY')\n",
        "    # print('index = ' + str(image_idx))\n",
        "    # print('label =' + str(label))\n",
        "    res = index.query(features[image_idx], img_per_labels, mode = mode)\n",
        "    # print('first label of resultset (must be equal to label) = ' + str(res['labels'][0]))\n",
        "    assert res['labels'][0] == label, 'deve essere della stessa label'\n",
        "    sum += average_precision(label, res['labels'])\n",
        "  return sum / n_queries\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnsBZbD3neiC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5086700b-41a8-49ea-faf3-837d81dc0a52"
      },
      "source": [
        "map_value = mAP(no_index_base, sketches_features)\r\n",
        "print(map_value)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.02177244528603028\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKK7Ps1oKfJz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05d1715a-1afc-45e4-95d6-c92084fe2e01"
      },
      "source": [
        "mAP(no_index_finetuned, sketches_features_finetuned)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.026893228948344724"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2SDicGPgzK7"
      },
      "source": [
        "mAP(no_index_finetuned, sketches_features_finetuned, mode='similarity')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6EAikmUwnbzS"
      },
      "source": [
        "# try to calculate bucket dispersion\n",
        "# ritorna la percentuale media, la deviazione standard della classe più popolosa dei bucket,\n",
        "# ritorna anche il numero di bucket\n",
        "def bucket_dispersion(index):\n",
        "  percs = None\n",
        "  itemsCount = None\n",
        "  i = 0\n",
        "  for bucket in index._index:\n",
        "    i += 1\n",
        "    _, counts = np.unique(index._index[bucket]['labels'], return_counts=True)\n",
        "    perc = np.max(counts) / np.sum(counts)\n",
        "    itemCount = np.sum(counts)\n",
        "    if percs is None:\n",
        "      percs = np.array([perc])\n",
        "      itemsCount = np.array([itemCount])\n",
        "    else:\n",
        "      percs = np.concatenate((percs, np.array([perc])))\n",
        "      itemsCount = np.concatenate((itemsCount, np.array([itemCount])))\n",
        "  return {\n",
        "      'perc': {\n",
        "          'mean': np.mean(percs),\n",
        "          'deviation': np.std(percs)\n",
        "      },\n",
        "      'count': {\n",
        "          'average': np.mean(itemsCount),\n",
        "          'deviation': np.std(itemsCount)\n",
        "      },\n",
        "      'n_buckets': i,\n",
        "      'n_items_counting_duplicates': np.sum(itemsCount) # ci sono anche i duplicati\n",
        "  }\n",
        "print(bucket_dispersion(lsh_base))\n",
        "print(bucket_dispersion(lsh_finetuned))\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}